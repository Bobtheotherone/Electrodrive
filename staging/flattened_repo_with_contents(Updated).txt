# Flattened repository file listing
# Root: C:\Users\dimen\Desktop\R.J._Tech_Admin\emag\electrodrive_repo\staging

================================================================================
===== BEGIN FILE: code\basis.py =====
================================================================================

from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Dict, List, Sequence, Tuple
import json
from pathlib import Path
import math

import torch

from electrodrive.utils.config import K_E
from electrodrive.orchestration.parser import CanonicalSpec


@dataclass
class ImageBasisElement:
    """Abstract base class for image-system basis elements.

    Subclasses must implement :meth:`potential`, which evaluates the
    contribution of a *unit-weight* basis element in the same potential
    units used by the learning stack's collocation targets.
    """

    type: str
    params: Dict[str, torch.Tensor]

    def potential(self, targets: torch.Tensor) -> torch.Tensor:
        """Evaluate the basis element potential at a batch of points.

        Parameters
        ----------
        targets:
            [N, 3] tensor of evaluation points.
        """
        raise NotImplementedError

    def serialize(self) -> Dict[str, Any]:
        """Serialize to a JSON-friendly dict."""
        return {
            "type": self.type,
            "params": {k: v.detach().cpu().tolist() for k, v in self.params.items()},
        }

    @staticmethod
    def deserialize(
        data: Dict[str, Any],
        device: str | torch.device = "cpu",
        dtype: torch.dtype = torch.float32,
    ) -> "ImageBasisElement":
        """Inverse of :meth:`serialize`."""
        t = data["type"]
        if t == "toroidal_eigen_mode":
            return ToroidalEigenModeBasis({"components": data.get("params", {}).get("components", [])})
        params = {
            k: torch.tensor(v, device=device, dtype=dtype)
            for k, v in data["params"].items()
        }
        if t == "point":
            return PointChargeBasis(params)
        if t == "ring":
            return RingImageBasis(params, type_name="ring")
        if t == "ring_gauss":
            return RingImageBasis(params, type_name="ring_gauss")
        if t == "mirror_stack":
            return MirrorStackBasis(params)
        if t == "poloidal_ring":
            return PoloidalRingBasis(params)
        if t in ("ring_ladder", "ring_ladder_inner", "ring_ladder_outer"):
            return RingLadderBasis(params)
        if t == "toroidal_mode_cluster":
            return ToroidalModeClusterBasis(params)
        if t == "toroidal_eigen_mode":
            return ToroidalEigenModeBasis(params)
        if t == "inner_rim_arc":
            return InnerRimArcBasis(params)
        if t == "inner_rim_ribbon":
            return InnerRimRibbonBasis(params)
        if t == "inner_patch_ring":
            return InnerPatchRingBasis(params)
        raise ValueError(f"Unknown basis element type: {t}")


class PointChargeBasis(ImageBasisElement):
    """Point-charge image basis element.

    The scalar weight associated with this basis element plays the role
    of an effective image charge. The potential returned here is in the
    *reduced* units used by the analytic shortcuts in the collocation
    stack:

        V_reduced = ε₀ * V_SI = ε₀ * (K_E * q / r) = q / (4π r)

    so that a unit weight corresponds to a unit charge in those units.
    This keeps the scales of the dictionary and the collocation targets
    compatible for canonical analytic problems, while remaining
    well-defined for BEM-backed oracles as well.
    """

    def __init__(self, params: Dict[str, torch.Tensor]):
        pos = params.get("position", None)
        if pos is None:
            raise ValueError("PointChargeBasis requires 'position' in params")
        if pos.ndim != 1 or pos.shape[0] != 3:
            # Be tolerant of [1,3] shapes coming from scripts.
            pos = pos.view(3)
        params["position"] = pos
        super().__init__("point", params)

    def potential(self, targets: torch.Tensor) -> torch.Tensor:
        """Potential of a unit-weight point charge in physical units."""
        pos = self.params["position"].to(targets.device, targets.dtype)
        R = torch.linalg.norm(targets - pos, dim=1).clamp_min(1e-12)
        return K_E / R


class RingImageBasis(ImageBasisElement):
    """Continuous ring (loop) basis approximated via fixed quadrature."""

    def __init__(self, params: Dict[str, torch.Tensor], type_name: str = "ring"):
        center = params.get("center", None)
        radius = params.get("radius", None)
        if center is None or radius is None:
            raise ValueError("RingImageBasis requires 'center' and 'radius'")
        center = center.view(3)
        radius = torch.as_tensor(radius).view(())

        n_quad_raw = params.get("n_quad", torch.tensor(64))
        n_quad = int(torch.as_tensor(n_quad_raw).item())
        n_quad = max(4, min(n_quad, 256))

        sigma = params.get("sigma", None)
        sigma_tensor = None
        if sigma is not None:
            sigma_tensor = torch.as_tensor(sigma).view(())

        super().__init__(
            type_name,
            {
                "center": center,
                "radius": radius,
                "n_quad": torch.tensor(n_quad, device=center.device),
                **({"sigma": sigma_tensor} if sigma_tensor is not None else {}),
            },
        )

    def _angles(self, device: torch.device, dtype: torch.dtype) -> torch.Tensor:
        n_quad = int(self.params["n_quad"].item())
        return torch.linspace(0.0, 2.0 * torch.pi, n_quad + 1, device=device, dtype=dtype)[
            :-1
        ]

    def potential(self, targets: torch.Tensor) -> torch.Tensor:
        """Potential of a unit-weight ring using deterministic quadrature."""
        device = targets.device
        dtype = targets.dtype
        center = self.params["center"].to(device=device, dtype=dtype)
        radius = self.params["radius"].to(device=device, dtype=dtype)

        theta = self._angles(device, dtype)
        cos_t = torch.cos(theta)
        sin_t = torch.sin(theta)
        pts = torch.stack(
            [radius * cos_t, radius * sin_t, torch.zeros_like(theta)], dim=1
        ) + center

        weights = torch.ones_like(theta)
        if "sigma" in self.params and self.type == "ring_gauss":
            sigma = float(self.params["sigma"].item())
            sigma = max(sigma, 1e-6)
            # Wrap angles to [-pi, pi] for the bell weighting.
            ang = torch.remainder(theta + torch.pi, 2.0 * torch.pi) - torch.pi
            weights = torch.exp(-0.5 * (ang / sigma) ** 2)
            weights = weights / weights.sum().clamp_min(1e-12)
        else:
            weights = weights / float(weights.numel())

        R = torch.linalg.norm(targets[:, None, :] - pts[None, :, :], dim=2).clamp_min(
            1e-12
        )
        return torch.sum(weights * (K_E / R), dim=1)


class MirrorStackBasis(ImageBasisElement):
    """Finite mirror-image stack between two parallel planes."""

    MAX_IMAGES = 20

    def __init__(self, params: Dict[str, torch.Tensor]):
        pos = params.get("position", None)
        z_lower = params.get("z_lower", None)
        z_upper = params.get("z_upper", None)
        n_images_raw = params.get("n_images", torch.tensor(6))

        if pos is None or z_lower is None or z_upper is None:
            raise ValueError(
                "MirrorStackBasis requires 'position', 'z_lower', and 'z_upper'"
            )
        pos = pos.view(3)
        z_lower_f = float(torch.as_tensor(z_lower).item())
        z_upper_f = float(torch.as_tensor(z_upper).item())
        n_images = int(torch.as_tensor(n_images_raw).item())
        n_images = max(1, min(n_images, self.MAX_IMAGES))

        super().__init__(
            "mirror_stack",
            {
                "position": pos,
                "z_lower": torch.tensor(z_lower_f, device=pos.device),
                "z_upper": torch.tensor(z_upper_f, device=pos.device),
                "n_images": torch.tensor(n_images, device=pos.device),
            },
        )

        self._images, self._signs = self._build_stack(pos, z_lower_f, z_upper_f, n_images)

    @staticmethod
    def _build_stack(
        pos: torch.Tensor, z_lower: float, z_upper: float, n_images: int
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        x0, y0, z0 = float(pos[0]), float(pos[1]), float(pos[2])
        d = 0.5 * (z_upper - z_lower)
        if d <= 0.0:
            raise ValueError("MirrorStackBasis requires z_upper > z_lower")

        images: List[List[float]] = []
        signs: List[float] = []
        # Finite truncation of the classic parallel-planes image series.
        for n in range(-n_images, n_images + 1):
            sign_n = (-1.0) ** n
            z_pos = 2.0 * n * d + z0
            images.append([x0, y0, z_pos])
            signs.append(sign_n)

            if n == 0:
                # Skip the duplicate at n=0 for the mirrored branch.
                continue
            z_mirror = 2.0 * n * d - z0
            images.append([x0, y0, z_mirror])
            signs.append(-sign_n)

        return torch.tensor(images), torch.tensor(signs)

    def potential(self, targets: torch.Tensor) -> torch.Tensor:
        device = targets.device
        dtype = targets.dtype
        imgs = self._images.to(device=device, dtype=dtype)
        signs = self._signs.to(device=device, dtype=dtype)
        R = torch.linalg.norm(targets[:, None, :] - imgs[None, :, :], dim=2).clamp_min(
            1e-12
        )
        return torch.sum(signs * (K_E / R), dim=1)


class PoloidalRingBasis(ImageBasisElement):
    """Fixed poloidal multipole ring combination with a single scalar weight."""

    PATTERNS: Dict[int, Tuple[List[float], List[float]]] = {
        0: ([0.0], [1.0]),
        1: ([-1.0, 1.0], [1.0, -1.0]),
        2: ([-1.0, 0.0, 1.0], [1.0, -2.0, 1.0]),
    }

    def __init__(self, params: Dict[str, torch.Tensor]):
        center = params.get("center", None)
        radius = params.get("radius", None)
        delta_r = params.get("delta_r", None)
        order = int(torch.as_tensor(params.get("order", 0)).item())
        n_quad_raw = params.get("n_quad", torch.tensor(96))

        if center is None or radius is None or delta_r is None:
            raise ValueError("PoloidalRingBasis requires 'center', 'radius', and 'delta_r'")
        if order not in self.PATTERNS:
            raise ValueError(f"PoloidalRingBasis order must be one of {list(self.PATTERNS.keys())}")

        center = center.view(3)
        radius = torch.as_tensor(radius).view(())
        delta_r = torch.as_tensor(delta_r).view(())
        n_quad = int(torch.as_tensor(n_quad_raw).item())
        n_quad = max(8, min(n_quad, 256))

        super().__init__(
            "poloidal_ring",
            {
                "center": center,
                "radius": radius,
                "delta_r": delta_r,
                "order": torch.tensor(order, device=center.device),
                "n_quad": torch.tensor(n_quad, device=center.device),
            },
        )

    def _angles(self, device: torch.device, dtype: torch.dtype) -> torch.Tensor:
        n_quad = int(self.params["n_quad"].item())
        return torch.linspace(0.0, 2.0 * torch.pi, n_quad + 1, device=device, dtype=dtype)[:-1]

    def potential(self, targets: torch.Tensor) -> torch.Tensor:
        device = targets.device
        dtype = targets.dtype
        center = self.params["center"].to(device=device, dtype=dtype)
        base_radius = float(self.params["radius"].item())
        delta_r = float(self.params["delta_r"].item())

        theta = self._angles(device, dtype)
        cos_t = torch.cos(theta)
        sin_t = torch.sin(theta)

        offsets, coeffs = self.PATTERNS[int(self.params["order"].item())]
        norm = max(1e-8, sum(abs(c) for c in coeffs))
        acc = torch.zeros(targets.shape[0], device=device, dtype=dtype)
        for off, coeff in zip(offsets, coeffs):
            r_here = max(1e-6, base_radius + off * delta_r)
            pts = torch.stack(
                [r_here * cos_t, r_here * sin_t, torch.zeros_like(theta)], dim=1
            ) + center
            R = torch.linalg.norm(targets[:, None, :] - pts[None, :, :], dim=2).clamp_min(1e-12)
            ring_pot = torch.sum((K_E / R), dim=1) / float(theta.numel())
            acc = acc + (coeff / norm) * ring_pot
        return acc


class RingLadderBasis(ImageBasisElement):
    """Stack of rings marching radially inward or outward with decaying weights."""

    def __init__(self, params: Dict[str, torch.Tensor]):
        center = params.get("center", None)
        radius = params.get("radius", None)
        minor_radius = params.get("minor_radius", None)
        variant = params.get("variant", "inner")
        n_quad_raw = params.get("n_quad", torch.tensor(96))

        if center is None or radius is None or minor_radius is None:
            raise ValueError("RingLadderBasis requires 'center', 'radius', and 'minor_radius'")
        center = center.view(3)
        radius = torch.as_tensor(radius).view(())
        minor_radius = torch.as_tensor(minor_radius).view(())
        n_quad = int(torch.as_tensor(n_quad_raw).item())
        n_quad = max(8, min(n_quad, 256))

        if isinstance(variant, torch.Tensor):
            try:
                variant = str(variant.item())
            except Exception:
                variant = "inner"
        variant = str(variant)
        if variant not in ("inner", "outer"):
            variant = "inner"

        super().__init__(
            f"ring_ladder_{variant}",
            {
                "center": center,
                "radius": radius,
                "minor_radius": minor_radius,
                "variant": torch.tensor(0 if variant == "inner" else 1, device=center.device),
                "n_quad": torch.tensor(n_quad, device=center.device),
            },
        )

    def _angles(self, device: torch.device, dtype: torch.dtype) -> torch.Tensor:
        n_quad = int(self.params["n_quad"].item())
        return torch.linspace(0.0, 2.0 * torch.pi, n_quad + 1, device=device, dtype=dtype)[:-1]

    def potential(self, targets: torch.Tensor) -> torch.Tensor:
        device = targets.device
        dtype = targets.dtype
        center = self.params["center"].to(device=device, dtype=dtype)
        R_base = float(self.params["radius"].item())
        a = float(self.params["minor_radius"].item())
        variant = "inner" if int(self.params["variant"].item()) == 0 else "outer"

        theta = self._angles(device, dtype)
        cos_t = torch.cos(theta)
        sin_t = torch.sin(theta)

        # Radial offsets marching into or out of the tube.
        offsets = (-0.6 * a, -0.3 * a, 0.0) if variant == "inner" else (0.0, 0.3 * a, 0.6 * a)
        coeffs = (1.0, 0.6, 0.36)
        norm = max(1e-8, sum(abs(c) for c in coeffs))

        acc = torch.zeros(targets.shape[0], device=device, dtype=dtype)
        for off, coeff in zip(offsets, coeffs):
            r_here = max(1e-6, R_base + off)
            pts = torch.stack(
                [r_here * cos_t, r_here * sin_t, torch.zeros_like(theta)], dim=1
            ) + center
            R = torch.linalg.norm(targets[:, None, :] - pts[None, :, :], dim=2).clamp_min(1e-12)
            ring_pot = torch.sum((K_E / R), dim=1) / float(theta.numel())
            acc = acc + (coeff / norm) * ring_pot
        return acc


class ToroidalModeClusterBasis(ImageBasisElement):
    """Azimuthal mode cluster: discrete ring of points with cos(m phi) weights."""

    def __init__(self, params: Dict[str, torch.Tensor]):
        center = params.get("center", None)
        major_radius = params.get("major_radius", None)
        minor_radius = params.get("minor_radius", None)
        mode_m = int(torch.as_tensor(params.get("mode_m", 0)).item())
        n_phi_raw = params.get("n_phi", torch.tensor(12))
        radial_offset = params.get("radial_offset", None)

        if center is None or major_radius is None or minor_radius is None:
            raise ValueError("ToroidalModeClusterBasis requires 'center', 'major_radius', and 'minor_radius'")
        center = center.view(3)
        R_major = torch.as_tensor(major_radius).view(())
        a_minor = torch.as_tensor(minor_radius).view(())
        n_phi = int(torch.as_tensor(n_phi_raw).item())
        n_phi = max(4, min(n_phi, 64))
        radial_offset = torch.as_tensor(radial_offset if radial_offset is not None else 0.5 * a_minor).view(())

        super().__init__(
            "toroidal_mode_cluster",
            {
                "center": center,
                "major_radius": R_major,
                "minor_radius": a_minor,
                "mode_m": torch.tensor(mode_m, device=center.device),
                "n_phi": torch.tensor(n_phi, device=center.device),
                "radial_offset": radial_offset,
            },
        )

    def potential(self, targets: torch.Tensor) -> torch.Tensor:
        device = targets.device
        dtype = targets.dtype
        center = self.params["center"].to(device=device, dtype=dtype)
        R_major = float(self.params["major_radius"].item())
        a_minor = float(self.params["minor_radius"].item())
        m = int(self.params["mode_m"].item())
        n_phi = int(self.params["n_phi"].item())
        r_off = float(self.params["radial_offset"].item())

        phi = torch.linspace(0.0, 2.0 * torch.pi, n_phi + 1, device=device, dtype=dtype)[:-1]
        cos_phi = torch.cos(phi)
        sin_phi = torch.sin(phi)
        # Place points slightly off the major circle to mimic cross-section penetration.
        r_samples = torch.full_like(phi, R_major + r_off)
        z_samples = torch.zeros_like(phi)
        pts = torch.stack(
            [r_samples * cos_phi, r_samples * sin_phi, z_samples],
            dim=1,
        ) + center

        weights = torch.ones_like(phi)
        if m == 1:
            weights = torch.cos(phi)
        elif m == 2:
            weights = torch.cos(2.0 * phi)
        # Normalise weights to keep scale stable.
        norm = torch.sum(torch.abs(weights)).clamp_min(1e-8)
        weights = weights / norm

        R = torch.linalg.norm(targets[:, None, :] - pts[None, :, :], dim=2).clamp_min(1e-12)
        return torch.sum(weights * (K_E / R), dim=1)


def _torus_point_and_normal(
    center: torch.Tensor,
    R_major: float,
    a_minor: float,
    sigma: torch.Tensor,
    phi: torch.Tensor,
    device: torch.device,
    dtype: torch.dtype,
) -> Tuple[torch.Tensor, torch.Tensor]:
    """Return torus surface point and outward normal for given angles."""
    sigma = sigma.to(device=device, dtype=dtype)
    phi = phi.to(device=device, dtype=dtype)
    cos_s = torch.cos(sigma)
    sin_s = torch.sin(sigma)
    cos_p = torch.cos(phi)
    sin_p = torch.sin(phi)

    # Parametric point on torus surface.
    r_ring = R_major + a_minor * cos_s
    x = r_ring * cos_p
    y = r_ring * sin_p
    z = a_minor * sin_s
    point = torch.stack([x, y, z], dim=-1) + center

    # Outward normal (not normalized to 1 for small efficiency gain).
    n = torch.stack([cos_s * cos_p, cos_s * sin_p, sin_s], dim=-1)
    norm = torch.linalg.norm(n, dim=-1, keepdim=True).clamp_min(1e-12)
    n_hat = n / norm
    return point, n_hat


class InnerRimArcBasis(ImageBasisElement):
    """Short poloidal arc on the inner rim, represented by a few inward-offset points."""

    def __init__(self, params: Dict[str, torch.Tensor]):
        required = ("center", "R", "a", "phi0", "d_sigma")
        for k in required:
            if k not in params:
                raise ValueError(f"InnerRimArcBasis missing param '{k}'")

        center = params["center"].view(3)
        R = float(torch.as_tensor(params["R"]).item())
        a = float(torch.as_tensor(params["a"]).item())
        phi0 = float(torch.as_tensor(params["phi0"]).item())
        d_sigma = float(torch.as_tensor(params["d_sigma"]).item())
        n_pts = int(torch.as_tensor(params.get("n_pts", 8)).item())
        n_pts = max(3, min(32, n_pts))
        offset_frac = float(torch.as_tensor(params.get("offset_frac", 0.3)).item())
        offset_frac = float(min(0.4, max(0.2, offset_frac)))
        taper_raw = params.get("taper", None)
        taper_str = "cos"
        if taper_raw is not None:
            try:
                taper_flag = int(torch.as_tensor(taper_raw).item())
                taper_str = "cos" if taper_flag == 0 else "gauss"
            except Exception:
                t_str = str(taper_raw)
                taper_str = t_str if t_str in ("cos", "gauss") else "cos"
        taper_str = taper_str if taper_str in ("cos", "gauss") else "cos"

        device = center.device
        dtype = center.dtype

        sigma_center = float(torch.as_tensor(params.get("sigma0", math.pi)).item())
        sigma_vals = torch.linspace(
            sigma_center - d_sigma, sigma_center + d_sigma, n_pts, device=device, dtype=dtype
        )
        phi_vals = torch.full_like(sigma_vals, phi0)

        pts, normals = _torus_point_and_normal(center, R, a, sigma_vals, phi_vals, device, dtype)
        inward = pts - offset_frac * a * normals  # move inside conductor

        # Weighting along sigma.
        if taper_str == "gauss":
            rel = (sigma_vals - sigma_center) / max(d_sigma, 1e-6)
            w = torch.exp(-0.5 * rel * rel)
        else:
            rel = torch.abs(sigma_vals - sigma_center) / max(d_sigma, 1e-6)
            w = torch.clamp(torch.cos(0.5 * math.pi * rel), min=0.0)
        w = w / w.sum().clamp_min(1e-12)

        self._points = inward
        self._weights = w
        super().__init__(
            "inner_rim_arc",
            {
                "center": center,
                "R": torch.tensor(R, device=device, dtype=dtype),
                "a": torch.tensor(a, device=device, dtype=dtype),
                "phi0": torch.tensor(phi0, device=device, dtype=dtype),
                "sigma0": torch.tensor(sigma_center, device=device, dtype=dtype),
                "d_sigma": torch.tensor(d_sigma, device=device, dtype=dtype),
                "n_pts": torch.tensor(n_pts, device=device),
                "offset_frac": torch.tensor(offset_frac, device=device, dtype=dtype),
                "taper": torch.tensor(0 if taper_str == "cos" else 1, device=device, dtype=torch.int64),
            },
        )

    def potential(self, targets: torch.Tensor) -> torch.Tensor:
        pts = self._points.to(device=targets.device, dtype=targets.dtype)
        w = self._weights.to(device=targets.device, dtype=targets.dtype)
        Rv = torch.linalg.norm(targets[:, None, :] - pts[None, :, :], dim=2).clamp_min(1e-12)
        return torch.sum(w * (K_E / Rv), dim=1)

    def serialize(self) -> Dict[str, Any]:
        p = {k: v.detach().cpu().tolist() for k, v in self.params.items()}
        # taper stored as int; map back to string for readability
        taper_flag = int(self.params["taper"].item())
        p["taper"] = "cos" if taper_flag == 0 else "gauss"
        return {"type": self.type, "params": p}


class InnerRimRibbonBasis(ImageBasisElement):
    """Short σ–φ strip on the inner rim using a separable taper."""

    def __init__(self, params: Dict[str, torch.Tensor]):
        required = ("center", "R", "a", "phi0", "d_sigma", "d_phi")
        for k in required:
            if k not in params:
                raise ValueError(f"InnerRimRibbonBasis missing param '{k}'")

        center = params["center"].view(3)
        R = float(torch.as_tensor(params["R"]).item())
        a = float(torch.as_tensor(params["a"]).item())
        phi0 = float(torch.as_tensor(params["phi0"]).item())
        d_sigma = float(torch.as_tensor(params["d_sigma"]).item())
        d_phi = float(torch.as_tensor(params["d_phi"]).item())
        n_sigma = int(torch.as_tensor(params.get("n_sigma", 6)).item())
        n_phi = int(torch.as_tensor(params.get("n_phi", 6)).item())
        n_sigma = max(3, min(48, n_sigma))
        n_phi = max(3, min(48, n_phi))
        offset_frac = float(torch.as_tensor(params.get("offset_frac", 0.3)).item())
        offset_frac = float(min(0.4, max(0.2, offset_frac)))
        taper_sigma_raw = params.get("taper_sigma", "cos")
        taper_phi_raw = params.get("taper_phi", "cos")
        try:
            taper_sigma_flag = int(torch.as_tensor(taper_sigma_raw).item())
            taper_sigma = "cos" if taper_sigma_flag == 0 else "gauss"
        except Exception:
            taper_sigma = str(taper_sigma_raw) if str(taper_sigma_raw) in ("cos", "gauss") else "cos"
        try:
            taper_phi_flag = int(torch.as_tensor(taper_phi_raw).item())
            taper_phi = "cos" if taper_phi_flag == 0 else "gauss"
        except Exception:
            taper_phi = str(taper_phi_raw) if str(taper_phi_raw) in ("cos", "gauss") else "cos"

        device = center.device
        dtype = center.dtype

        sigma_center = float(torch.as_tensor(params.get("sigma0", math.pi)).item())
        sigma_vals = torch.linspace(
            sigma_center - d_sigma, sigma_center + d_sigma, n_sigma, device=device, dtype=dtype
        )
        phi_vals = torch.linspace(phi0 - d_phi, phi0 + d_phi, n_phi, device=device, dtype=dtype)
        sigma_grid, phi_grid = torch.meshgrid(sigma_vals, phi_vals, indexing="ij")

        pts, normals = _torus_point_and_normal(center, R, a, sigma_grid, phi_grid, device, dtype)
        inward = pts - offset_frac * a * normals

        def _taper(vals: torch.Tensor, center_val: float, width: float, kind: str) -> torch.Tensor:
            if kind == "gauss":
                rel = (vals - center_val) / max(width, 1e-6)
                return torch.exp(-0.5 * rel * rel)
            rel = torch.abs(vals - center_val) / max(width, 1e-6)
            return torch.clamp(torch.cos(0.5 * math.pi * rel), min=0.0)

        w_sigma = _taper(sigma_vals, sigma_center, d_sigma, taper_sigma)
        w_phi = _taper(phi_vals, phi0, d_phi, taper_phi)
        w = torch.outer(w_sigma, w_phi)
        w = w / w.sum().clamp_min(1e-12)

        self._points = inward.reshape(-1, 3)
        self._weights = w.reshape(-1)
        super().__init__(
            "inner_rim_ribbon",
            {
                "center": center,
                "R": torch.tensor(R, device=device, dtype=dtype),
                "a": torch.tensor(a, device=device, dtype=dtype),
                "phi0": torch.tensor(phi0, device=device, dtype=dtype),
                "sigma0": torch.tensor(sigma_center, device=device, dtype=dtype),
                "d_sigma": torch.tensor(d_sigma, device=device, dtype=dtype),
                "d_phi": torch.tensor(d_phi, device=device, dtype=dtype),
                "n_sigma": torch.tensor(n_sigma, device=device),
                "n_phi": torch.tensor(n_phi, device=device),
                "offset_frac": torch.tensor(offset_frac, device=device, dtype=dtype),
                "taper_sigma": torch.tensor(0 if taper_sigma == "cos" else 1, device=device, dtype=torch.int64),
                "taper_phi": torch.tensor(0 if taper_phi == "cos" else 1, device=device, dtype=torch.int64),
            },
        )

    def potential(self, targets: torch.Tensor) -> torch.Tensor:
        pts = self._points.to(device=targets.device, dtype=targets.dtype)
        w = self._weights.to(device=targets.device, dtype=targets.dtype)
        Rv = torch.linalg.norm(targets[:, None, :] - pts[None, :, :], dim=2).clamp_min(1e-12)
        return torch.sum(w * (K_E / Rv), dim=1)

    def serialize(self) -> Dict[str, Any]:
        p = {k: v.detach().cpu().tolist() for k, v in self.params.items()}
        p["taper_sigma"] = "cos" if int(self.params["taper_sigma"].item()) == 0 else "gauss"
        p["taper_phi"] = "cos" if int(self.params["taper_phi"].item()) == 0 else "gauss"
        return {"type": self.type, "params": p}


class InnerPatchRingBasis(ImageBasisElement):
    """Localized patch on inner rim plus compensating inner ring for near-neutrality."""

    def __init__(self, params: Dict[str, torch.Tensor]):
        required = ("center", "R", "a", "phi0", "d_sigma", "d_phi")
        for k in required:
            if k not in params:
                raise ValueError(f"InnerPatchRingBasis missing param '{k}'")

        center = params["center"].view(3)
        R = float(torch.as_tensor(params["R"]).item())
        a = float(torch.as_tensor(params["a"]).item())
        phi0 = float(torch.as_tensor(params["phi0"]).item())
        d_sigma = float(torch.as_tensor(params["d_sigma"]).item())
        d_phi = float(torch.as_tensor(params["d_phi"]).item())
        n_sigma = int(torch.as_tensor(params.get("n_sigma", 6)).item())
        n_phi = int(torch.as_tensor(params.get("n_phi", 6)).item())
        n_sigma = max(3, min(48, n_sigma))
        n_phi = max(3, min(48, n_phi))
        offset_frac = float(torch.as_tensor(params.get("offset_frac", 0.3)).item())
        offset_frac = float(min(0.4, max(0.2, offset_frac)))
        ring_offset_frac = float(torch.as_tensor(params.get("ring_offset_frac", 0.55)).item())
        ring_offset_frac = float(min(0.9, max(0.1, ring_offset_frac)))
        n_ring = int(torch.as_tensor(params.get("n_ring", 12)).item())
        n_ring = max(4, min(128, n_ring))
        neutral_factor = float(torch.as_tensor(params.get("neutral_factor", 1.0)).item())
        neutral_factor = float(max(0.0, neutral_factor))
        taper_sigma_raw = params.get("taper_sigma", "cos")
        taper_phi_raw = params.get("taper_phi", "cos")
        try:
            taper_sigma_flag = int(torch.as_tensor(taper_sigma_raw).item())
            taper_sigma = "cos" if taper_sigma_flag == 0 else "gauss"
        except Exception:
            taper_sigma = str(taper_sigma_raw) if str(taper_sigma_raw) in ("cos", "gauss") else "cos"
        try:
            taper_phi_flag = int(torch.as_tensor(taper_phi_raw).item())
            taper_phi = "cos" if taper_phi_flag == 0 else "gauss"
        except Exception:
            taper_phi = str(taper_phi_raw) if str(taper_phi_raw) in ("cos", "gauss") else "cos"

        device = center.device
        dtype = center.dtype

        sigma_center = float(torch.as_tensor(params.get("sigma0", math.pi)).item())
        sigma_vals = torch.linspace(
            sigma_center - d_sigma, sigma_center + d_sigma, n_sigma, device=device, dtype=dtype
        )
        phi_vals = torch.linspace(phi0 - d_phi, phi0 + d_phi, n_phi, device=device, dtype=dtype)
        sigma_grid, phi_grid = torch.meshgrid(sigma_vals, phi_vals, indexing="ij")

        patch_pts, patch_normals = _torus_point_and_normal(center, R, a, sigma_grid, phi_grid, device, dtype)
        patch_pts = patch_pts - offset_frac * a * patch_normals

        def _taper(vals: torch.Tensor, center_val: float, width: float, kind: str) -> torch.Tensor:
            if kind == "gauss":
                rel = (vals - center_val) / max(width, 1e-6)
                return torch.exp(-0.5 * rel * rel)
            rel = torch.abs(vals - center_val) / max(width, 1e-6)
            return torch.clamp(torch.cos(0.5 * math.pi * rel), min=0.0)

        w_sigma = _taper(sigma_vals, sigma_center, d_sigma, taper_sigma)
        w_phi = _taper(phi_vals, phi0, d_phi, taper_phi)
        patch_w = torch.outer(w_sigma, w_phi)
        patch_w = patch_w / patch_w.sum().clamp_min(1e-12)

        # Ring centered on inner radius (R - ring_offset_frac * a) in the torus plane.
        ring_radius = max(1e-6, R - ring_offset_frac * a)
        theta = torch.linspace(0.0, 2.0 * math.pi, n_ring + 1, device=device, dtype=dtype)[:-1]
        ring_cos = torch.cos(theta)
        ring_sin = torch.sin(theta)
        ring_pts = torch.stack(
            [
                ring_radius * ring_cos,
                ring_radius * ring_sin,
                torch.zeros_like(theta),
            ],
            dim=1,
        ) + center
        # Approximate inward shift along inner-rim normal (sigma=pi).
        ring_normals = torch.stack(
            [-ring_cos, -ring_sin, torch.zeros_like(theta)],
            dim=1,
        )
        norm_ring = torch.linalg.norm(ring_normals, dim=1, keepdim=True).clamp_min(1e-12)
        ring_normals = ring_normals / norm_ring
        ring_pts = ring_pts - offset_frac * a * ring_normals

        patch_w_flat = patch_w.reshape(-1)
        patch_pts_flat = patch_pts.reshape(-1, 3)
        patch_total = patch_w_flat.sum().item()
        ring_w = torch.full_like(theta, 1.0 / float(n_ring))
        if patch_total != 0.0:
            ring_w = -neutral_factor * patch_total * ring_w

        # Normalise so that patch weights sum to +1, ring to -neutral_factor.
        self._patch_points = patch_pts_flat
        self._patch_weights = patch_w_flat
        self._ring_points = ring_pts
        self._ring_weights = ring_w

        super().__init__(
            "inner_patch_ring",
            {
                "center": center,
                "R": torch.tensor(R, device=device, dtype=dtype),
                "a": torch.tensor(a, device=device, dtype=dtype),
                "phi0": torch.tensor(phi0, device=device, dtype=dtype),
                "sigma0": torch.tensor(sigma_center, device=device, dtype=dtype),
                "d_sigma": torch.tensor(d_sigma, device=device, dtype=dtype),
                "d_phi": torch.tensor(d_phi, device=device, dtype=dtype),
                "n_sigma": torch.tensor(n_sigma, device=device),
                "n_phi": torch.tensor(n_phi, device=device),
                "offset_frac": torch.tensor(offset_frac, device=device, dtype=dtype),
                "ring_offset_frac": torch.tensor(ring_offset_frac, device=device, dtype=dtype),
                "n_ring": torch.tensor(n_ring, device=device),
                "neutral_factor": torch.tensor(neutral_factor, device=device, dtype=dtype),
                "taper_sigma": torch.tensor(0 if taper_sigma == "cos" else 1, device=device, dtype=torch.int64),
                "taper_phi": torch.tensor(0 if taper_phi == "cos" else 1, device=device, dtype=torch.int64),
            },
        )

    def potential(self, targets: torch.Tensor) -> torch.Tensor:
        device = targets.device
        dtype = targets.dtype
        patch_pts = self._patch_points.to(device=device, dtype=dtype)
        patch_w = self._patch_weights.to(device=device, dtype=dtype)
        ring_pts = self._ring_points.to(device=device, dtype=dtype)
        ring_w = self._ring_weights.to(device=device, dtype=dtype)

        R_patch = torch.linalg.norm(targets[:, None, :] - patch_pts[None, :, :], dim=2).clamp_min(1e-12)
        R_ring = torch.linalg.norm(targets[:, None, :] - ring_pts[None, :, :], dim=2).clamp_min(1e-12)

        V_patch = torch.sum(patch_w * (K_E / R_patch), dim=1)
        V_ring = torch.sum(ring_w * (K_E / R_ring), dim=1)
        return V_patch + V_ring

    def serialize(self) -> Dict[str, Any]:
        p = {k: v.detach().cpu().tolist() for k, v in self.params.items()}
        p["taper_sigma"] = "cos" if int(self.params["taper_sigma"].item()) == 0 else "gauss"
        p["taper_phi"] = "cos" if int(self.params["taper_phi"].item()) == 0 else "gauss"
        return {"type": self.type, "params": p}


class ToroidalEigenModeBasis(ImageBasisElement):
    """Fixed linear combination of primitive basis elements representing a learned BEM mode."""

    def __init__(self, params: Dict[str, torch.Tensor]):
        comps = params.get("components", None)
        if comps is None:
            raise ValueError("ToroidalEigenModeBasis requires 'components'")
        comp_list = comps
        elements: List[Tuple[float, ImageBasisElement]] = []
        for entry in comp_list:
            coeff = float(entry.get("coeff", 0.0))
            elem_ser = entry.get("elem", {})
            if elem_ser is None:
                continue
            elem = ImageBasisElement.deserialize(elem_ser, device=params.get("device", "cpu"), dtype=torch.float32)
            elements.append((coeff, elem))
        self.components = elements
        super().__init__(
            "toroidal_eigen_mode",
            {
                "components": comp_list,
            },
        )

    def potential(self, targets: torch.Tensor) -> torch.Tensor:
        if not self.components:
            return torch.zeros(targets.shape[0], device=targets.device, dtype=targets.dtype)
        acc = torch.zeros(targets.shape[0], device=targets.device, dtype=targets.dtype)
        for coeff, elem in self.components:
            acc = acc + coeff * elem.potential(targets)
        return acc

    def serialize(self) -> Dict[str, Any]:
        return {
            "type": self.type,
            "params": {
                "components": self.params["components"],
            },
        }

def generate_candidate_basis(
    spec: CanonicalSpec,
    basis_types: List[str],
    n_candidates: int,
    device: str | torch.device = "cpu",
    dtype: torch.dtype = torch.float32,
) -> List[ImageBasisElement]:
    """Generate a list of candidate image basis elements for a spec.

    The current implementation focuses on grounded planes with point
    charges, using simple physics-informed heuristics:

    * For each point charge, include the mirror point across the plane
      as an image candidate.
    * Perturb the mirror position tangentially and along the normal to
      create a small cloud of nearby candidates.

    This is intentionally generic: it does *not* hard-code any closed-
    form solution, but instead proposes a family of plausible basis
    locations that can be pruned by the sparse solver.
    """
    candidates: List[ImageBasisElement] = []

    conductors = getattr(spec, "conductors", []) or []
    point_charges = [
        c for c in getattr(spec, "charges", []) if c.get("type") == "point"
    ]

    wants_point = "point" in basis_types
    wants_ring = "ring" in basis_types
    wants_ring_gauss = "ring_gauss" in basis_types
    wants_mirror_stack = "mirror_stack" in basis_types
    wants_poloidal = "poloidal_ring" in basis_types
    wants_ladder_inner = "ring_ladder_inner" in basis_types
    wants_ladder_outer = "ring_ladder_outer" in basis_types
    wants_mode_cluster = "toroidal_mode_cluster" in basis_types
    wants_eigen_mode = "toroidal_eigen_mode" in basis_types
    wants_eigen_boundary = "toroidal_eigen_mode_boundary" in basis_types
    wants_eigen_offaxis = "toroidal_eigen_mode_offaxis" in basis_types
    wants_inner_arc = "inner_rim_arc" in basis_types
    wants_inner_ribbon = "inner_rim_ribbon" in basis_types
    wants_inner_patch_ring = "inner_patch_ring" in basis_types
    wants_rich_inner = "rich_inner_rim" in basis_types

    # Mirror-stack candidates for parallel planes (experimental).
    planes = [c for c in conductors if c.get("type") == "plane"]
    if wants_mirror_stack and len(planes) == 2 and point_charges:
        try:
            z_vals = sorted(float(p.get("z", 0.0)) for p in planes)
            z_lower, z_upper = z_vals[0], z_vals[1]
            for charge in point_charges:
                pos = torch.tensor(charge["pos"], device=device, dtype=dtype)
                n_img = min(MirrorStackBasis.MAX_IMAGES, max(2, n_candidates // 4))
                candidates.append(
                    MirrorStackBasis(
                        {
                            "position": pos,
                            "z_lower": torch.tensor(z_lower, device=device, dtype=dtype),
                            "z_upper": torch.tensor(z_upper, device=device, dtype=dtype),
                            "n_images": torch.tensor(n_img, device=device, dtype=dtype),
                        }
                    )
                )
        except Exception:
            pass

    # Plane heuristic (original path)
    plane_conductor = None
    for conductor in conductors:
        if conductor.get("type") == "plane":
            plane_conductor = conductor
            break
    if plane_conductor is not None and wants_point:
        z_plane = float(plane_conductor.get("z", 0.0))
        if not point_charges:
            return candidates[:n_candidates]
        for charge in point_charges:
            pos = charge["pos"]
            x0, y0, z0 = float(pos[0]), float(pos[1]), float(pos[2])

            # Include the real charge position so the solver can represent
            # the total field when needed.
            real_pos = torch.tensor([x0, y0, z0], device=device, dtype=dtype)
            candidates.append(PointChargeBasis({"position": real_pos}))

            # Mirror the charge position across the plane z = z_plane.
            z_img = 2.0 * z_plane - z0
            img_pos = torch.tensor([x0, y0, z_img], device=device, dtype=dtype)
            candidates.append(PointChargeBasis({"position": img_pos}))

            # Add a small cloud of perturbed candidates around the mirror.
            dist = abs(z0 - z_plane)
            if dist > 0.0:
                perturb_scale = 0.1 * dist

                remaining = max(0, n_candidates - len(candidates))
                if remaining > 0:
                    n_perturb = min(16, remaining)

                    for _ in range(n_perturb):
                        perturb = (
                            torch.randn(3, device=device, dtype=dtype) * perturb_scale
                        )
                        p = img_pos + perturb
                        # Keep perturbed images on the opposite side of the plane
                        # from the source charge.
                        if (z0 > z_plane and p[2] <= z_plane) or (
                            z0 < z_plane and p[2] >= z_plane
                        ):
                            p[2] = 2.0 * z_plane - p[2]
                        candidates.append(PointChargeBasis({"position": p}))
            if len(candidates) >= n_candidates:
                break
        return candidates[:n_candidates]

    # Torus heuristic (point + ring candidates)
    torus = None
    for conductor in conductors:
        if conductor.get("type") in ("torus", "toroid"):
            torus = conductor
            break
    if torus is None:
        return candidates

    def _torus_tag(major_radius: float, minor_radius: float) -> str:
        aspect = minor_radius / max(major_radius, 1e-6)
        if aspect < 0.25:
            return "thin"
        if aspect < 0.45:
            return "mid"
        return "fat"

    def _load_eigen_modes(tag: str) -> List[Dict[str, Any]]:
        search_paths = [
            Path("runs/torus") / f"toroidal_eigenmodes_{tag}.json",
            Path("runs") / f"toroidal_eigenmodes_{tag}.json",
        ]
        for p in search_paths:
            if p.exists():
                try:
                    data = json.load(p.open())
                    return data.get("modes", [])
                except Exception:
                    continue
        return []

    R = float(torus.get("major_radius", torus.get("radius", 1.0)))
    a = float(torus.get("minor_radius", 0.25 * R))
    center = torch.tensor(
        torus.get("center", [0.0, 0.0, 0.0]), device=device, dtype=dtype
    )
    aspect = a / max(R, 1e-9)

    # Helper to append a ring of point candidates at radius r_ring, height z_off.
    def _add_ring_points(
        n_pts: int, r_ring: float, z_off: float, jitter_scale: float
    ) -> None:
        nonlocal candidates
        if n_pts <= 0 or len(candidates) >= n_candidates:
            return
        theta = torch.linspace(0.0, 2.0 * torch.pi, n_pts + 1, device=device)[:-1]
        cos_t = torch.cos(theta)
        sin_t = torch.sin(theta)
        base = torch.stack(
            [r_ring * cos_t, r_ring * sin_t, torch.full_like(theta, z_off)], dim=1
        )
        jitter = torch.randn_like(base) * jitter_scale
        pts = base + jitter + center
        for p in pts:
            if len(candidates) >= n_candidates:
                break
            candidates.append(PointChargeBasis({"position": p}))

    # Non-local ring basis elements (experimental) added first so they survive trimming.
    if wants_ring or wants_ring_gauss:
        ring_n_quad = 64
        radii = [max(1e-6, R - 0.5 * a), R, max(1e-6, R + 0.5 * a)]
        z_offsets = [0.0, 0.3 * a, -0.3 * a]
        for r_ring in radii:
            for z_off in z_offsets:
                if wants_ring:
                    candidates.append(
                        RingImageBasis(
                            {
                                "center": center + torch.tensor(
                                    [0.0, 0.0, z_off], device=device, dtype=dtype
                                ),
                                "radius": torch.tensor(r_ring, device=device, dtype=dtype),
                                "n_quad": torch.tensor(ring_n_quad, device=device),
                            },
                            type_name="ring",
                        )
                    )
                if wants_ring_gauss:
                    candidates.append(
                        RingImageBasis(
                            {
                                "center": center + torch.tensor(
                                    [0.0, 0.0, z_off], device=device, dtype=dtype
                                ),
                                "radius": torch.tensor(r_ring, device=device, dtype=dtype),
                                "n_quad": torch.tensor(ring_n_quad, device=device),
                                "sigma": torch.tensor(0.4, device=device, dtype=dtype),
                            },
                            type_name="ring_gauss",
                        )
                    )

    # Poloidal multipole rings (non-local, keep near front).
    if wants_poloidal:
        delta_r = 0.5 * a
        n_quad = 128
        for order in (0, 1, 2):
            candidates.append(
                PoloidalRingBasis(
                    {
                        "center": center,
                        "radius": torch.tensor(R, device=device, dtype=dtype),
                        "delta_r": torch.tensor(delta_r, device=device, dtype=dtype),
                        "order": torch.tensor(order, device=device, dtype=dtype),
                        "n_quad": torch.tensor(n_quad, device=device),
                    }
                )
            )

    # Ring ladders approximating tails.
    if wants_ladder_inner:
        candidates.append(
            RingLadderBasis(
                {
                    "center": center,
                    "radius": torch.tensor(R, device=device, dtype=dtype),
                    "minor_radius": torch.tensor(a, device=device, dtype=dtype),
                    "variant": torch.tensor(0, device=device, dtype=torch.int64),
                    "n_quad": torch.tensor(96, device=device),
                }
            )
        )
    if wants_ladder_outer:
        candidates.append(
            RingLadderBasis(
                {
                    "center": center,
                    "radius": torch.tensor(R, device=device, dtype=dtype),
                    "minor_radius": torch.tensor(a, device=device, dtype=dtype),
                    "variant": torch.tensor(1, device=device, dtype=torch.int64),
                    "n_quad": torch.tensor(96, device=device),
                }
            )
        )

    def _load_family(family: str) -> List[Dict[str, Any]]:
        tag = _torus_tag(R, a)
        fname = f"toroidal_eigenmodes_{tag}_{family}.json"
        search_paths = [
            Path("runs/torus") / fname,
            Path("runs") / fname,
        ]
        for p in search_paths:
            if p.exists():
                try:
                    data = json.load(p.open())
                    return data.get("modes", [])
                except Exception:
                    continue
        return []

    def _append_modes(modes: List[Dict[str, Any]], max_modes: int = 4) -> None:
        for m in modes[:max_modes]:
            comps = m.get("components", [])
            try:
                candidates.append(
                    ToroidalEigenModeBasis(
                        {
                            "components": comps,
                        }
                    )
                )
            except Exception:
                continue

    if wants_eigen_mode:
        modes = _load_eigen_modes(_torus_tag(R, a))
        _append_modes(modes, max_modes=4)
    if wants_eigen_boundary:
        modes = _load_family("boundary")
        _append_modes(modes, max_modes=4)
    if wants_eigen_offaxis:
        modes = _load_family("offaxis")
        _append_modes(modes, max_modes=4)

    # Inner-rim localized primitives (experimental, boundary-layer inspired).
    if wants_inner_arc or wants_inner_ribbon or wants_inner_patch_ring:
        # Span families (half-spans in radians).
        if aspect < 0.25:  # thin
            arc_spans = [math.radians(25.0), math.radians(35.0)]
            ribbon_phi_spans = [0.55, 0.9]
            ribbon_sigma_span = math.radians(35.0)
        elif aspect < 0.45:  # mid
            arc_spans = [math.radians(40.0), math.radians(55.0)]
            ribbon_phi_spans = [0.8, 1.1]
            ribbon_sigma_span = math.radians(50.0)
        else:  # fat fallback
            arc_spans = [math.radians(45.0), math.radians(60.0)]
            ribbon_phi_spans = [0.8, 1.2]
            ribbon_sigma_span = math.radians(55.0)

        offset_frac = 0.3
        sigma_center = math.pi

        def _phi0_for_charge(pos: torch.Tensor) -> float:
            rel = pos - center
            return float(math.atan2(rel[1].item(), rel[0].item()))

        arc_span_extra = math.radians(15.0)
        for charge in point_charges:
            if len(candidates) >= n_candidates:
                break
            pos = torch.tensor(charge["pos"], device=device, dtype=dtype)
            phi0 = _phi0_for_charge(pos)
            rel = pos - center
            rho = float(torch.linalg.norm(rel[:2]).item())
            z_val = float(rel[2].item())
            dist_centerline = math.sqrt((rho - R) ** 2 + z_val * z_val)
            near_centerline = dist_centerline <= (R + 1.1 * a)

            if wants_inner_arc:
                spans_local = list(arc_spans)
                if wants_rich_inner and aspect < 0.25 and near_centerline:
                    spans_local = [arc_span_extra] + spans_local
                for i, span in enumerate(spans_local):
                    if len(candidates) >= n_candidates:
                        break
                    n_pts = 8 if i == 0 else 10
                    candidates.append(
                        InnerRimArcBasis(
                            {
                                "center": center,
                                "R": torch.tensor(R, device=device, dtype=dtype),
                                "a": torch.tensor(a, device=device, dtype=dtype),
                                "phi0": torch.tensor(phi0, device=device, dtype=dtype),
                                "d_sigma": torch.tensor(span, device=device, dtype=dtype),
                                "n_pts": torch.tensor(n_pts, device=device),
                                "offset_frac": torch.tensor(offset_frac, device=device, dtype=dtype),
                                "taper": torch.tensor(0, device=device, dtype=torch.int64),
                            }
                            )
                        )
                if wants_rich_inner and len(candidates) < n_candidates:
                    delta = math.radians(10.0)
                    span_rich = arc_span_extra if (aspect < 0.25 and near_centerline) else arc_spans[0]
                    for sign in (-1.0, 1.0):
                        if len(candidates) >= n_candidates:
                            break
                        sigma0 = math.pi + sign * delta
                        candidates.append(
                            InnerRimArcBasis(
                                {
                                    "center": center,
                                    "R": torch.tensor(R, device=device, dtype=dtype),
                                    "a": torch.tensor(a, device=device, dtype=dtype),
                                    "phi0": torch.tensor(phi0, device=device, dtype=dtype),
                                    "sigma0": torch.tensor(sigma0, device=device, dtype=dtype),
                                    "d_sigma": torch.tensor(span_rich, device=device, dtype=dtype),
                                    "n_pts": torch.tensor(8, device=device),
                                    "offset_frac": torch.tensor(offset_frac, device=device, dtype=dtype),
                                    "taper": torch.tensor(0, device=device, dtype=torch.int64),
                                }
                            )
                        )
            if wants_inner_ribbon and len(candidates) < n_candidates:
                d_phi = ribbon_phi_spans[-1]
                candidates.append(
                    InnerRimRibbonBasis(
                        {
                            "center": center,
                            "R": torch.tensor(R, device=device, dtype=dtype),
                            "a": torch.tensor(a, device=device, dtype=dtype),
                            "phi0": torch.tensor(phi0, device=device, dtype=dtype),
                            "d_sigma": torch.tensor(ribbon_sigma_span, device=device, dtype=dtype),
                            "d_phi": torch.tensor(d_phi, device=device, dtype=dtype),
                            "n_sigma": torch.tensor(6, device=device),
                            "n_phi": torch.tensor(6, device=device),
                            "offset_frac": torch.tensor(offset_frac, device=device, dtype=dtype),
                            "taper_sigma": torch.tensor(0, device=device, dtype=torch.int64),
                            "taper_phi": torch.tensor(0, device=device, dtype=torch.int64),
                        }
                    )
                )
            if wants_inner_patch_ring and len(candidates) < n_candidates:
                candidates.append(
                    InnerPatchRingBasis(
                        {
                            "center": center,
                            "R": torch.tensor(R, device=device, dtype=dtype),
                            "a": torch.tensor(a, device=device, dtype=dtype),
                            "phi0": torch.tensor(phi0, device=device, dtype=dtype),
                            "d_sigma": torch.tensor(ribbon_sigma_span, device=device, dtype=dtype),
                            "d_phi": torch.tensor(ribbon_phi_spans[-1], device=device, dtype=dtype),
                            "n_sigma": torch.tensor(6, device=device),
                            "n_phi": torch.tensor(6, device=device),
                            "offset_frac": torch.tensor(offset_frac, device=device, dtype=dtype),
                            "ring_offset_frac": torch.tensor(0.55, device=device, dtype=dtype),
                            "n_ring": torch.tensor(16, device=device),
                            "neutral_factor": torch.tensor(1.0, device=device, dtype=dtype),
                            "taper_sigma": torch.tensor(0, device=device, dtype=torch.int64),
                            "taper_phi": torch.tensor(0, device=device, dtype=torch.int64),
                        }
                    )
                )
                if wants_rich_inner and len(candidates) < n_candidates:
                    candidates.append(
                        InnerPatchRingBasis(
                            {
                                "center": center,
                                "R": torch.tensor(R, device=device, dtype=dtype),
                                "a": torch.tensor(a, device=device, dtype=dtype),
                                "phi0": torch.tensor(phi0, device=device, dtype=dtype),
                                "d_sigma": torch.tensor(arc_spans[0], device=device, dtype=dtype),
                                "d_phi": torch.tensor(ribbon_phi_spans[0], device=device, dtype=dtype),
                                "n_sigma": torch.tensor(5, device=device),
                                "n_phi": torch.tensor(5, device=device),
                                "offset_frac": torch.tensor(offset_frac, device=device, dtype=dtype),
                                "ring_offset_frac": torch.tensor(0.6, device=device, dtype=dtype),
                                "n_ring": torch.tensor(12, device=device),
                                "neutral_factor": torch.tensor(0.8, device=device, dtype=dtype),
                                "taper_sigma": torch.tensor(0, device=device, dtype=torch.int64),
                                "taper_phi": torch.tensor(0, device=device, dtype=torch.int64),
                            }
                        )
                    )

    if wants_point:
        remaining = max(1, n_candidates - len(candidates))
        target = max(1, remaining)
        n_ring_main = max(8, min(32, target // 2))
        n_ring_offset = max(0, min(24, target // 3))
        n_axis = max(1, min(3, target - (n_ring_main + 2 * n_ring_offset)))

        # Main ring slightly inside the tube to stay within conductor volume.
        r_main = max(1e-6, R - 0.3 * a)
        jitter = 0.1 * a
        _add_ring_points(n_ring_main, r_main, 0.0, jitter)

        # Inner/outer offset rings and z-perturbed rings to capture surface curvature.
        r_inner = max(1e-6, R - 0.6 * a)
        r_outer = max(1e-6, R + 0.6 * a)
        z_off = 0.3 * a
        _add_ring_points(n_ring_offset, r_inner, 0.0, jitter)
        _add_ring_points(n_ring_offset, r_outer, 0.0, jitter)
        _add_ring_points(max(4, n_ring_offset // 2), r_main, z_off, jitter)
        _add_ring_points(max(4, n_ring_offset // 2), r_main, -z_off, jitter)

        # Axial helpers near the torus hole / centerline to act like effective ring charges.
        if n_axis > 0:
            rho_axis = 0.25 * R
            z_positions = torch.linspace(-0.2 * a, 0.2 * a, n_axis, device=device)
            for z_val in z_positions:
                for sign in (-1.0, 1.0):
                    if len(candidates) >= n_candidates:
                        break
                    pos = torch.tensor(
                        [sign * rho_axis, 0.0, float(z_val)], device=device, dtype=dtype
                    ) + center
                    candidates.append(PointChargeBasis({"position": pos}))

    if wants_mode_cluster:
        for m in (0, 1, 2):
            candidates.append(
                ToroidalModeClusterBasis(
                    {
                        "center": center,
                        "major_radius": torch.tensor(R, device=device, dtype=dtype),
                        "minor_radius": torch.tensor(a, device=device, dtype=dtype),
                        "mode_m": torch.tensor(m, device=device, dtype=torch.int64),
                        "n_phi": torch.tensor(16, device=device, dtype=torch.int64),
                        "radial_offset": torch.tensor(0.5 * a, device=device, dtype=dtype),
                    }
                )
            )

    if len(candidates) > n_candidates:
        candidates = candidates[:n_candidates]
    return candidates


def build_dictionary(
    basis: Sequence[ImageBasisElement],
    X: torch.Tensor,
    device: str | torch.device = "cpu",
    dtype: torch.dtype = torch.float32,
) -> torch.Tensor:
    """Build a dictionary matrix Φ with columns Φ[:, k] = basis[k].potential(X).

    Parameters
    ----------
    basis:
        Sequence of image basis elements.
    X:
        [N, 3] tensor of evaluation points.
    device, dtype:
        Device and dtype for the returned matrix and the point cloud.
    """
    if not isinstance(device, torch.device):
        device = torch.device(device)

    X = X.to(device=device, dtype=dtype)
    N = X.shape[0]
    K = len(basis)

    if K == 0:
        return torch.zeros(N, 0, device=device, dtype=dtype)
    if N == 0:
        return torch.zeros(0, K, device=device, dtype=dtype)

    Phi = torch.empty(N, K, device=device, dtype=dtype)
    for k, elem in enumerate(basis):
        Phi[:, k] = elem.potential(X).to(device=device, dtype=dtype)
    return Phi

================================================================================
===== END FILE: code\basis.py =====
================================================================================

================================================================================
===== BEGIN FILE: code\bem.py =====
================================================================================

﻿from __future__ import annotations

import json
import math
import os
import sys
import time
import traceback
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional, Tuple

import torch
import numpy as np

from electrodrive.core.bem_mesh import TriMesh, generate_mesh
from electrodrive.core.bem_kernel import (
    _bem_E_field_targets_core_torch,  # differentiable E-field targets
    _bem_matvec_core_torch,  # differentiable matvec core
    _bem_potential_targets_core_torch,  # differentiable potential targets
    bem_E_field_targets,  # non-diff E-field at targets
    bem_matvec_gpu,  # non-diff matvec (no_grad, KeOps-capable)
    bem_potential_targets,  # non-diff potential at targets
)
from electrodrive.core.bem_quadrature import (
    self_integral_correction,
    near_singular_quadrature,
)

# Optional CUDA near-field extension (panel-panel / target-panel).
try:  # pragma: no cover - optional dependency
    from electrodrive.core import bem_near_cuda  # type: ignore[import]
except Exception:  # pragma: no cover - optional dependency
    bem_near_cuda = None  # type: ignore[assignment]

from electrodrive.core.bem_solver import gmres_restart
from electrodrive.utils.config import BEMConfig, K_E
from electrodrive.utils.logging import JsonlLogger
from electrodrive.orchestration.parser import CanonicalSpec
from electrodrive.debug import bem_intercept

__all__ = ["bem_solve", "BEMSolution"]


# ---------------------------------------------------------------------------
# Lazy diffbem import
# ---------------------------------------------------------------------------


def _get_diffbem_module():
    """
    Lazy import for the differentiable BEM solver.

    This avoids introducing a hard xitorch dependency for users who only
    rely on the standard non-differentiable BEM path.
    """
    try:  # pragma: no cover - import path only
        from electrodrive.core import diffbem as _diffbem  # type: ignore
        return _diffbem
    except Exception:
        return None


# ---------------------------------------------------------------------------
# Small helpers / control loop primitives
# ---------------------------------------------------------------------------


class _ControlSignal(Exception):
    """
    Sentinel exception used to abort GMRES early in response to control.json.

    This is intentionally local to bem.py and never exposed as part of the
    public API. Callers should catch it inside bem_solve and translate to a
    structured error.
    """


@dataclass
class _ControlState:
    pause: bool = False
    terminate: bool = False
    write_every: Optional[int] = None
    snapshot_marks: List[str] = field(default_factory=list)
    last_poll_ts: float = 0.0


def _safe_import_exists(mod_name: str) -> bool:
    try:
        __import__(mod_name)
        return True
    except Exception:
        return False


def _detect_backends() -> Dict[str, bool]:
    return {
        "torch": "torch" in sys.modules or _safe_import_exists("torch"),
        "keops": _safe_import_exists("pykeops") or _safe_import_exists("keopscore"),
        "cupy": _safe_import_exists("cupy"),
    }


def _has_bem_near_cuda() -> bool:
    """
    Return True if the optional bem_near_cuda extension is available.

    This helper is defensive and never raises; if the extension or its
    capability flag is missing, it simply returns False.
    """
    global bem_near_cuda
    if bem_near_cuda is None:
        return False
    try:
        # Prefer the explicit availability checker if present.
        fn = getattr(bem_near_cuda, "is_bem_near_cuda_available", None)
        if callable(fn):
            return bool(fn())
        # Backwards-compatible fallbacks.
        legacy_fn = getattr(bem_near_cuda, "has_bem_near_cuda", None)
        if callable(legacy_fn):
            return bool(legacy_fn())
        flag = getattr(bem_near_cuda, "HAS_BEM_NEAR_CUDA", None)
        if flag is not None:
            return bool(flag)
        # If the module imported successfully and exposes neither helper,
        # assume it is usable.
        return True
    except Exception:
        return False


def _get_run_dir_from_env_or_cfg(cfg: BEMConfig) -> Optional[Path]:
    """
    Determine run directory for control/manifest/metrics integration.

    Preference:
    - cfg.run_dir if present and non-empty.
    - env EDE_RUN_DIR if set.
    """
    run_dir_val = getattr(cfg, "run_dir", None)
    if isinstance(run_dir_val, (str, os.PathLike)) and str(run_dir_val).strip():
        p = Path(run_dir_val).expanduser()
        try:
            p.mkdir(parents=True, exist_ok=True)
            return p
        except Exception:
            return None

    env_val = os.getenv("EDE_RUN_DIR", "").strip()
    if env_val:
        p = Path(env_val).expanduser()
        try:
            p.mkdir(parents=True, exist_ok=True)
            return p
        except Exception:
            return None
    return None


def _atomic_write_json(path: Path, payload: Dict[str, Any]) -> None:
    """
    Atomically write JSON to path (tmp + replace + fsync).

    Cross-platform safe; never raises to caller (best-effort).
    """
    try:
        path.parent.mkdir(parents=True, exist_ok=True)
        tmp = path.with_suffix(path.suffix + ".tmp")
        with tmp.open("w", encoding="utf-8") as f:
            json.dump(payload, f, indent=2)
            f.flush()
            try:
                os.fsync(f.fileno())
            except Exception:
                pass
        os.replace(tmp, path)
    except Exception:
        # Best-effort; do not crash solver on logging failures.
        pass


def _poll_control_file(
    run_dir: Optional[Path],
    state: _ControlState,
    logger: Optional[JsonlLogger],
    *,
    max_hz: float = 4.0,
) -> None:
    """
    Poll control.json (if present) at most max_hz for pause/terminate/write_every.

    This function:
    - Updates state.pause / state.terminate / state.write_every.
    - Appends any snapshot marks to state.snapshot_marks.
    - Implements a bounded wait loop for pause, with small sleeps (no busy spin).
    """
    if run_dir is None:
        return

    now = time.time()
    min_dt = 1.0 / max_hz
    if now - state.last_poll_ts < min_dt:
        return
    state.last_poll_ts = now

    path = run_dir / "control.json"
    if not path.is_file():
        return

    try:
        with path.open("r", encoding="utf-8") as f:
            obj = json.load(f)
    except Exception:
        return

    if not isinstance(obj, dict):
        return

    pause = bool(obj.get("pause", False))
    terminate = bool(obj.get("terminate", False))
    write_every = obj.get("write_every", None)

    if isinstance(write_every, int) and write_every > 0:
        state.write_every = write_every
    elif write_every is None:
        # leave unchanged
        pass

    snapshot = obj.get("snapshot", None)
    if isinstance(snapshot, str) and snapshot:
        state.snapshot_marks.append(snapshot)

    if pause and not state.pause and logger:
        logger.info("Control: entering pause state.")
    if not pause and state.pause and logger:
        logger.info("Control: resuming from pause state.")
    state.pause = pause

    if terminate and not state.terminate and logger:
        logger.warning("Control: terminate requested; will abort solve.")
    state.terminate = terminate

    # Handle blocking pause (bounded; no busy loop).
    if state.pause and not state.terminate:
        if logger:
            logger.info("Control: paused. Waiting until pause=false or terminate=true.")
        max_wait = 3600.0  # 1 hour safety cap
        t0 = time.time()
        while True:
            if state.terminate:
                break
            if time.time() - t0 > max_wait:
                if logger:
                    logger.warning(
                        "Control: pause exceeded max_wait; auto-resuming.",
                        max_wait=max_wait,
                    )
                state.pause = False
                break
            time.sleep(0.25)
            _poll_control_file(run_dir, state, logger, max_hz=max_hz)
            if not state.pause:
                break


def _init_device(cfg: BEMConfig) -> torch.device:
    if getattr(cfg, "use_gpu", False) and torch.cuda.is_available():
        return torch.device("cuda")
    return torch.device("cpu")


def _free_space_at_points(
    spec: CanonicalSpec,
    P: torch.Tensor,
    dtype: torch.dtype,
    device: torch.device,
) -> torch.Tensor:
    """
    Free-space potential from explicit point charges at points P[N,3].

    V_free(x) = sum_k K_E * q_k / |x - r_k|
    """
    if P.numel() == 0:
        return torch.zeros(0, device=device, dtype=dtype)

    V = torch.zeros(P.shape[0], device=device, dtype=dtype)
    for ch in spec.charges:
        if ch.get("type") != "point":
            continue
        try:
            q = torch.as_tensor(float(ch["q"]), device=device, dtype=dtype)
            pos = torch.as_tensor(
                [float(x) for x in ch["pos"]],
                device=device,
                dtype=dtype,
            )
        except Exception:
            continue
        r = torch.linalg.norm(P - pos[None, :], dim=1).clamp_min(1e-12)
        V = V + (K_E * q) / r
    return V


def _free_space_potential_on_centroids(
    spec: CanonicalSpec,
    centroids: torch.Tensor,
) -> torch.Tensor:
    """
    Convenience wrapper: free-space potential evaluated at panel centroids.

    This uses the same point-charge model as `_free_space_at_points`.
    """
    return _free_space_at_points(
        spec=spec,
        P=centroids,
        dtype=centroids.dtype,
        device=centroids.device,
    )


def _free_space_E_field_at_points(
    spec: CanonicalSpec,
    P: torch.Tensor,
    dtype: torch.dtype,
    device: torch.device,
) -> torch.Tensor:
    """
    Free-space E-field from explicit point charges at points P[N,3].

    E_free(x) = sum_k K_E * q_k (x - r_k) / |x - r_k|^3
    """
    if P.numel() == 0:
        return torch.zeros(0, 3, device=device, dtype=dtype)

    E = torch.zeros(P.shape[0], 3, device=device, dtype=dtype)
    for ch in spec.charges:
        if ch.get("type") != "point":
            continue
        try:
            q = torch.as_tensor(float(ch["q"]), device=device, dtype=dtype)
            pos = torch.as_tensor(
                [float(x) for x in ch["pos"]],
                device=device,
                dtype=dtype,
            )
        except Exception:
            continue
        R = P - pos[None, :]
        r = torch.linalg.norm(R, dim=1, keepdim=True).clamp_min(1e-12)
        E = E + (K_E * q) * R / (r**3)
    return E


def _bc_vector(
    spec: CanonicalSpec,
    mesh: TriMesh,
    device: torch.device,
    dtype: torch.dtype,
) -> torch.Tensor:
    """
    Construct per-panel Dirichlet BC values (V on conductor surfaces).

    Each panel inherits the potential of its owning conductor. Panels whose
    conductor has no explicit 'potential' field default to 0.0 (grounded).
    """
    # Default: all panels grounded
    bc = torch.zeros(mesh.n_panels, device=device, dtype=dtype)

    # Map conductor ID -> potential
    id_to_V: Dict[int, float] = {}
    for i, c in enumerate(getattr(spec, "conductors", []) or []):
        try:
            V = float(c.get("potential", 0.0))
        except Exception:
            V = 0.0
        # Some specs may carry an explicit "id"; otherwise fall back to index.
        cid = int(c.get("id", i))
        id_to_V[cid] = V

    # mesh.conductor_ids is length n_panels; panels with unknown IDs get 0.0
    for i, cid in enumerate(mesh.conductor_ids):
        bc[i] = id_to_V.get(int(cid), 0.0)

    return bc


def _offset_from_boundary(
    spec: Optional[CanonicalSpec],
    P: torch.Tensor,
    areas: torch.Tensor,
    centroids: torch.Tensor,
    dtype: torch.dtype,
    device: torch.device,
    sign: float = 1.0,
) -> torch.Tensor:
    """
    Slightly nudge points that lie exactly on idealized boundaries (plane/sphere)
    to avoid numerical coincidences when evaluating induced fields.

    Only applied to evaluation points; does not affect the solved system.
    """
    if P.numel() == 0:
        return P

    P2 = P.clone()

    if areas.numel() > 0:
        try:
            req = float(
                torch.median(
                    torch.sqrt(areas.clamp_min(1e-30) / math.pi)
                ).item()
            )
        except Exception:
            req = 1e-3
    else:
        req = 1e-3

    delta = torch.as_tensor(sign * 1e-6 * req, device=device, dtype=dtype)

    if spec is None:
        return P2

    for c in spec.conductors:
        t = c.get("type")
        if t == "plane":
            z0 = float(c.get("z", 0.0))
            mask = torch.abs(P2[:, 2] - z0) < 10.0 * torch.finfo(dtype).eps
            if mask.any():
                P2[mask, 2] = z0 + delta
        elif t == "sphere":
            try:
                center = torch.as_tensor(
                    [float(x) for x in c.get("center", [0.0, 0.0, 0.0])],
                    device=device,
                    dtype=dtype,
                )
                a = float(c.get("radius", 1.0))
            except Exception:
                continue
            r = torch.linalg.norm(P2 - center[None, :], dim=1)
            mask = (
                torch.abs(r - a)
                < 10.0 * torch.finfo(dtype).eps * max(1.0, a)
            )
            if torch.any(mask):
                v = P2[mask] - center[None, :]
                v = v / torch.linalg.norm(v, dim=1, keepdim=True).clamp_min(1e-24)
                P2[mask] = center[None, :] + (a + float(delta)) * v

    return P2


def _build_near_pairs_for_panels(
    centroids_np: np.ndarray,
    areas_np: np.ndarray,
    distance_factor: float,
    n_panels: Optional[int] = None,
) -> np.ndarray:
    """
    Construct a list of (i, j) indices for panel–panel interactions that are
    considered "near" based on centroid distance and panel radii.

    Panels i and j are marked near if

        |C_i - C_j| <= distance_factor * (R_i + R_j),

    where R_k = sqrt(A_k / pi) is the equal-area disk radius associated with
    panel k. Self-interactions (i == j) are excluded; they are handled by
    `self_integral_correction`.

    Returns
    -------
    near_pairs : ndarray, shape (P, 2)
        Possibly empty array of (i, j) index pairs.
    """
    # Normalise inputs
    C_full = np.asarray(centroids_np, dtype=float)
    A_full = np.asarray(areas_np, dtype=float).reshape(-1)

    N_C = int(C_full.shape[0])
    N_A = int(A_full.shape[0])

    if n_panels is not None:
        N = max(0, min(int(n_panels), N_C, N_A))
    else:
        N = max(0, min(N_C, N_A))

    if N <= 1:
        return np.zeros((0, 2), dtype=np.int64)

    # Truncate to the common prefix to avoid any shape mismatch surprises.
    C = C_full[:N]
    A = A_full[:N]

    # Equal-area disk radii R = sqrt(A/pi), clipping to avoid negatives
    A_clipped = np.clip(A, 0.0, np.inf)
    radii = np.sqrt(A_clipped / math.pi)

    df = float(distance_factor)

    # Collect near pairs incrementally to avoid dense N×N allocations.
    pairs_i: List[np.ndarray] = []
    pairs_j: List[np.ndarray] = []

    for i in range(N):
        # Distances from panel i to all panels.
        diff = C[i] - C  # (N, 3)
        dists = np.linalg.norm(diff, axis=1)  # (N,)

        # Pair-dependent near threshold: df * (R_i + R_j).
        thresh_i = df * (radii[i] + radii)  # (N,)

        # Robustness: ignore any non-finite distances/thresholds.
        mask = (
            np.isfinite(dists)
            & np.isfinite(thresh_i)
            & (dists > 0.0)
            & (dists <= thresh_i)
        )

        js = np.nonzero(mask)[0]
        if js.size == 0:
            continue

        pairs_i.append(np.full(js.shape, i, dtype=np.int64))
        pairs_j.append(js.astype(np.int64))

    if not pairs_i:
        return np.zeros((0, 2), dtype=np.int64)

    i_idx = np.concatenate(pairs_i, axis=0)
    j_idx = np.concatenate(pairs_j, axis=0)
    return np.stack([i_idx, j_idx], axis=1)


def _precompute_near_correction_weights(
    centroids: np.ndarray,
    areas: np.ndarray,
    panel_vertices: np.ndarray,
    near_pairs: np.ndarray,
    quad_order: int,
) -> np.ndarray:
    """
    Precompute geometry-only near-field correction weights for panel pairs.

    For each (i, j) in near_pairs, this computes the scalar delta

        delta_ij = I_near(C_i, panel_j) - K_E * A_j / |C_i - C_j|,

    where I_near is evaluated using near_singular_quadrature.  These
    deltas depend only on geometry and quadrature order, not on sigma,
    so they can be reused across GMRES iterations.
    """
    if near_pairs.size == 0:
        return np.zeros((0,), dtype=float)

    C_np = np.asarray(centroids, dtype=float)
    A_np = np.asarray(areas, dtype=float).reshape(-1)
    verts_np = np.asarray(panel_vertices, dtype=float)

    N_panels = min(int(C_np.shape[0]), int(A_np.shape[0]), int(verts_np.shape[0]))
    if N_panels <= 0:
        return np.zeros((near_pairs.shape[0],), dtype=float)

    weights = np.zeros((near_pairs.shape[0],), dtype=float)

    for idx_pair, (idx_i_raw, idx_j_raw) in enumerate(near_pairs):
        idx_i = int(idx_i_raw)
        idx_j = int(idx_j_raw)

        if not (0 <= idx_i < N_panels) or not (0 <= idx_j < N_panels):
            continue

        Aj = float(A_np[idx_j])
        if Aj <= 0.0:
            continue

        target = C_np[idx_i]
        verts_j = verts_np[idx_j]

        pts, w = near_singular_quadrature(
            target=target,
            panel_vertices=verts_j,
            method="telles",
            order=quad_order,
        )
        if w.size == 0:
            continue

        r = np.linalg.norm(pts - target[None, :], axis=1)
        r = np.maximum(r, 1e-12)
        kernel_vals = K_E / r
        I_near = float(np.sum(kernel_vals * w))

        r_far = np.linalg.norm(target - C_np[idx_j])
        if r_far < 1e-12:
            continue
        I_far = float(K_E * Aj / r_far)

        weights[idx_pair] = I_near - I_far

    return weights


def _apply_near_quadrature_matvec(
    V_far: torch.Tensor,
    sigma: torch.Tensor,
    *,
    centroids: torch.Tensor,
    areas: torch.Tensor,
    panel_vertices: np.ndarray,
    near_pairs: np.ndarray,
    quad_order: int,
    near_pair_weights: Optional[np.ndarray] = None,
) -> torch.Tensor:
    """
    Apply a near-field quadrature correction to a matrix-vector product V_far.

    This function assumes:
      - centroids, areas, sigma, and V_far are Tensors (CPU or GPU).
      - panel_vertices and near_pairs are numpy arrays built from TriMesh.

    The correction replaces the point-lumped approximation

        K_E * A_j / |C_i - C_j|

    with a quadrature-based estimate of the integral

        ∫_panel_j K_E / |C_i - y| dS_y

    for all (i, j) listed in near_pairs.
    """
    if near_pairs.size == 0:
        return V_far

    device = V_far.device
    dtype = V_far.dtype

    V_np = V_far.detach().cpu().numpy()
    sigma_np = sigma.detach().cpu().numpy()
    C_np = centroids.detach().cpu().numpy()
    A_np = areas.detach().cpu().numpy()

    # Guard against any shape mismatches: work with the common prefix length.
    N_V = int(V_np.shape[0])
    N_C = int(C_np.shape[0])
    N_A = int(A_np.shape[0])
    N_panels = min(N_V, N_C, N_A, int(panel_vertices.shape[0]))

    if N_panels <= 0:
        return V_far

    weights_np: Optional[np.ndarray] = None
    if near_pair_weights is not None:
        weights_np = np.asarray(near_pair_weights, dtype=float).reshape(-1)
        if weights_np.shape[0] != near_pairs.shape[0]:
            weights_np = None

    from electrodrive.utils.config import K_E  # local import to avoid cycles

    for pair_idx, (idx_i_raw, idx_j_raw) in enumerate(near_pairs):
        idx_i = int(idx_i_raw)
        idx_j = int(idx_j_raw)

        # Robust index bounds check: skip any out-of-range pairs.
        if not (0 <= idx_i < N_panels):
            continue
        if not (0 <= idx_j < N_panels):
            continue

        Aj = float(A_np[idx_j])
        sig_j = float(sigma_np[idx_j])
        if Aj <= 0.0 or sig_j == 0.0:
            continue

        target = C_np[idx_i]
        verts_j = panel_vertices[idx_j]

        delta = None
        if weights_np is not None and pair_idx < weights_np.shape[0]:
            delta = float(weights_np[pair_idx])
            if not math.isfinite(delta):
                delta = None

        if delta is None:
            pts, w = near_singular_quadrature(
                target=target,
                panel_vertices=verts_j,
                method="telles",
                order=quad_order,
            )
            if w.size == 0:
                continue

            r = np.linalg.norm(pts - target[None, :], axis=1)
            r = np.maximum(r, 1e-12)
            kernel_vals = K_E / r
            I_near = float(np.sum(kernel_vals * w))

            r_far = np.linalg.norm(target - C_np[idx_j])
            if r_far < 1e-12:
                # Diagonal terms rely on self_integral_correction instead.
                continue
            I_far = float(K_E * Aj / r_far)
            delta = I_near - I_far

        if delta == 0.0:
            continue

        V_np[idx_i] += sig_j * delta

    return torch.as_tensor(V_np, device=device, dtype=dtype)


def _apply_near_quadrature_matvec_cuda(
    V_far: torch.Tensor,
    sigma: torch.Tensor,
    *,
    centroids: torch.Tensor,
    areas: torch.Tensor,
    panel_vertices: torch.Tensor,
    near_pairs: torch.Tensor,
    quad_order: int,
    panel_vertices_np: Optional[np.ndarray] = None,
    near_pairs_np: Optional[np.ndarray] = None,
    near_pair_weights_np: Optional[np.ndarray] = None,
) -> torch.Tensor:
    """
    CUDA-accelerated near-field quadrature correction to a matrix-vector
    product V_far.

    This wrapper expects all tensor arguments to reside on the same CUDA
    device. It delegates the heavy lifting to the optional
    `electrodrive.core.bem_near_cuda` extension when available and
    falls back to the CPU implementation `_apply_near_quadrature_matvec`
    when needed.

    Parameters are analogous to `_apply_near_quadrature_matvec`, except
    that `panel_vertices` and `near_pairs` are Tensors.
    """
    # Nothing to do if there are no near interactions.
    if near_pairs is None or near_pairs.numel() == 0:
        return V_far

    device = V_far.device
    if device.type != "cuda":
        # Not on CUDA; fall back to the CPU helper if we have NumPy arrays.
        if panel_vertices_np is not None and near_pairs_np is not None:
            return _apply_near_quadrature_matvec(
                V_far,
                sigma,
                centroids=centroids,
                areas=areas,
                panel_vertices=panel_vertices_np,
                near_pairs=near_pairs_np,
                quad_order=quad_order,
                near_pair_weights=near_pair_weights_np,
            )
        return V_far

    if not _has_bem_near_cuda():
        if panel_vertices_np is not None and near_pairs_np is not None:
            return _apply_near_quadrature_matvec(
                V_far,
                sigma,
                centroids=centroids,
                areas=areas,
                panel_vertices=panel_vertices_np,
                near_pairs=near_pairs_np,
                quad_order=quad_order,
                near_pair_weights=near_pair_weights_np,
            )
        return V_far

    try:
        # Delegate to the high-level CUDA wrapper, which normalises inputs
        # and calls the compiled extension.
        return bem_near_cuda.apply_near_quadrature_matvec_cuda(  # type: ignore[attr-defined]
            V_far,
            sigma,
            centroids=centroids,
            areas=areas,
            panel_vertices=panel_vertices,
            near_pairs=near_pairs,
            quad_order=quad_order,
            K_E=None,
        )
    except Exception:
        # Graceful fallback to CPU helper if we can.
        if panel_vertices_np is not None and near_pairs_np is not None:
            return _apply_near_quadrature_matvec(
                V_far,
                sigma,
                centroids=centroids,
                areas=areas,
                panel_vertices=panel_vertices_np,
                near_pairs=near_pairs_np,
                quad_order=quad_order,
            )
        return V_far


def _apply_near_quadrature_potentials(
    V_far: torch.Tensor,
    targets: torch.Tensor,
    centroids: torch.Tensor,
    areas: torch.Tensor,
    sigma: torch.Tensor,
    panel_vertices: torch.Tensor,
    *,
    distance_factor: float,
    quad_order: int,
) -> torch.Tensor:
    """
    Near-field quadrature correction for potentials at arbitrary targets.

    Parameters
    ----------
    V_far : (M,) tensor
        Potential computed via centroid-lumped kernel.
    targets : (M,3) tensor
        Evaluation points.
    centroids : (N,3) tensor
    areas : (N,) tensor
    sigma : (N,) tensor
    panel_vertices : (N,3,3) tensor

    Returns
    -------
    V_corr : (M,) tensor
        Corrected potential (same shape as V_far).
    """
    if targets.numel() == 0 or sigma.numel() == 0:
        return V_far

    device = V_far.device
    dtype = V_far.dtype

    # Work in NumPy on CPU to mesh naturally with TriMesh-style arrays.
    V_np = V_far.detach().cpu().numpy()
    T_np = targets.detach().cpu().numpy()
    C_np = centroids.detach().cpu().numpy()
    A_np = areas.detach().cpu().numpy()
    sigma_np = sigma.detach().cpu().numpy()
    panel_vertices_np = panel_vertices.detach().cpu().numpy()

    areas_clipped = np.clip(A_np, 0.0, np.inf)
    radii = np.sqrt(areas_clipped / math.pi)

    from electrodrive.utils.config import K_E  # local import to avoid cycles

    M = int(T_np.shape[0])
    N = int(C_np.shape[0])
    if N == 0:
        return V_far

    for i in range(M):
        x = T_np[i]
        dists = np.linalg.norm(C_np - x[None, :], axis=1)
        # Panels whose centroid is within distance_factor * R_j are treated
        # with the refined rule.
        thresh = distance_factor * radii
        near_idx = np.nonzero(dists <= thresh)[0]
        if near_idx.size == 0:
            continue

        for j in near_idx:
            Aj = float(A_np[j])
            sig_j = float(sigma_np[j])
            if Aj <= 0.0 or sig_j == 0.0:
                continue

            verts_j = panel_vertices_np[j]
            pts, w = near_singular_quadrature(
                target=x, panel_vertices=verts_j, method="telles", order=quad_order
            )
            if w.size == 0:
                continue

            r = np.linalg.norm(pts - x[None, :], axis=1)
            r = np.maximum(r, 1e-12)
            kernel_vals = K_E / r
            I_near = float(np.sum(kernel_vals * w))

            r_far = dists[j]
            if r_far < 1e-12:
                continue
            I_far = float(K_E * Aj / r_far)

            V_np[i] += sig_j * (I_near - I_far)

    return torch.as_tensor(V_np, device=device, dtype=dtype)


def _autotune_tile_size(
    N: int,
    dtype: torch.dtype,
    device: torch.device,
    logger: JsonlLogger,
    target_vram_fraction: float = 0.8,
    max_vram_gb: float = 24.0,
    *,
    min_tile: int = 512,
    max_tile: Optional[int] = None,
    target_peak_gb: Optional[float] = None,
    tile_mem_divisor: float = 3.0,
) -> int:
    """
    Choose a safe tile size for kernels under a VRAM budget.

    The goal here is robustness first:
    - stay well inside the available VRAM envelope
    - respect dtype differences (fp64 is more expensive than fp32)
    - avoid overly large tiles on CPU-only runs
    """
    # CPU / no-CUDA path: pick a conservative power-of-two tile size.
    if device.type != "cuda" or N <= 0 or not torch.cuda.is_available():
        if N <= 0:
            return min_tile
        # cap at 2048 by default on CPU to avoid blowing caches
        T = min(N, max(min_tile, 2048))
        # round down to power of two
        T = 2 ** int(math.log2(max(1, T)))
        return int(T)

    try:
        total_vram = torch.cuda.get_device_properties(device).total_memory
    except Exception:
        logger.warning(
            "Could not query total VRAM. Falling back to configured cap.",
            max_vram_gb=max_vram_gb,
        )
        total_vram = max_vram_gb * (1024**3)

    available = total_vram * float(target_vram_fraction)
    bytes_per = torch.finfo(dtype).bits // 8

    # Vector/state memory we expect to keep around during the solve
    vector_mem = N * 10 * bytes_per

    divisor = float(tile_mem_divisor) if tile_mem_divisor and tile_mem_divisor > 0 else 3.0
    memory_for_tiling = max(0.0, available - vector_mem) / divisor

    # Rough model: kernel needs ~4 * bytes_per * T^2
    T = int(math.sqrt(max(1.0, memory_for_tiling / (4 * bytes_per))))
    T = min(N, max(min_tile, T))

    if T > 0:
        # snap to power of two for better kernel behavior
        T = 2 ** int(math.log2(T))
    else:
        T = min_tile

    # Optional: if caller provides a stricter peak budget, respect it by
    # shrinking the tile size (never enlarging it).
    try:
        total_gb = total_vram / (1024**3)
        if target_peak_gb and target_peak_gb > 0:
            budget_gb = min(target_peak_gb, total_gb * float(target_vram_fraction))
            mem_bytes = budget_gb * (1024**3)
            mem_for_tiles = max(0.0, mem_bytes - vector_mem) / 3.0
            T2 = int(math.sqrt(max(1.0, mem_for_tiles / (4 * bytes_per))))
            T2 = min(N, max(min_tile, T2))
            if T2 > 0:
                T2 = 2 ** int(math.log2(T2))
            else:
                T2 = min_tile
            # Never exceed the original T when honoring a stricter peak budget.
            T = min(T, T2)
    except Exception:
        pass

    # Apply caller-provided max_tile clamp if present.
    if max_tile is not None:
        T = min(T, max_tile)

    # Dtype-aware hard caps as an additional safety net.
    try:
        if dtype == torch.float64:
            # fp64 is expensive; keep tiles moderate
            T = min(T, 4096)
        else:
            # fp32 can tolerate somewhat larger tiles
            T = min(T, 8192)
    except Exception:
        # If anything goes wrong, just leave T as-is.
        pass

    logger.info(
        "VRAM autotune result.",
        tile_size=int(T),
        N_dof=int(N),
        dtype=str(dtype),
        divisor=float(divisor),
        total_vram_gb=f"{total_vram / (1024 ** 3):.2f}",
    )

    return int(T)


def _jacobi_fallback_solve(
    A: Callable[[torch.Tensor], torch.Tensor],
    b: torch.Tensor,
    diag: torch.Tensor,
    logger: JsonlLogger,
    *,
    maxiter: int = 1024,
    tol: float = 1e-6,
    omega: float = 0.8,
) -> Tuple[torch.Tensor, Dict[str, Any]]:
    """
    Very simple damped Jacobi fallback solver for Ax = b.

    Returns (x, stats) with similar 'info' shape to gmres_restart.
    """
    x = torch.zeros_like(b)
    Dinv = 1.0 / diag.clamp_min(1e-18)

    with torch.no_grad():
        r = b - A(x)
        r_norm0 = float(torch.linalg.norm(r))

        if not math.isfinite(r_norm0):
            logger.error(
                "Jacobi fallback: initial residual is non-finite.",
                r0=r_norm0,
            )
            return x, {
                "iters": 0,
                "resid": r_norm0,
                "success": False,
                "solver": "jacobi_fallback",
            }

        target = tol * max(r_norm0, 1.0)
        logger.warning(
            "Jacobi fallback: starting iterative solve.",
            r0=r_norm0,
            tol=tol,
            target=target,
            maxiter=maxiter,
        )

        it = 0
        for k in range(maxiter):
            it = k + 1
            x = x + omega * Dinv * r
            r = b - A(x)
            r_norm = float(torch.linalg.norm(r))

            if not math.isfinite(r_norm):
                logger.error(
                    "Jacobi fallback: residual became non-finite.",
                    iter=it,
                    resid=r_norm,
                )
                return x, {
                    "iters": it,
                    "resid": r_norm,
                    "success": False,
                    "solver": "jacobi_fallback",
                }

            if k == 0 or (k + 1) % 25 == 0:
                logger.info(
                    "Jacobi fallback iter.",
                    iter=it,
                    resid=r_norm,
                )

            if r_norm <= target:
                logger.info(
                    "Jacobi fallback converged.",
                    iters=it,
                    resid=r_norm,
                    target=target,
                )
                return x, {
                    "iters": it,
                    "resid": r_norm,
                    "success": True,
                    "solver": "jacobi_fallback",
                }

        logger.warning(
            "Jacobi fallback reached maxiter without convergence.",
            iters=it,
            resid=r_norm,
            target=target,
        )
        return x, {
            "iters": it,
            "resid": r_norm,
            "success": False,
            "solver": "jacobi_fallback",
        }


def compute_bem_capacitive_energy(
    V_total: torch.Tensor,
    sigma: torch.Tensor,
    areas: torch.Tensor,
) -> float:
    """
    Capacitive energy from boundary data (Route A variant):

        U = 1/2 * ∫ (V * sigma) dS  ≈ 0.5 * sum_i V_i * sigma_i * A_i

    For numerical robustness, accumulation is always carried out in float64,
    even if the main solve ran in float32.
    """
    try:
        V64 = V_total.to(torch.float64)
        s64 = sigma.to(torch.float64)
        a64 = areas.to(torch.float64)
        energy = 0.5 * torch.sum(V64 * s64 * a64)
        return float(energy.item())
    except Exception:
        return float("nan")


def _sample_gpu_peak_mb() -> Dict[str, float]:
    """
    Return current peak GPU memory usage in MB.
    """
    if not torch.cuda.is_available():
        return {"allocated": 0.0, "reserved": 0.0}
    try:
        dev = torch.cuda.current_device()
        torch.cuda.synchronize(dev)
        max_alloc = float(torch.cuda.max_memory_allocated(dev))
        max_res = float(torch.cuda.max_memory_reserved(dev))
        return {
            "allocated": max_alloc / (1024.0 * 1024.0),
            "reserved": max_res / (1024.0 * 1024.0),
        }
    except Exception:
        return {"allocated": 0.0, "reserved": 0.0}


def _write_manifest(
    run_dir: Optional[Path],
    *,
    run_id: str,
    device: torch.device,
    dtype: torch.dtype,
    requested_mode: str,
    selected_mode: str,
    planner_rationale: str = "",
    fallback_reason: Optional[str] = None,
) -> None:
    """
    Best-effort manifest.json writer for BEM runs.
    """
    if run_dir is None:
        return

    backends = _detect_backends()
    gpu_peak = _sample_gpu_peak_mb()

    tf32_enabled = False
    try:
        if hasattr(torch, "get_float32_matmul_precision"):
            tf32_mode = str(torch.get_float32_matmul_precision())
            tf32_enabled = tf32_mode.lower() in ("high", "highest", "medium")
    except Exception:
        tf32_enabled = False

    device_name = "cpu"
    gpu_available = bool(device.type == "cuda" and torch.cuda.is_available())
    if gpu_available:
        try:
            props = torch.cuda.get_device_properties(device)
            device_name = props.name
        except Exception:
            device_name = "unknown"

    manifest: Dict[str, Any] = {
        "run_id": run_id,
        "git_sha": os.getenv("EDE_GIT_SHA", ""),
        "versions": {
            "python": sys.version,
            "torch": getattr(torch, "__version__", "unavailable"),
        },
        "planner": {
            "requested_mode": requested_mode,
            "selected_mode": selected_mode,
            "rationale": planner_rationale,
        },
        "device": {
            "gpu_available": gpu_available,
            "device_name": device_name,
            "dtype": str(dtype),
            "tf32": tf32_enabled,
            "gpu_mem_peak_mb": gpu_peak,
        },
        "backend": {
            "available": backends,
            "selected": "torch",
            "fallback_reason": fallback_reason,
        },
    }

    _atomic_write_json(run_dir / "manifest.json", manifest)


# ---------------------------------------------------------------------------
# BEMSolution: evaluation wrapper
# ---------------------------------------------------------------------------


class BEMSolution:
    """
    Simple evaluator wrapping the solved boundary data.

    Provides:
    - eval(p: (x,y,z)) -> float potential
    - eval_V_E_batched(P: [N,3]) -> (V[N], E[N,3])

    When constructed with differentiable=True, eval_V_E_batched uses
    differentiable kernel cores so that gradients can flow back to sigma.
    """

    def __init__(
        self,
        spec: CanonicalSpec,
        centroids: torch.Tensor,
        areas: torch.Tensor,
        sigma: torch.Tensor,
        device: torch.device,
        dtype: torch.dtype,
        tile_size: int,
        normals: Optional[torch.Tensor] = None,
        differentiable: bool = False,
        panel_vertices: Optional[torch.Tensor] = None,
        near_quadrature: bool = False,
        near_quad_order: int = 2,
        near_quad_dist_factor: float = 1.5,
    ):
        self._spec = spec
        self._C = centroids
        self._A = areas
        self._N = normals
        self._S = sigma
        self._device = device
        self._dtype = dtype
        self._tile = tile_size
        self._differentiable = bool(differentiable)
        self._panel_vertices = panel_vertices
        # Near-field quadrature is implemented for the non-differentiable
        # evaluation path. The correction kernels themselves run on CPU but
        # accept inputs from either CPU or GPU and return results on the
        # original device.
        self._near_quad_enabled = bool(
            near_quadrature
            and (panel_vertices is not None)
            and not self._differentiable
        )
        self._near_quad_order = int(near_quad_order)
        self._near_quad_dist_factor = float(near_quad_dist_factor)
        self.meta: Dict[str, Any] = {}

    def _eval_at_points(
        self,
        P: torch.Tensor,
        compute_V: bool,
        compute_E: bool,
    ) -> Tuple[Optional[torch.Tensor], Optional[torch.Tensor]]:
        P = P.to(device=self._device, dtype=self._dtype)

        P_shift = _offset_from_boundary(
            self._spec,
            P,
            self._A,
            self._C,
            self._dtype,
            self._device,
        )

        V_total: Optional[torch.Tensor] = None
        E_total: Optional[torch.Tensor] = None

        if compute_V:
            V_free = _free_space_at_points(
                self._spec, P_shift, self._dtype, self._device
            )
            if self._differentiable:
                V_ind = _bem_potential_targets_core_torch(
                    targets=P_shift,
                    src_centroids=self._C,
                    areas=self._A,
                    sigma=self._S,
                    tile_size=self._tile,
                )
            else:
                V_ind = bem_potential_targets(
                    targets=P_shift,
                    src_centroids=self._C,
                    areas=self._A,
                    sigma=self._S,
                    tile_size=self._tile,
                )
                if (
                    self._near_quad_enabled
                    and self._panel_vertices is not None
                    and self._panel_vertices.numel() > 0
                ):
                    V_ind = _apply_near_quadrature_potentials(
                        V_ind,
                        targets=P_shift,
                        centroids=self._C,
                        areas=self._A,
                        sigma=self._S,
                        panel_vertices=self._panel_vertices,
                        distance_factor=self._near_quad_dist_factor,
                        quad_order=self._near_quad_order,
                    )
            V_total = V_free + V_ind

        if compute_E:
            E_free = _free_space_E_field_at_points(
                self._spec, P_shift, self._dtype, self._device
            )
            if self._differentiable:
                E_ind = _bem_E_field_targets_core_torch(
                    targets=P_shift,
                    src_centroids=self._C,
                    areas=self._A,
                    sigma=self._S,
                    tile_size=self._tile,
                )
            else:
                E_ind = bem_E_field_targets(
                    targets=P_shift,
                    src_centroids=self._C,
                    areas=self._A,
                    sigma=self._S,
                    tile_size=self._tile,
                )
            E_total = E_free + E_ind

        return V_total, E_total

    def eval(self, p: Tuple[float, float, float]) -> float:
        P = torch.tensor(
            [[float(p[0]), float(p[1]), float(p[2])]],
            device=self._device,
            dtype=self._dtype,
        )
        V, _ = self._eval_at_points(P, compute_V=True, compute_E=False)
        return float(V[0].item() if V is not None and V.numel() > 0 else 0.0)

    def eval_V_E_batched(
        self,
        P: torch.Tensor,
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        V, E = self._eval_at_points(P, compute_V=True, compute_E=True)
        if V is None:
            V = torch.empty(0, device=self._device, dtype=self._dtype)
        if E is None:
            E = torch.empty(0, 3, device=self._device, dtype=self._dtype)
        return V, E


# ---------------------------------------------------------------------------
# Main solver
# ---------------------------------------------------------------------------


def bem_solve(
    spec: CanonicalSpec,
    cfg: BEMConfig,
    logger: JsonlLogger,
    differentiable: bool = False,
) -> Dict[str, Any]:
    """
    Single-layer BEM for Dirichlet problems with explicit point charges.

    Returns either a rich dict with a BEMSolution, or {"error": "..."}.
    """
    device = _init_device(cfg)
    dtype: torch.dtype = torch.float64 if getattr(cfg, "fp64", False) else torch.float32

    run_dir = _get_run_dir_from_env_or_cfg(cfg)
    run_id = os.getenv("EDE_RUN_ID", "") or f"bem-{int(time.time())}"

    logger.info(
        "BEM solver start.",
        device=str(device),
        fp64=bool(getattr(cfg, "fp64", False)),
        max_refine_passes=getattr(cfg, "max_refine_passes", 3),
        differentiable=bool(differentiable),
        run_id=run_id,
    )

    intercept_ctx = bem_intercept.maybe_start_intercept(
        spec, test_name="bem_solve", bem_cfg=cfg
    )
    stop_reason = "unset"

    control = _ControlState()

    if device.type == "cuda" and torch.cuda.is_available():
        try:
            torch.cuda.reset_peak_memory_stats(device)
        except Exception:
            pass

    current_h = float(getattr(cfg, "initial_h", 0.3))
    refine_factor = float(getattr(cfg, "refine_factor", 0.5))
    target_bc = float(getattr(cfg, "target_bc_inf_norm", 1e-7))

    history: List[Dict[str, Any]] = []
    best: Optional[Dict[str, Any]] = None
    best_bc = float("inf")
    plateau = 0
    # Plateau parameters are now configurable via cfg:
    max_plateau = int(getattr(cfg, "plateau_max", 1))
    plateau_rel_improvement = float(getattr(cfg, "plateau_rel_improvement", 0.05))

    def _error_result(msg: str, **extra: Any) -> Dict[str, Any]:
        """
        Centralized structured error helper.

        Ensures that any error surfaced to callers also carries whatever
        refinement history and best-pass diagnostics are available, and
        that a manifest is written for post-mortem analysis.
        """
        payload: Dict[str, Any] = {"error": msg}
        if history:
            payload["refinement_history"] = history
        if best is not None:
            payload["best_bc_resid_linf"] = best.get("bc_resid_linf")
            payload["best_dof"] = best.get("dof")
        payload.update(extra)
        try:
            _write_manifest(
                run_dir,
                run_id=run_id,
                device=device,
                dtype=dtype,
                requested_mode="bem",
                selected_mode="bem",
                planner_rationale="bem_solve_direct",
                fallback_reason=msg,
            )
        except Exception:
            # Logging/manifest failures must not mask the core error.
            pass
        try:
            bem_intercept.finalize(intercept_ctx)
        except Exception:
            pass
        return payload

    def _maybe_poll_control() -> None:
        _poll_control_file(run_dir, control, logger)
        if control.terminate:
            raise _ControlSignal("Terminate requested via control.json")

    try:
        for rp in range(int(getattr(cfg, "max_refine_passes", 3))):
            _maybe_poll_control()

            logger.info(
                f"Refine pass {rp + 1}: target h={current_h:.4f}",
                refine_pass=rp + 1,
                target_h=current_h,
            )

            try:
                mesh: TriMesh = generate_mesh(
                    spec,
                    target_h=current_h,
                    logger=logger,
                )
            except Exception as e:
                logger.error("Mesh generation failed.", error=str(e))
                break

            N = mesh.n_panels
            logger.info("Mesh built.", dof=N)

            if N == 0:
                logger.error("Generated mesh has zero panels; aborting.")
                break

            if int(getattr(cfg, "tile_size", 0)) > 0:
                tile_size = int(getattr(cfg, "tile_size", 0))
            else:
                target_peak_gb = getattr(cfg, "target_peak_gb", None)
                tile_mem_divisor = getattr(cfg, "tile_mem_divisor", 3.0)
                tile_size = _autotune_tile_size(
                    N,
                    dtype,
                    device,
                    logger,
                    target_vram_fraction=getattr(cfg, "target_vram_fraction", 0.8),
                    max_vram_gb=getattr(cfg, "vram_cap_gb", 24.0),
                    min_tile=getattr(cfg, "min_tile", 512),
                    max_tile=getattr(cfg, "max_tile", None),
                    target_peak_gb=target_peak_gb,
                    tile_mem_divisor=tile_mem_divisor,
                )

            C = torch.as_tensor(mesh.centroids, device=device, dtype=dtype)
            A = torch.as_tensor(mesh.areas, device=device, dtype=dtype)
            Nrm = torch.as_tensor(mesh.normals, device=device, dtype=dtype)

            bc = _bc_vector(spec, mesh, device, dtype)
            V_free = _free_space_potential_on_centroids(spec, C)

            # Basic sanity checks on BC and free-space potential.
            if not torch.isfinite(bc).all():
                n_bad = int((~torch.isfinite(bc)).sum().item())
                logger.error(
                    "BEM BC vector has non-finite entries.",
                    n_bad=n_bad,
                    max_abs=float(
                        torch.nan_to_num(
                            torch.abs(bc), nan=0.0, posinf=0.0, neginf=0.0
                        ).max().item()
                    ),
                )
                return _error_result("BEM BC vector contains NaN/Inf.")

            if not torch.isfinite(V_free).all():
                n_bad = int((~torch.isfinite(V_free)).sum().item())
                logger.error(
                    "Free-space potential on centroids has non-finite entries.",
                    n_bad=n_bad,
                    max_abs=float(
                        torch.nan_to_num(
                            torch.abs(V_free), nan=0.0, posinf=0.0, neginf=0.0
                        ).max().item()
                    ),
                )
                return _error_result(
                    "Free-space potential on centroids contains NaN/Inf."
                )

            # Self-panel diagonal:
            # - self_integrals: raw self integral I_self(A) = ∫_panel G dS
            # - self_corr:     per-area diagonal K_ii = I_self / A
            self_integrals = torch.empty(N, device=device, dtype=dtype)
            for i in range(N):
                self_integrals[i] = self_integral_correction(A[i])

            A_safe = A.clamp_min(torch.finfo(dtype).tiny)
            self_corr = self_integrals / A_safe

            # Near-field quadrature setup (panel geometry for matvec).
            use_near_quad_matvec = bool(
                getattr(cfg, "use_near_quadrature_matvec", False)
            )
            near_quad_order = int(
                getattr(cfg, "near_quadrature_order", 2)
            )
            near_quad_dist_factor = float(
                getattr(cfg, "near_quadrature_distance_factor", 1.5)
            )

            panel_vertices_np: np.ndarray | None = None
            near_pairs_np: np.ndarray = np.zeros((0, 2), dtype=np.int64)
            near_pair_weights_np: Optional[np.ndarray] = None
            # Optional CUDA-side backing arrays for near-field data.
            panel_vertices_cuda: Optional[torch.Tensor] = None
            near_pairs_cuda: Optional[torch.Tensor] = None
            use_near_quad_matvec_cuda = False

            if use_near_quad_matvec and N > 1:
                # Sanity: TriMesh invariants should guarantee these shapes.
                assert mesh.centroids.shape[0] >= N and mesh.areas.shape[0] >= N, (
                    "TriMesh inconsistent: centroids/areas length mismatch "
                    f"(C={mesh.centroids.shape[0]}, "
                    f"A={mesh.areas.shape[0]}, N={N})"
                )
                try:
                    # Ensure triangles are an integer array and in-bounds.
                    tris = np.asarray(mesh.triangles, dtype=np.int64)
                    verts = np.asarray(mesh.vertices, dtype=float)
                    panel_vertices_np = verts[tris]

                    # Build robust near pairs using the explicit panel count N.
                    near_pairs_np = _build_near_pairs_for_panels(
                        mesh.centroids,
                        mesh.areas,
                        distance_factor=near_quad_dist_factor,
                        n_panels=N,
                    )

                    if near_pairs_np.size == 0:
                        use_near_quad_matvec = False
                    else:
                        logger.info(
                            "Precomputing near-field matvec geometry corrections.",
                            dof=int(N),
                            n_pairs=int(near_pairs_np.shape[0]),
                            quad_order=int(near_quad_order),
                        )
                        near_pair_weights_np = _precompute_near_correction_weights(
                            mesh.centroids,
                            mesh.areas,
                            panel_vertices_np,
                            near_pairs_np,
                            quad_order=near_quad_order,
                        )
                        if device.type == "cuda":
                            # Try to prepare CUDA buffers and use bem_near_cuda.
                            if _has_bem_near_cuda():
                                try:
                                    panel_vertices_cuda = torch.as_tensor(
                                        panel_vertices_np,
                                        device=device,
                                        dtype=dtype,
                                    )
                                    near_pairs_cuda = torch.as_tensor(
                                        near_pairs_np,
                                        device=device,
                                        dtype=torch.long,
                                    )
                                    use_near_quad_matvec_cuda = True
                                    logger.info(
                                        "Near-field quadrature for matvec "
                                        "enabled on CUDA via bem_near_cuda.",
                                        dof=int(N),
                                        n_pairs=int(near_pairs_np.shape[0]),
                                    )
                                except Exception as exc:
                                    panel_vertices_cuda = None
                                    near_pairs_cuda = None
                                    use_near_quad_matvec_cuda = False
                                    logger.warning(
                                        "Failed to move near-field quadrature "
                                        "data to CUDA; falling back to CPU "
                                        "near corrections.",
                                        error=str(exc),
                                    )
                            if not use_near_quad_matvec_cuda:
                                logger.info(
                                    "Near-field quadrature for matvec enabled: "
                                    "far-field matvec on device, near corrections "
                                    "on CPU.",
                                    device=str(device),
                                    dof=int(N),
                                    n_pairs=int(near_pairs_np.shape[0]),
                                )
                        else:
                            logger.info(
                                "Near-field quadrature for matvec enabled on CPU.",
                                dof=int(N),
                                n_pairs=int(near_pairs_np.shape[0]),
                            )
                except Exception as exc:
                    logger.warning(
                        "Failed to set up near-field quadrature; "
                        "continuing without it.",
                        error=str(exc),
                        exc_type=type(exc).__name__,
                        traceback=traceback.format_exc(),
                    )
                    panel_vertices_np = None
                    near_pairs_np = np.zeros((0, 2), dtype=np.int64)
                    near_pair_weights_np = None
                    panel_vertices_cuda = None
                    near_pairs_cuda = None
                    use_near_quad_matvec = False
                    use_near_quad_matvec_cuda = False
            elif use_near_quad_matvec:
                # N <= 1, nothing to correct.
                use_near_quad_matvec = False
                use_near_quad_matvec_cuda = False

            def _matvec_sigma_nondiff_base(sig: torch.Tensor) -> torch.Tensor:
                # Far field via the standard tiled kernel.
                V_far = bem_matvec_gpu(
                    sigma=sig,
                    src_centroids=C,
                    areas=A,
                    tile_size=tile_size,
                    self_integrals=self_corr,
                    use_near_quad=False,
                )
                # Optional near-field correction using triangle quadrature.
                if (
                    use_near_quad_matvec
                    and panel_vertices_np is not None
                    and near_pairs_np.size > 0
                ):
                    if (
                        use_near_quad_matvec_cuda
                        and panel_vertices_cuda is not None
                        and near_pairs_cuda is not None
                    ):
                        V_far = _apply_near_quadrature_matvec_cuda(
                            V_far,
                            sig,
                            centroids=C,
                            areas=A,
                            panel_vertices=panel_vertices_cuda,
                            near_pairs=near_pairs_cuda,
                            quad_order=near_quad_order,
                            panel_vertices_np=panel_vertices_np,
                            near_pairs_np=near_pairs_np,
                            near_pair_weights_np=near_pair_weights_np,
                        )
                    else:
                        V_far = _apply_near_quadrature_matvec(
                            V_far,
                            sig,
                            centroids=C,
                            areas=A,
                            panel_vertices=panel_vertices_np,
                            near_pairs=near_pairs_np,
                            quad_order=near_quad_order,
                            near_pair_weights=near_pair_weights_np,
                        )
                return V_far

            def _matvec_sigma_diff_base(sig: torch.Tensor) -> torch.Tensor:
                return _bem_matvec_core_torch(
                    centroids=C,
                    areas=A,
                    sigma=sig,
                    self_integrals=self_corr,
                    tile_size=tile_size,
                )

            alpha = float(getattr(cfg, "near_alpha", 0.0))
            if alpha > 0.0:
                k = int(getattr(cfg, "near_k", 8))
                k = max(1, min(k, max(1, N - 1)))
                with torch.no_grad():
                    dists = torch.cdist(C, C, p=2)
                    idx = torch.arange(N, device=device)
                    dists[idx, idx] = float("inf")
                    near_idx = torch.topk(dists, k=k, largest=False, dim=1).indices
            else:
                near_idx = None

            def _matvec_with_near(
                base_mv: Callable[[torch.Tensor], torch.Tensor],
                sig: torch.Tensor,
            ) -> torch.Tensor:
                v = base_mv(sig)
                if near_idx is None or alpha <= 0.0 or sig.numel() == 0:
                    return v
                idx_l = near_idx
                idx_clamped = idx_l.clamp_min(0).clamp_max(sig.shape[0] - 1)
                neigh = v.index_select(0, idx_clamped.view(-1)).view(idx_clamped.shape)
                neigh_mean = neigh.mean(dim=1)
                return (1.0 - alpha) * v + alpha * neigh_mean

            def matvec_sigma_nondiff(sig: torch.Tensor) -> torch.Tensor:
                return _matvec_with_near(_matvec_sigma_nondiff_base, sig)

            def matvec_sigma_diff(sig: torch.Tensor) -> torch.Tensor:
                return _matvec_with_near(_matvec_sigma_diff_base, sig)

            # 7) RHS and initial guess
            b = bc - V_free
            # Use the raw self-integral I_self(A) as an approximation to the
            # matrix diagonal; self_corr contains the per-area K_ii entries.
            diag = self_integrals.clamp_min(1e-18)
            x0 = b / diag

            # Sanity checks to catch NaN/Inf before GMRES
            b_finite = torch.isfinite(b)
            diag_finite = torch.isfinite(diag)
            x0_finite = torch.isfinite(x0)

            if not b_finite.all():
                n_bad = int((~b_finite).sum().item())
                logger.error(
                    "BEM RHS has non-finite entries.",
                    n_bad=n_bad,
                    max_abs=float(
                        torch.nan_to_num(
                            torch.abs(b), nan=0.0, posinf=0.0, neginf=0.0
                        ).max().item()
                    ),
                )
                return _error_result("BEM RHS contains NaN/Inf.")

            if not diag_finite.all():
                n_bad = int((~diag_finite).sum().item())
                logger.error(
                    "BEM diagonal has non-finite entries.",
                    n_bad=n_bad,
                )
                return _error_result(
                    "BEM diagonal (self-integrals) contains NaN/Inf."
                )

            if not x0_finite.all():
                n_bad = int((~x0_finite).sum().item())
                logger.warning(
                    "Initial guess x0 has non-finite entries; resetting to zeros.",
                    n_bad=n_bad,
                )
                x0 = torch.zeros_like(b)

            # 7b) GMRES callback with control + telemetry
            def _gmres_callback(
                iter_idx: int,
                resid_norm: float,
                ctx: Dict[str, Any],
            ) -> None:
                try:
                    _poll_control_file(run_dir, control, logger)
                    if control.terminate:
                        raise _ControlSignal(
                            "Terminate requested via control.json during GMRES."
                        )

                    tile_sz = int(ctx.get("tile_size", tile_size))
                    pass_idx = int(ctx.get("pass_index", rp + 1))

                    extra = {
                        k: v
                        for k, v in (ctx or {}).items()
                        if k not in ("iter", "resid", "tile_size", "pass_index")
                    }

                    logger.debug(
                        "GMRES iter.",
                        iter=int(iter_idx),
                        resid=float(resid_norm),
                        tile_size=tile_sz,
                        dof=int(N),
                        pass_index=pass_idx,
                        write_every=control.write_every,
                        **extra,
                    )
                except _ControlSignal:
                    raise
                except Exception:
                    pass

            # 8) Linear solve
            if not differentiable:
                use_precond = bool(getattr(cfg, "use_precond", True))
                precond_label: Optional[str] = "jacobi" if use_precond else None

                try:
                    sigma, info = gmres_restart(
                        matvec_sigma_nondiff,
                        b,
                        restart=int(getattr(cfg, "gmres_restart", 50)),
                        tol=float(getattr(cfg, "gmres_tol", 1e-8)),
                        maxiter=int(getattr(cfg, "gmres_maxiter", 500)),
                        precond=precond_label,
                        areas=A,
                        A_diag=diag,
                        logger=logger,
                        x0=x0,
                        callback=_gmres_callback,
                        callback_context={
                            "tile_size": int(tile_size),
                            "pass_index": int(rp + 1),
                        },
                        log_every=int(getattr(cfg, "gmres_log_every", 25)),
                    )
                except _ControlSignal as cs:
                    logger.warning(
                        "GMRES aborted via control signal.",
                        reason=str(cs),
                    )
                    return _error_result(
                        f"BEM solve aborted via control: {cs}"
                    )
                except Exception as e:
                    logger.error("GMRES failed.", error=str(e))
                    return _error_result(f"GMRES failed: {e}")

                # Inspect GMRES outcome; optionally retry without preconditioner,
                # then fall back to Jacobi if still unsuccessful.
                resid_val = info.get("resid", float("inf"))
                try:
                    resid_float = float(resid_val)
                except Exception:
                    resid_float = float("inf")
                success_flag = bool(info.get("success", True))
                code_val = int(info.get("code", 0) or 0)

                # If GMRES with preconditioner fails or produces a non-finite
                # residual, retry once without any preconditioner before
                # falling back to Jacobi.
                if precond_label is not None and (
                    (not success_flag) or (not math.isfinite(resid_float))
                ):
                    logger.warning(
                        "GMRES reported failure or non-finite residual with "
                        "preconditioner; retrying without preconditioner.",
                        gmres_resid=resid_float,
                        gmres_code=code_val,
                    )
                    try:
                        sigma2, info2 = gmres_restart(
                            matvec_sigma_nondiff,
                            b,
                            restart=int(getattr(cfg, "gmres_restart", 50)),
                            tol=float(getattr(cfg, "gmres_tol", 1e-8)),
                            maxiter=int(getattr(cfg, "gmres_maxiter", 500)),
                            precond=None,
                            areas=A,
                            A_diag=diag,
                            logger=logger,
                            x0=x0,
                            callback=_gmres_callback,
                            callback_context={
                                "tile_size": int(tile_size),
                                "pass_index": int(rp + 1),
                            },
                            log_every=int(getattr(cfg, "gmres_log_every", 25)),
                        )
                        sigma, info = sigma2, info2
                        resid_val = info.get("resid", float("inf"))
                        try:
                            resid_float = float(resid_val)
                        except Exception:
                            resid_float = float("inf")
                        success_flag = bool(info.get("success", True))
                        code_val = int(info.get("code", 0) or 0)
                    except _ControlSignal as cs:
                        logger.warning(
                            "GMRES aborted via control signal on retry.",
                            reason=str(cs),
                        )
                        return _error_result(
                            f"BEM solve aborted via control: {cs}"
                        )
                    except Exception as e:
                        logger.error(
                            "GMRES retry without preconditioner failed.",
                            error=str(e),
                        )
                        return _error_result(
                            f"GMRES failed on retry without preconditioner: {e}"
                        )

                if (not success_flag) or (not math.isfinite(resid_float)):
                    use_jacobi = bool(getattr(cfg, "allow_jacobi_fallback", True))
                    if use_jacobi:
                        logger.warning(
                            "GMRES reported failure; attempting Jacobi fallback.",
                            gmres_resid=resid_float,
                            gmres_code=code_val,
                        )
                        sigma_j, info_j = _jacobi_fallback_solve(
                            A=matvec_sigma_nondiff,
                            b=b,
                            diag=diag,
                            logger=logger,
                            maxiter=int(getattr(cfg, "jacobi_maxiter", 256)),
                            tol=float(getattr(cfg, "jacobi_tol", 1e-5)),
                            omega=float(getattr(cfg, "jacobi_omega", 0.8)),
                        )
                        resid_j = info_j.get("resid", float("inf"))
                        try:
                            resid_j_float = float(resid_j)
                        except Exception:
                            resid_j_float = float("inf")

                        if bool(info_j.get("success", False)) and math.isfinite(
                            resid_j_float
                        ):
                            sigma = sigma_j
                            info = info_j
                            logger.info(
                                "Jacobi fallback succeeded.",
                                resid=resid_j_float,
                                iters=info_j.get("iters"),
                            )
                        else:
                            logger.error(
                                "Jacobi fallback failed after GMRES failure.",
                                gmres_resid=resid_float,
                                gmres_code=code_val,
                                jacobi_resid=resid_j_float,
                                jacobi_iters=info_j.get("iters"),
                            )
                            return _error_result(
                                (
                                    "BEM linear solve failed: "
                                    f"GMRES(code={code_val}, resid={resid_float}) "
                                    f"and Jacobi(resid={resid_j_float})"
                                ),
                                gmres_resid=resid_float,
                                gmres_code=code_val,
                                jacobi_resid=resid_j_float,
                                jacobi_iters=info_j.get("iters"),
                            )
                    else:
                        logger.error(
                            "BEM linear solve failed; GMRES reported failure and "
                            "Jacobi fallback is disabled.",
                            gmres_resid=resid_float,
                            gmres_code=code_val,
                        )
                        return _error_result(
                            (
                                "BEM linear solve failed: "
                                f"GMRES(code={code_val}, resid={resid_float})"
                            ),
                            gmres_resid=resid_float,
                            gmres_code=code_val,
                        )
            else:
                diffbem = _get_diffbem_module()
                if diffbem is None:
                    msg = (
                        "differentiable=True requested for bem_solve, "
                        "but electrodrive.core.diffbem or xitorch is unavailable."
                    )
                    logger.error(msg)
                    raise RuntimeError(msg)

                diff_out = diffbem.solve_diffbem(
                    spec,
                    cfg,
                    logger,
                    C=C,
                    N=Nrm,
                    A=A,
                    rhs=b,
                    matvec=matvec_sigma_diff,
                    x0=x0,
                )
                sigma = diff_out["sigma"]
                info = dict(diff_out.get("stats", {}))
                info.setdefault("solver", "xitorch_gmres")

                resid_val = info.get("resid", None)
                if resid_val is not None:
                    try:
                        resid_float = float(resid_val)
                    except Exception:
                        resid_float = float("inf")
                else:
                    resid_float = 0.0
                success_flag = bool(info.get("success", True))
                if (not success_flag) or (not math.isfinite(resid_float)):
                    logger.error(
                        "Differentiable BEM linear solve reported failure.",
                        resid=resid_float,
                        info=info,
                    )
                    return _error_result(
                        (
                            "Differentiable BEM linear solve failed: "
                            f"resid={resid_float}"
                        ),
                        resid=resid_float,
                        info=info,
                    )

            logger.info(
                "BEM linear solve done.",
                iters=info.get("iters"),
                resid=info.get("resid"),
                success=info.get("success", True),
                differentiable=bool(differentiable),
            )

            # 9) Post-process: induced potential at centroids and BC residual
            sigma_finite = torch.isfinite(sigma)
            if not sigma_finite.all():
                n_bad = int((~sigma_finite).sum().item())
                logger.error(
                    "Surface charge density contains non-finite entries.",
                    n_bad=n_bad,
                )
                return _error_result(
                    "BEM sigma contains NaN/Inf after linear solve."
                )

            if not differentiable:
                V_ind = matvec_sigma_nondiff(sigma)
            else:
                V_ind = matvec_sigma_diff(sigma)

            V_tot = torch.nan_to_num(
                V_free + V_ind,
                nan=0.0,
                posinf=0.0,
                neginf=0.0,
            )
            bc_resid_linf = float(torch.max(torch.abs(V_tot - bc)).item())

            sigma_sane = torch.nan_to_num(
                sigma,
                nan=0.0,
                posinf=0.0,
                neginf=0.0,
            )
            energy_A = compute_bem_capacitive_energy(V_tot, sigma_sane, A)

            logger.info(
                "Pass results.",
                bc_residual_linf=bc_resid_linf,
                energy_A=f"{energy_A:.6e}",
            )

            pass_payload: Dict[str, Any] = {
                "pass": rp + 1,
                "h": current_h,
                "dof": N,
                "bc_resid_linf": bc_resid_linf,
                "energy_A": energy_A,
                "gmres_info": info,
                "tile_size": tile_size,
                "artifacts": (
                    spec,
                    C,
                    A,
                    Nrm,
                    sigma,
                    V_tot,
                    mesh,
                ),
            }
            history.append(pass_payload)
            try:
                bem_intercept.record_bem_pass(
                    intercept_ctx,
                    {
                        "pass": rp + 1,
                        "h": current_h,
                        "n_panels": N,
                        "tile_size": tile_size,
                        "bc_resid_linf": bc_resid_linf,
                        "gmres_iters": info.get("iters"),
                        "gmres_resid_true": info.get("resid"),
                        "gmres_tol_abs": info.get("tol_abs"),
                        "gmres_code": info.get("code"),
                        "gmres_used_precond": info.get("used_preconditioner", False),
                        "device": str(device),
                        "dtype": str(dtype),
                        "plateau": plateau,
                        "near_quad_eval": bool(getattr(cfg, "use_near_quadrature", False)),
                    },
                )
            except Exception:
                pass

            if bc_resid_linf < best_bc:
                improvement = (
                    best_bc - bc_resid_linf
                    if math.isfinite(best_bc)
                    else float("inf")
                )
                best = pass_payload
                best_bc = bc_resid_linf
                plateau = (
                    0
                    if improvement
                    > max(
                        1e-16,
                        plateau_rel_improvement * max(best_bc, 1e-16),
                    )
                    else plateau + 1
                )
            else:
                plateau += 1

            stop_by_bc = bc_resid_linf <= target_bc
            have_min_panels = N >= int(getattr(cfg, "min_panels", 0))
            have_min_passes = (rp + 1) >= int(getattr(cfg, "min_refine_passes", 1))

            if stop_by_bc and have_min_panels and have_min_passes:
                logger.info(
                    "Target BC residual reached and min_panels/min_passes satisfied.",
                    min_panels=int(getattr(cfg, "min_panels", 0)),
                    passes=rp + 1,
                    dof=N,
                )
                stop_reason = "target_bc"
                break

            if plateau >= max_plateau and have_min_panels and have_min_passes:
                logger.info(
                    "Plateau detected; stopping refinement to avoid long runs.",
                    plateau=plateau,
                )
                stop_reason = "plateau"
                break

            current_h *= refine_factor

    except _ControlSignal as cs_outer:
        logger.warning(
            "BEM solve aborted via control signal.",
            reason=str(cs_outer),
        )
        if not history:
            return _error_result(f"BEM solve aborted via control: {cs_outer}")

    if stop_reason == "unset":
        stop_reason = "max_passes_reached"

    # Fallback if no best pass was selected
    if best is None:
        if not history:
            logger.error("BEM solve produced no passes.")
            return _error_result("BEM solve failed (no passes)")

        # Prefer passes whose linear solve actually succeeded and has finite residual.
        def _pass_ok(p: Dict[str, Any]) -> bool:
            info_p = p.get("gmres_info") or {}
            success_p = bool(info_p.get("success", True))
            resid_p = info_p.get("resid", None)
            if resid_p is None:
                return success_p
            try:
                resid_f = float(resid_p)
            except Exception:
                resid_f = float("inf")
            return success_p and math.isfinite(resid_f)

        good_passes = [p for p in history if _pass_ok(p)]
        if not good_passes:
            last_info = history[-1].get("gmres_info", {})
            logger.error(
                "BEM solve produced passes but none had a successful linear solve.",
                last_gmres_info=last_info,
            )
            return _error_result(
                "BEM solve failed (no successful linear solves)",
                gmres_last=last_info,
            )

        best = min(good_passes, key=lambda p: p.get("bc_resid_linf", float("inf")))
        logger.warning(
            "Using best successful pass for diagnostics.",
            dof=best["dof"],
            bc_resid_linf=best.get("bc_resid_linf"),
        )

    (
        spec_b,
        C_b,
        A_b,
        Nrm_b,
        sigma_b,
        Vtot_b,
        mesh_b,
    ) = best["artifacts"]
    N_b = best["dof"]
    tile_b = best["tile_size"]

    # Panel vertices for near-field evaluation quadrature on the final mesh.
    panel_vertices_b: Optional[torch.Tensor] = None
    use_near_quad_eval = bool(getattr(cfg, "use_near_quadrature", False))
    if use_near_quad_eval and N_b > 0:
        try:
            verts_b = torch.as_tensor(
                mesh_b.vertices, device=C_b.device, dtype=C_b.dtype
            )
            tris_b = torch.as_tensor(
                mesh_b.triangles, device=C_b.device, dtype=torch.long
            )
            panel_vertices_b = verts_b[tris_b]
        except Exception as exc:
            use_near_quad_eval = False
            panel_vertices_b = None
            logger.warning(
                "Failed to build panel vertices for near-field evaluation; "
                "continuing without near quadrature at targets.",
                error=str(exc),
            )

    solution = BEMSolution(
        spec_b,
        C_b,
        A_b,
        sigma_b,
        C_b.device,
        C_b.dtype,
        tile_b,
        normals=Nrm_b,
        differentiable=bool(differentiable),
        panel_vertices=panel_vertices_b,
        near_quadrature=use_near_quad_eval,
        near_quad_order=int(getattr(cfg, "near_quadrature_order", 2)),
        near_quad_dist_factor=float(
            getattr(cfg, "near_quadrature_distance_factor", 1.5)
        ),
    )
    solution.meta["energy_A"] = best["energy_A"]
    solution.meta["bem_vram_config"] = {
        "target_peak_gb": float(getattr(cfg, "target_peak_gb", 0.0) or 0.0),
        "tile_mem_divisor": float(getattr(cfg, "tile_mem_divisor", 3.0) or 3.0),
        "fp64": bool(getattr(cfg, "fp64", False)),
    }

    if N_b <= 0:
        sample_points: List[List[float]] = []
        boundary_samples: List[float] = []
    else:
        n_samples = min(1024, max(1, N_b))
        if n_samples == 1:
            idx = torch.tensor([0], device=C_b.device, dtype=torch.long)
        else:
            step = max(1, N_b // n_samples)
            idx = torch.arange(0, N_b, step, device=C_b.device, dtype=torch.long)[
                :n_samples
            ]

        sample_points = C_b[idx].detach().cpu().numpy().tolist()
        boundary_samples = Vtot_b[idx].detach().cpu().numpy().tolist()

    patch_L: Optional[float] = None
    try:
        # Use the best-pass spec explicitly; for current workflows this is
        # identical to the input spec, but it makes the intent clearer.
        if any(c.get("type") == "plane" for c in spec_b.conductors):
            total_area = float(A_b.sum().item()) if N_b > 0 else 0.0
            if total_area > 0.0:
                patch_L = math.sqrt(total_area)
                logger.info(
                    "Plane patch extent recorded.",
                    total_area=f"{total_area:.6f}",
                    patch_L=f"{patch_L:.6f}",
                )
            else:
                logger.warning("Plane patch extent unavailable (zero area).")
    except Exception as exc:
        logger.warning("Failed computing patch extent.", error=str(exc))
        patch_L = None

    gpu_peak_mb = _sample_gpu_peak_mb()

    mesh_stats: Dict[str, Any] = {
        "n_panels": N_b,
        "total_area": float(A_b.sum().item()) if N_b > 0 else 0.0,
        "bc_residual_linf": float(best["bc_resid_linf"]),
        "h_final": float(best["h"]),
        "tile_size_final": int(tile_b),
        "gpu_mem_peak_mb": gpu_peak_mb,
    }
    if patch_L is not None:
        mesh_stats["patch_L"] = patch_L
        try:
            if intercept_ctx is not None:
                for p in intercept_ctx.payload.get("refinement_passes", []):
                    if int(p.get("pass", -1)) == int(best.get("pass", -1)):
                        p["patch_L"] = patch_L
        except Exception:
            pass

    gmres_stats = dict(best.get("gmres_info", {}))
    gmres_stats.setdefault("gpu_mem_peak_mb", gpu_peak_mb)

    out: Dict[str, Any] = {
        "boundary_samples": boundary_samples,
        "sample_points": sample_points,
        "solution": solution,
        "surface_charge_density": sigma_b.detach().cpu().numpy(),
        "mesh_stats": mesh_stats,
        "gmres_stats": gmres_stats,
        "refinement_history": history,
    }

    try:
        _write_manifest(
            run_dir,
            run_id=run_id,
            device=device,
            dtype=dtype,
            requested_mode="bem",
            selected_mode="bem",
            planner_rationale="bem_solve_direct",
        )
    except Exception:
        pass

    try:
        bem_intercept.set_stop_reason(intercept_ctx, stop_reason)
        bem_intercept.finalize(intercept_ctx)
    except Exception:
        pass

    return out

================================================================================
===== END FILE: code\bem.py =====
================================================================================

================================================================================
===== BEGIN FILE: code\bem_fmm.py =====
================================================================================

# bem_fmm.py
from __future__ import annotations

"""
High-level BEM ⇄ FMM glue for the Laplace single-layer operator.

This module implements a *numerically robust* external backend for
:func:`electrodrive.core.bem_kernel.bem_matvec_gpu` based on the Tier-3
FMM stack in :mod:`electrodrive.fmm3d`.

Compared to the original prototype treecode implementation, this version:

- delegates geometry + interaction logic to :mod:`electrodrive.fmm3d`,
- uses high-order spherical-harmonic expansions (order p >= 4),
- cleanly separates near-field (exact P2P) and far-field (M2L/L2P),
- enforces consistent physics with the BEM kernel (same K_E, same
  handling of diagonal self-integrals),
- exposes instrumentation hooks via :class:`MultipoleOpStats` and the
  standard :class:`JsonlLogger` used elsewhere in the project`.

Public API
==========

The main entry points are

- :class:`LaplaceFmm3D` – stateful backend object owning the tree and FMM
  configuration, with a :meth:`matvec` method compatible with
  ``bem_matvec_gpu(backend="external")``.
- :func:`make_laplace_fmm_backend` – convenience constructor used by
  tests and orchestration helpers.
"""

from dataclasses import dataclass
from typing import Optional, Any

import copy
import torch
from torch import Tensor

from electrodrive.utils.config import K_E
from electrodrive.fmm3d.config import FmmConfig, BackendKind
from electrodrive.utils.logging import JsonlLogger
from electrodrive.core.bem_kernel import (
    LaplaceSingleLayerKernel,
    SingleLayerKernel,
    DEFAULT_SINGLE_LAYER_KERNEL,
)

from electrodrive.fmm3d.tree import FmmTree, build_fmm_tree
from electrodrive.fmm3d.interaction_lists import (
    InteractionLists,
    build_interaction_lists,
)
from electrodrive.fmm3d.multipole_operators import (
    MultipoleCoefficients,
    LocalCoefficients,
    MultipoleOpStats,
)
from electrodrive.fmm3d.kernels_cpu import (
    apply_p2p_cpu,
    apply_p2p_cpu_tiled,
    p2m_cpu,
    m2m_cpu,
    m2l_cpu,
    l2l_cpu,
    l2p_cpu,
    P2PResult,
)
from electrodrive.fmm3d.kernels_gpu import (
    apply_p2p_gpu,
    p2m_gpu,
    m2m_gpu,
    m2l_gpu,
    l2l_gpu,
    l2p_gpu,
)
from electrodrive.fmm3d.logging_utils import get_logger


__all__ = ["LaplaceFmm3D", "make_laplace_fmm_backend"]


@dataclass
class _BemFmmState:
    """
    Internal cached state for a symmetric BEM FMM matvec.

    Attributes
    ----------
    tree:
        Geometry tree over the panel centroids (sources == targets).
    cfg:
        FMM configuration (expansion order, MAC, leaf size, dtype).
    lists:
        Interaction lists used for near-field P2P (U-list) and far-field
        M2L (V/W/X lists).
    """

    tree: FmmTree
    cfg: FmmConfig
    lists: InteractionLists


class LaplaceFmm3D:
    """
    High-order 3D Laplace FMM backend for the single-layer BEM operator.

    This class is intentionally minimal: it owns a geometry tree and an
    :class:`FmmConfig` instance and exposes a single :meth:`matvec`
    method that matches the external-backend hook of
    :func:`bem_matvec_gpu`.

    Notes
    -----
    - Geometry passed to the constructor (``src_centroids`` and
      ``areas``) must live on the CPU. Tree construction and interaction
      list generation are CPU-only for correctness and debuggability.
      Heavy FMM work (multipole translations + P2P) can run either on
      the CPU or on a CUDA device depending on ``backend``.
    - The expansion order is controlled via :class:`FmmConfig` and
      defaults to whatever that class uses (currently p = 8).  This is
      typically sufficient to achieve < 1% relative error on well-behaved
      meshes when combined with a reasonably strict MAC (e.g.
      ``theta ≲ 0.6``).
    """

    def __init__(
        self,
        src_centroids: Tensor,
        areas: Tensor,
        *,
        max_leaf_size: int = 64,
        theta: float = 0.5,
        use_dipole: bool = True,
        logger: Optional[Any] = None,
        expansion_order: Optional[int] = None,
        backend: BackendKind = "auto",
        device: Optional[torch.device | str] = None,
    ) -> None:
        """
        Parameters
        ----------
        src_centroids : (N, 3) tensor
            Panel centroids (sources == targets for BEM matvecs).
        areas : (N,) tensor
            Panel areas. Used only to form physical charges
            ``q = sigma * area`` per matvec.
        max_leaf_size : int, optional
            Maximum number of points per leaf node in the FMM tree.
        theta : float, optional
            MAC (multipole-acceptance criterion) parameter.  Smaller
            values yield more accurate but more expensive FMMs.
        use_dipole : bool, optional
            Kept for backwards compatibility with the original treecode
            backend; has no effect in the high-order FMM implementation.
        logger : JsonlLogger or None
            Optional structured logger for diagnostics.
        expansion_order : int or None, optional
            Override the FMM expansion order ``p``.  If None, the
            default from :class:`FmmConfig` is used (currently p = 8).
        backend : {"cpu", "gpu", "auto"}, optional
            Logical backend selector. "auto" chooses a GPU backend when
            available and allowed by ``FmmConfig.use_gpu``, otherwise
            falls back to CPU.
        device : torch.device or str or None, optional
            Preferred device for FMM work when ``backend`` resolves to
            "gpu". If ``None``, defaults to the current CUDA device.
        """
        if src_centroids.ndim != 2 or src_centroids.shape[1] != 3:
            raise ValueError("src_centroids must have shape (N, 3)")
        if areas.ndim != 1 or areas.shape[0] != src_centroids.shape[0]:
            raise ValueError("areas must have shape (N,) matching src_centroids")

        # The constructor remains CPU-only: geometry tensors must live on
        # the CPU. GPU acceleration is handled internally by moving the
        # *tree* and per-matvec charges, not by accepting CUDA geometry.
        if src_centroids.device.type != "cpu" or areas.device.type != "cpu":
            raise ValueError(
                "LaplaceFmm3D currently supports only CPU tensors for "
                "src_centroids and areas."
            )

        self.src_centroids = src_centroids
        self.areas = areas
        self.N = int(src_centroids.shape[0])
        self.max_leaf_size = int(max_leaf_size)
        self.theta = float(theta)
        self.use_dipole = bool(use_dipole)  # retained for API stability

        # Normalize logger: supports fan-out to console if verbose mode is enabled.
        self.logger = get_logger(logger)

        self.device = src_centroids.device  # CPU device for public API
        self.dtype = src_centroids.dtype

        # Build FMM configuration.  We let FmmConfig handle validation.
        # dtype is derived from src_centroids.dtype so that multipole math
        # stays numerically consistent with the BEM layer.
        cfg_kwargs = dict(
            mac_theta=self.theta,
            leaf_size=self.max_leaf_size,
            dtype=self.dtype,
            backend=backend,
        )
        if expansion_order is not None:
            cfg_kwargs["expansion_order"] = int(expansion_order)

        self.cfg = FmmConfig(**cfg_kwargs)

        # Resolve backend and FMM device after config construction so that
        # we can respect cfg.use_gpu and keep dtype unchanged.
        if backend == "auto":
            if torch.cuda.is_available() and self.cfg.use_gpu:
                self.backend: BackendKind = "gpu"
                self.fmm_device = torch.device(device or "cuda")
            else:
                self.backend = "cpu"
                self.fmm_device = self.src_centroids.device
        elif backend == "gpu":
            if not torch.cuda.is_available() or not self.cfg.use_gpu:
                raise RuntimeError("GPU backend requested but CUDA/use_gpu not available.")
            self.backend = "gpu"
            self.fmm_device = torch.device(device or "cuda")
        else:
            # Force CPU execution even if GPUs are available.
            self.backend = "cpu"
            self.fmm_device = self.src_centroids.device

        # Keep the config in sync with the resolved backend.
        self.cfg.backend = self.backend

        # Build geometry tree on CPU in original point ordering.
        # The tree stores points in its own "tree order"; we keep the
        # original centroids separately for pointer sanity checks.
        if self.N > 0:
            # IMPORTANT: respect cfg.leaf_size so that the geometry
            # driving the interaction lists matches the FMM config.
            tree = build_fmm_tree(
                self.src_centroids,
                leaf_size=int(self.cfg.leaf_size),
            )
            # Precompute interaction lists once, based on MAC.
            lists = build_interaction_lists(
                tree,
                tree,
                mac_theta=self.cfg.mac_theta,
            )
        else:
            # Degenerate empty tree; still construct a minimal FmmTree
            # via build_fmm_tree to keep invariants consistent.
            tree = build_fmm_tree(
                torch.zeros(0, 3, dtype=self.dtype, device=self.device),
                leaf_size=int(self.cfg.leaf_size),
            )
            lists = build_interaction_lists(
                tree,
                tree,
                mac_theta=self.cfg.mac_theta,
            )

        # CPU-oriented cached state.
        self.tree_cpu: FmmTree = tree
        self.lists: InteractionLists = lists
        self.state = _BemFmmState(tree=self.tree_cpu, cfg=self.cfg, lists=self.lists)
        # Backwards-compatibility alias for existing code that expects `backend.tree`.
        self.tree: FmmTree = self.tree_cpu

        # Optional GPU clone of the tree, created eagerly for GPU backends.
        self.tree_gpu: Optional[FmmTree] = None
        if self.backend == "gpu":
            self.tree_gpu = copy.deepcopy(self.tree_cpu)
            self.tree_gpu.to(self.fmm_device, dtype=self.cfg.dtype)

        if self.logger is not None:
            self.logger.info(
                "LaplaceFmm3D backend constructed.",
                N=int(self.N),
                leaf_size=int(self.max_leaf_size),
                theta=float(self.theta),
                expansion_order=int(self.cfg.expansion_order),
                dtype=str(self.dtype),
                backend=self.backend,
                fmm_device=str(self.fmm_device),
            )

    # ------------------------------------------------------------------
    # Public matvec API (bem_matvec_gpu external backend)
    # ------------------------------------------------------------------

    def _check_geometry_consistency(
        self,
        src_centroids: Tensor,
        areas: Tensor,
    ) -> None:
        """
        Basic sanity checks that the matvec call matches the geometry
        used to build the backend.
        """
        if src_centroids.data_ptr() != self.src_centroids.data_ptr():
            raise ValueError(
                "LaplaceFmm3D.matvec called with different src_centroids "
                "than the ones used to build the FMM tree."
            )
        if areas.data_ptr() != self.areas.data_ptr():
            raise ValueError(
                "LaplaceFmm3D.matvec called with different areas "
                "than the ones used to build the FMM tree."
            )
        if src_centroids.device.type != "cpu" or areas.device.type != "cpu":
            raise ValueError(
                "LaplaceFmm3D currently requires matvec geometry tensors "
                "to live on the CPU."
            )
        if src_centroids.dtype != self.dtype or areas.dtype != self.dtype:
            raise ValueError(
                "LaplaceFmm3D geometry dtype mismatch: "
                f"expected {self.dtype}, got "
                f"{src_centroids.dtype} / {areas.dtype}."
            )

    def _log_stats(
        self,
        logger: Optional[Any],
        stats: MultipoleOpStats,
        p2p_result: Optional[P2PResult] = None,
    ) -> None:
        """
        Emit a structured debug log with FMM operator statistics.

        The core counters come from :meth:`MultipoleOpStats.as_dict` (if available);
        any additional numeric counters registered in ``stats.extras`` are included
        as well.  P2P-specific metrics (if exposed by ``apply_p2p_cpu_tiled``) are
        logged under a ``p2p_*`` prefix.

        Logging is strictly best-effort: any exception is caught and
        ignored so that instrumentation can never affect the numerical
        path.
        """
        if logger is None:
            return

        try:
            payload = {}

            # Core + extra counters from the multipole backend.
            if hasattr(stats, "as_dict"):
                # Newer MultipoleOpStats implementations
                for k, v in stats.as_dict().items():  # type: ignore[attr-defined]
                    payload[k] = float(v)
            else:
                # Fallback for older MultipoleOpStats without as_dict()
                payload.update(
                    p2m_calls=float(getattr(stats, "p2m_calls", 0)),
                    m2m_calls=float(getattr(stats, "m2m_calls", 0)),
                    m2l_calls=float(getattr(stats, "m2l_calls", 0)),
                    l2l_calls=float(getattr(stats, "l2l_calls", 0)),
                    l2p_calls=float(getattr(stats, "l2p_calls", 0)),
                )
                for k, v in getattr(stats, "extras", {}).items():
                    payload[k] = float(v)

            # Attach a minimal geometry/config snapshot so that operator
            # counts can be correlated with problem size in logs.
            payload.update(
                N=int(self.N),
                n_nodes=int(self.state.tree.n_nodes),
                leaf_size=int(self.max_leaf_size),
                expansion_order=int(self.cfg.expansion_order),
                mac_theta=float(self.cfg.mac_theta),
            )

            # P2P metrics (if the P2P kernel exposes them).
            if p2p_result is not None:
                for attr in ("n_pairs", "n_interactions", "n_tiles"):
                    if hasattr(p2p_result, attr):
                        try:
                            payload[f"p2p_{attr}"] = int(getattr(p2p_result, attr))
                        except Exception:
                            # Best-effort: ignore if non-int-convertible.
                            pass

            logger.debug("LaplaceFmm3D statistics.", **payload)  # type: ignore[arg-type]
        except Exception:
            # Never let instrumentation break the numerical path.
            pass

    def _matvec_cpu(
        self,
        *,
        sigma: Tensor,
        tile_size: int,
        self_integrals: Optional[Tensor],
        logger: Optional[Any],
        kernel: Optional[SingleLayerKernel],
    ) -> Tensor:
        """
        CPU implementation of the symmetric Laplace single-layer matvec.

        This is the original matvec body, factored out so that the public
        :meth:`matvec` method can dispatch between CPU and GPU backends.
        """
        del kernel  # unused in the CPU path; kept for signature symmetry

        N = int(sigma.shape[0])
        if N == 0:
            return torch.zeros_like(sigma)

        with torch.no_grad():
            # Physical charges q_j = sigma_j * A_j.
            q = sigma * self.areas  # (N,)

            # Upward pass: P2M + M2M on the pre-built tree.
            stats = MultipoleOpStats()
            multipoles: MultipoleCoefficients = p2m_cpu(
                tree=self.state.tree,
                charges=q,
                cfg=self.state.cfg,
                stats=stats,
            )
            multipoles = m2m_cpu(
                tree=self.state.tree,
                multipoles=multipoles,
                cfg=self.state.cfg,
                stats=stats,
            )

            # Far-field: M2L + L2L + L2P → potentials in tree order
            # for the 1/|r| kernel.
            locals_: LocalCoefficients = m2l_cpu(
                source_tree=self.state.tree,
                target_tree=self.state.tree,
                multipoles=multipoles,
                lists=self.state.lists,
                cfg=self.state.cfg,
                stats=stats,
            )
            locals_ = l2l_cpu(
                tree=self.state.tree,
                locals_=locals_,
                cfg=self.state.cfg,
                stats=stats,
            )
            phi_far_tree: Tensor = l2p_cpu(
                tree=self.state.tree,
                locals_=locals_,
                cfg=self.state.cfg,
                stats=stats,
            )

            # Near-field: exact P2P on leaves using precomputed lists.
            # The P2P kernel implements the same 1/|r| kernel as the
            # far-field; the Coulomb constant K_E is applied once to the
            # combined near- and far-field contributions below.
            # charges_src must be in tree order; p2m_cpu already
            # produced multipoles with a tree-ordered charges vector.

            # Allow the user-supplied tile_size to override the config-driven
            # batch size for this call, if that field exists on FmmConfig.
            if hasattr(self.state.cfg, "p2p_batch_size"):
                self.state.cfg.p2p_batch_size = int(tile_size)

            p2p_result: P2PResult = apply_p2p_cpu(
                source_tree=self.state.tree,
                target_tree=self.state.tree,
                charges_src=multipoles.charges,
                lists=self.state.lists,
                cfg=self.state.cfg,
                logger=logger,  # normalized logger
                out=None,
            )
            phi_p2p_tree: Tensor = p2p_result.potential

            # Stage-wise diagnostics: L2 norms of far-field and near-field
            # contributions for the underlying 1/|r| kernel before
            # applying the physical Coulomb constant.
            try:
                stats.extras["l2_norm_phi_far"] = float(
                    torch.linalg.vector_norm(phi_far_tree).item()
                )
                stats.extras["l2_norm_phi_near"] = float(
                    torch.linalg.vector_norm(phi_p2p_tree).item()
                )
            except Exception:
                # Telemetry must never interfere with the numerical path.
                pass

            # Combine near + far for the 1/|r| kernel.
            phi_total_tree = phi_far_tree + phi_p2p_tree

            # Scale by Coulomb constant so that the overall kernel
            # matches G(r) = K_E / |r| used by the BEM layer.
            phi_total_tree = phi_total_tree * float(K_E)

            # Map back to original panel order.
            V = self.state.tree.map_to_original_order(phi_total_tree)

            # Add diagonal self-integral term if provided:
            #   V_i += self_integrals[i] * sigma_i * area_i
            if self_integrals is not None:
                if self_integrals.shape != sigma.shape:
                    raise ValueError(
                        "self_integrals must have shape (N,) matching sigma."
                    )
                V = V + self_integrals * sigma * self.areas

            # Basic sanity: clamp non-finite results (should not happen).
            mask_finite = torch.isfinite(V)
            if not torch.all(mask_finite):
                if logger is not None:
                    logger.error(
                        "Non-finite entries detected in LaplaceFmm3D matvec "
                        "output; clamping to zero."
                    )
                V = torch.where(mask_finite, V, torch.zeros_like(V))

            # Instrumentation / telemetry
            self._log_stats(logger, stats, p2p_result=p2p_result)

        return V

    def _matvec_gpu(
        self,
        *,
        sigma: Tensor,
        tile_size: int,
        self_integrals: Optional[Tensor],
        logger: Optional[Any],
        kernel: Optional[SingleLayerKernel],
    ) -> Tensor:
        """
        GPU-accelerated implementation of the symmetric Laplace single-layer matvec.

        Heavy FMM work (P2M/M2M/M2L/L2L/L2P + P2P) is carried out on
        ``self.fmm_device`` while the public API remains CPU-oriented.
        """
        del kernel  # unused in the GPU path; kept for signature symmetry

        N = int(sigma.shape[0])
        if N == 0:
            return torch.zeros_like(sigma)

        if self.backend != "gpu":
            raise RuntimeError("LaplaceFmm3D._matvec_gpu called but backend is not 'gpu'.")

        # Lazily build the GPU clone of the tree if it does not exist yet.
        if self.tree_gpu is None:
            self.tree_gpu = copy.deepcopy(self.tree_cpu)
            self.tree_gpu.to(self.fmm_device, dtype=self.cfg.dtype)

        tree_gpu = self.tree_gpu
        assert tree_gpu is not None  # for type checkers

        dev = self.fmm_device
        dtype = self.cfg.dtype

        with torch.no_grad():
            # Form physical charges on CPU and move them to the FMM device.
            q_cpu = sigma * self.areas  # (N,)
            q_gpu = q_cpu.to(device=dev, dtype=dtype)

            stats = MultipoleOpStats()
            multipoles: MultipoleCoefficients = p2m_gpu(
                tree=tree_gpu,
                charges=q_gpu,
                cfg=self.state.cfg,
                stats=stats,
            )
            multipoles = m2m_gpu(
                tree=tree_gpu,
                multipoles=multipoles,
                cfg=self.state.cfg,
                stats=stats,
            )

            # Far-field on GPU.
            locals_: LocalCoefficients = m2l_gpu(
                source_tree=tree_gpu,
                target_tree=tree_gpu,
                multipoles=multipoles,
                lists=self.state.lists,
                cfg=self.state.cfg,
                stats=stats,
            )
            locals_ = l2l_gpu(
                tree=tree_gpu,
                locals_=locals_,
                cfg=self.state.cfg,
                stats=stats,
            )
            phi_far_tree_gpu: Tensor = l2p_gpu(
                tree=tree_gpu,
                locals_=locals_,
                cfg=self.state.cfg,
                stats=stats,
            )

            # Near-field P2P on GPU. Respect the per-call tile size override.
            if hasattr(self.state.cfg, "p2p_batch_size"):
                self.state.cfg.p2p_batch_size = int(tile_size)

            p2p_result: P2PResult = apply_p2p_gpu(
                source_tree=tree_gpu,
                target_tree=tree_gpu,
                charges_src=multipoles.charges,
                lists=self.state.lists,
                cfg=self.state.cfg,
                logger=logger,
                out=None,
            )
            phi_p2p_tree_gpu: Tensor = p2p_result.potential

            # L2 diagnostics on GPU contributions.
            try:
                stats.extras["l2_norm_phi_far"] = float(
                    torch.linalg.vector_norm(phi_far_tree_gpu).item()
                )
                stats.extras["l2_norm_phi_near"] = float(
                    torch.linalg.vector_norm(phi_p2p_tree_gpu).item()
                )
            except Exception:
                pass

            # Combine near + far (still pure 1/|r|) and scale by K_E.
            phi_total_tree_gpu = phi_far_tree_gpu + phi_p2p_tree_gpu
            phi_total_tree_gpu = phi_total_tree_gpu * float(K_E)

            # Map back to original panel order on GPU, then bring result to CPU.
            V_gpu_orig = tree_gpu.map_to_original_order(phi_total_tree_gpu)
            V = V_gpu_orig.to(device=self.device, dtype=self.dtype)

            # Apply diagonal self-integral correction on CPU.
            if self_integrals is not None:
                if self_integrals.shape != sigma.shape:
                    raise ValueError(
                        "self_integrals must have shape (N,) matching sigma."
                    )
                V = V + self_integrals * sigma * self.areas

            # Clamp non-finite entries on CPU.
            mask_finite = torch.isfinite(V)
            if not torch.all(mask_finite):
                if logger is not None:
                    logger.error(
                        "Non-finite entries detected in LaplaceFmm3D matvec "
                        "output; clamping to zero."
                    )
                V = torch.where(mask_finite, V, torch.zeros_like(V))

            # Instrumentation / telemetry
            self._log_stats(logger, stats, p2p_result=p2p_result)

        return V

    def matvec(
        self,
        *,
        sigma: Tensor,
        src_centroids: Tensor,
        areas: Tensor,
        tile_size: int,
        self_integrals: Optional[Tensor],
        logger: Optional[Any] = None,
        kernel: Optional[SingleLayerKernel] = None,
        **kwargs,
    ) -> Tensor:
        """
        External matvec implementation compatible with :func:`bem_matvec_gpu`.

        Parameters are keyword-only to match the call pattern used by
        ``bem_matvec_gpu(backend="external", matvec_impl=fmm.matvec, ...)``.
        """
        del kwargs  # unused, kept for forward-compatibility

        # Geometry consistency (same panel mesh as during construction)
        self._check_geometry_consistency(src_centroids, areas)

        if kernel is not None and not isinstance(kernel, LaplaceSingleLayerKernel):
            raise ValueError(
                "LaplaceFmm3D currently only supports LaplaceSingleLayerKernel."
            )

        N = int(sigma.shape[0])
        if N != self.N:
            raise ValueError(
                f"sigma has length {N}, but FMM backend was built for {self.N} panels."
            )
        if sigma.device.type != "cpu":
            raise ValueError(
                "LaplaceFmm3D.matvec currently supports only CPU sigma tensors."
            )
        if sigma.dtype != self.dtype:
            raise ValueError(
                f"LaplaceFmm3D sigma dtype mismatch: expected {self.dtype}, "
                f"got {sigma.dtype}."
            )

        # Resolve logger for this specific call.
        # If none provided, default to the instance logger (which is already normalized).
        # If provided, normalize it to ensure verbose output works for this call too.
        if logger is None:
            logger = self.logger
        else:
            logger = get_logger(logger)

        if logger is not None:
            logger.debug(
                "LaplaceFmm3D matvec called.",
                N=int(N),
                leaf_size=int(self.max_leaf_size),
                theta=float(self.theta),
                expansion_order=int(self.cfg.expansion_order),
                backend=self.backend,
                fmm_device=str(self.fmm_device),
            )

        if N == 0:
            return torch.zeros_like(sigma)

        # Dispatch to backend-specific implementation.
        if self.backend == "gpu":
            V = self._matvec_gpu(
                sigma=sigma,
                tile_size=tile_size,
                self_integrals=self_integrals,
                logger=logger,
                kernel=kernel,
            )
        else:
            V = self._matvec_cpu(
                sigma=sigma,
                tile_size=tile_size,
                self_integrals=self_integrals,
                logger=logger,
                kernel=kernel,
            )

        if logger is not None:
            logger.info(
                "LaplaceFmm3D matvec completed.",
                N=int(N),
                leaf_size=int(self.max_leaf_size),
                theta=float(self.theta),
                expansion_order=int(self.cfg.expansion_order),
                backend=self.backend,
                fmm_device=str(self.fmm_device),
            )

        return V


def make_laplace_fmm_backend(
    src_centroids: Tensor,
    areas: Tensor,
    *,
    max_leaf_size: int = 64,
    theta: float = 0.5,
    use_dipole: bool = True,
    logger: Optional[Any] = None,
    expansion_order: Optional[int] = None,
    backend: BackendKind = "auto",
    device: Optional[torch.device | str] = None,
) -> LaplaceFmm3D:
    """
    Convenience constructor for a Laplace FMM backend.

    Typical usage
    -------------
    >>> fmm = make_laplace_fmm_backend(centroids, areas)
    >>> V = bem_matvec_gpu(
    ...     sigma,
    ...     centroids,
    ...     areas,
    ...     backend="external",
    ...     matvec_impl=fmm.matvec,
    ...     kernel=DEFAULT_SINGLE_LAYER_KERNEL,
    ... )

    Parameters
    ----------
    src_centroids, areas, max_leaf_size, theta, use_dipole, logger, expansion_order
        Passed through to :class:`LaplaceFmm3D`.
    backend :
        Logical backend selector ("cpu", "gpu", or "auto").
    device :
        Optional device hint for GPU backends.

    This uses the same Laplace single-layer kernel as the default
    Torch/KeOps path, but accelerates the matvec via a high-order FMM
    approximation.  On modest expansion orders (e.g. p ≈ 8) and
    MAC parameters around theta ≈ 0.5–0.6, relative errors of
    ``O(10^{-2})`` or better are typically achievable on realistic meshes.
    """
    return LaplaceFmm3D(
        src_centroids=src_centroids,
        areas=areas,
        max_leaf_size=max_leaf_size,
        theta=theta,
        use_dipole=use_dipole,
        logger=logger,
        expansion_order=expansion_order,
        backend=backend,
        device=device,
    )

================================================================================
===== END FILE: code\bem_fmm.py =====
================================================================================

================================================================================
===== BEGIN FILE: code\bem_kernel.py =====
================================================================================

from __future__ import annotations

import os
from dataclasses import dataclass
from typing import Callable, Optional, Protocol, runtime_checkable

try:
    import torch  # type: ignore
    from torch import Tensor
except Exception as e:  # pragma: no cover
    raise ImportError("Torch is required by bem_kernel.py") from e

from electrodrive.utils.logging import JsonlLogger
from electrodrive.utils.config import K_E

# Optional KeOps
USE_KEOPS = False
try:  # pragma: no cover
    from pykeops.torch import LazyTensor  # type: ignore

    USE_KEOPS = True
except Exception:  # pragma: no cover
    LazyTensor = None  # type: ignore


# --------------------------------------------------------------------------------------
# Small helpers
# --------------------------------------------------------------------------------------


def _ensure_tile_size(tile_size: int) -> int:
    """Clamp tile_size to a sensible positive integer."""
    if tile_size is None or tile_size <= 0:
        return 1024
    return int(tile_size)


def _log_tensor_stats(
    logger: Optional[JsonlLogger],
    name: str,
    x: Tensor,
    level: str = "debug",
) -> None:
    """
    Log basic finite-range stats for a tensor (min, max, any_nonfinite).

    This is intentionally lightweight and only used when a logger is provided.
    """
    if logger is None:
        return
    try:
        finite = torch.isfinite(x)
        any_nonfinite = not bool(torch.all(finite))
        x_finite = x[finite]
        if x_finite.numel() == 0:
            stats = dict(any_nonfinite=any_nonfinite, numel=int(x.numel()))
        else:
            stats = dict(
                any_nonfinite=any_nonfinite,
                numel=int(x.numel()),
                min=float(x_finite.min().item()),
                max=float(x_finite.max().item()),
            )
        if level == "debug":
            logger.debug(f"{name} stats.", **stats)  # type: ignore[arg-type]
        elif level == "info":
            logger.info(f"{name} stats.", **stats)  # type: ignore[arg-type]
        elif level == "warning":
            logger.warning(f"{name} stats.", **stats)  # type: ignore[arg-type]
    except Exception:
        # Stats are best-effort only; never let them break the solver.
        return


# --------------------------------------------------------------------------------------
# Pluggable physics: single-layer Green's function abstraction
# --------------------------------------------------------------------------------------


@runtime_checkable
class SingleLayerKernel(Protocol):
    """
    Interface for a single-layer Green's function kernel.

    Implementations must provide:
      - potential(diff, r): scalar kernel K_ij for potential
      - e_field_weight(diff, r): scalar kernel W_ij such that

            E_i = sum_j W_ij * (sigma_j * A_j) * (x_i - r_j)

    Shapes:
        diff : (T, N, 3)
        r    : (T, N)
        returns (T, N)
    """

    name: str

    def potential(self, diff: Tensor, r: Tensor) -> Tensor:
        ...

    def e_field_weight(self, diff: Tensor, r: Tensor) -> Tensor:
        ...


@dataclass
class LaplaceSingleLayerKernel:
    """
    Free-space Laplace single-layer kernel:

        G(r) = K_E / |r|
    """

    name: str = "laplace_single_layer"

    def potential(self, diff: Tensor, r: Tensor) -> Tensor:
        # diff is unused for Laplace but kept for interface consistency
        return K_E / r

    def e_field_weight(self, diff: Tensor, r: Tensor) -> Tensor:
        # Weight such that:
        #   E(x) = sum_j W_ij * (sigma_j * A_j) * (x_i - r_j)
        inv_r3 = 1.0 / (r * r * r)
        return K_E * inv_r3


DEFAULT_SINGLE_LAYER_KERNEL: SingleLayerKernel = LaplaceSingleLayerKernel()


def have_keops() -> bool:
    """Return True if the KeOps backend is importable."""
    return bool(USE_KEOPS)


# --------------------------------------------------------------------------------------
# Differentiable cores (pure-Torch): used by diff paths and by non-diff wrappers.
# --------------------------------------------------------------------------------------


def _bem_matvec_core_torch(
    centroids: Tensor,
    areas: Tensor,
    sigma: Tensor,
    self_integrals: Optional[Tensor] = None,
    tile_size: int = 1024,
    kernel: Optional[SingleLayerKernel] = None,
) -> Tensor:
    """
    Differentiable matrix-vector apply for the single-layer operator:

        (V_ind)_i = sum_j K_ij * (sigma_j * A_j)

    where K_ij is provided by `kernel.potential(...)`.

    Diagonal handling:
    - If self_integrals is provided, K_ii is replaced by self_integrals[i].
    - If self_integrals is None, K_ii is set to 0.0 (consistent with FMM/KeOps).
    """
    device, dtype = sigma.device, sigma.dtype
    N = int(sigma.shape[0])

    tile_size = _ensure_tile_size(tile_size)
    ker = kernel or DEFAULT_SINGLE_LAYER_KERNEL

    V = torch.zeros(N, device=device, dtype=dtype)
    if N == 0:
        return V

    # Basic sanity: shapes
    assert centroids.shape[0] == N, "centroids and sigma must have the same length"
    assert areas.shape[0] == N, "areas and sigma must have the same length"

    for i0 in range(0, N, tile_size):
        i1 = min(i0 + tile_size, N)
        chunk = centroids[i0:i1]  # (T,3)
        diff = chunk[:, None, :] - centroids[None, :, :]  # (T,N,3)
        r = torch.linalg.norm(diff, dim=-1).clamp_min(1e-12)  # (T,N)

        # Pluggable physics prior
        K = ker.potential(diff, r)  # (T,N)

        # Diagonal indices within this chunk
        arng = torch.arange(i0, i1, device=device)
        local_idx = torch.arange(i1 - i0, device=device)

        if self_integrals is not None:
            # Replace diagonal with analytic integrals
            K[local_idx, arng] = self_integrals[arng]
        else:
            # Explicitly zero the diagonal to avoid huge 1/eps terms.
            # This ensures consistency with FMM/KeOps backends.
            K[local_idx, arng] = 0.0

        V[i0:i1] = torch.sum(K * sigma[None, :] * areas[None, :], dim=1)
    return V


def _bem_potential_targets_core_torch(
    targets: Tensor,
    src_centroids: Tensor,
    areas: Tensor,
    sigma: Tensor,
    tile_size: int = 1024,
    kernel: Optional[SingleLayerKernel] = None,
) -> Tensor:
    """
    Differentiable induced potential at arbitrary targets due to panel charges.

        V(target_i) = sum_j K_ij * (sigma_j * A_j)
    """
    device, dtype = targets.device, targets.dtype
    M, N = int(targets.shape[0]), int(sigma.shape[0])

    tile_size = _ensure_tile_size(tile_size)
    ker = kernel or DEFAULT_SINGLE_LAYER_KERNEL

    V = torch.zeros(M, device=device, dtype=dtype)
    if M == 0 or N == 0:
        return V

    assert src_centroids.shape[0] == N, "src_centroids and sigma must have the same length"
    assert areas.shape[0] == N, "areas and sigma must have the same length"

    for i0 in range(0, M, tile_size):
        i1 = min(i0 + tile_size, M)
        chunk = targets[i0:i1]  # (T,3)
        diff = chunk[:, None, :] - src_centroids[None, :, :]  # (T,N,3)
        r = torch.linalg.norm(diff, dim=-1).clamp_min(1e-12)  # (T,N)
        K = ker.potential(diff, r)
        V[i0:i1] = torch.sum(K * sigma[None, :] * areas[None, :], dim=1)
    return V


def _bem_E_field_targets_core_torch(
    targets: Tensor,
    src_centroids: Tensor,
    areas: Tensor,
    sigma: Tensor,
    tile_size: int = 1024,
    kernel: Optional[SingleLayerKernel] = None,
) -> Tensor:
    """
    Differentiable induced E-field at arbitrary targets due to panel charges.

        E(x) = sum_j W_ij * (sigma_j * A_j) * (x_i - r_j)

    where W_ij = kernel.e_field_weight(...).

    Returns
    -------
    Tensor of shape [M, 3]
    """
    device, dtype = targets.device, targets.dtype
    M, N = int(targets.shape[0]), int(sigma.shape[0])

    tile_size = _ensure_tile_size(tile_size)
    ker = kernel or DEFAULT_SINGLE_LAYER_KERNEL

    E = torch.zeros(M, 3, device=device, dtype=dtype)
    if M == 0 or N == 0:
        return E

    assert src_centroids.shape[0] == N, "src_centroids and sigma must have the same length"
    assert areas.shape[0] == N, "areas and sigma must have the same length"

    for i0 in range(0, M, tile_size):
        i1 = min(i0 + tile_size, M)
        chunk = targets[i0:i1]  # (T,3)
        diff = chunk[:, None, :] - src_centroids[None, :, :]  # (T,N,3)
        r = torch.linalg.norm(diff, dim=-1).clamp_min(1e-12)  # (T,N)

        weight = ker.e_field_weight(diff, r)  # (T,N)
        w = weight * sigma[None, :] * areas[None, :]  # (T,N)
        # Weighted sum over sources
        E[i0:i1] = torch.sum(w[..., None] * diff, dim=1)
    return E


# --------------------------------------------------------------------------------------
# Non-diff implementations (best-effort KeOps, else tiled Torch); safe fallbacks
# --------------------------------------------------------------------------------------


def _bem_matvec_torch_tiled(
    sigma: Tensor,
    src_centroids: Tensor,
    areas: Tensor,
    tile_size: int,
    self_integrals: Optional[Tensor],
    logger: Optional[JsonlLogger] = None,
    kernel: Optional[SingleLayerKernel] = None,
) -> Tensor:
    """
    Pure Torch non-differentiable matvec with explicit tiling.

    Kept as a separate helper so we can force this path in tests if needed.
    """
    device = sigma.device
    tile_size = _ensure_tile_size(tile_size)
    N = int(sigma.shape[0])

    with torch.no_grad():
        _log_tensor_stats(logger, "bem_matvec_torch_tiled_sigma", sigma, level="debug")
        _log_tensor_stats(logger, "bem_matvec_torch_tiled_areas", areas, level="debug")

        V = _bem_matvec_core_torch(
            centroids=src_centroids,
            areas=areas,
            sigma=sigma,
            self_integrals=self_integrals,
            tile_size=tile_size,
            kernel=kernel,
        )

        # Safety check: clamp any non-finite outputs to zero and log.
        if not torch.all(torch.isfinite(V)):
            if logger is not None:
                logger.error(
                    "Non-finite entries detected in _bem_matvec_torch_tiled output; "
                    "clamping to zero.",
                )
            V = torch.where(torch.isfinite(V), V, torch.zeros_like(V))

    if logger is not None:
        logger.debug(
            "Torch tiled matvec completed.",
            N=int(N),
            tile_size=int(tile_size),
            device=str(device),
        )
    return V


def _bem_matvec_keops(
    sigma: Tensor,
    src_centroids: Tensor,
    areas: Tensor,
    self_integrals: Optional[Tensor],
    logger: Optional[JsonlLogger] = None,
    kernel: Optional[SingleLayerKernel] = None,
) -> Tensor:
    """
    KeOps-based non-differentiable matvec.

    This path is optional and will raise if KeOps is not available; callers
    are expected to catch and fall back to a Torch implementation.

    Currently only supports the Laplace single-layer kernel.
    """
    if not USE_KEOPS or LazyTensor is None:
        raise RuntimeError("KeOps backend not available.")

    if kernel is not None and not isinstance(kernel, LaplaceSingleLayerKernel):
        raise ValueError(
            "KeOps matvec backend currently only supports LaplaceSingleLayerKernel."
        )

    N = int(sigma.shape[0])
    if N == 0:
        return torch.zeros_like(sigma)

    device = sigma.device

    # KeOps uses (N,1,3) and (1,N,3) layouts for broadcasting.
    X_i = LazyTensor(src_centroids[:, None, :])  # (N,1,3)
    X_j = LazyTensor(src_centroids[None, :, :])  # (1,N,3)
    Sigma_j = LazyTensor(sigma[None, :, None])  # (1,N,1)
    Area_j = LazyTensor(areas[None, :, None])  # (1,N,1)

    # Integer indices for diagonal mask
    idx = torch.arange(N, device=device, dtype=torch.int64)
    I = LazyTensor(idx[:, None, None])
    J = LazyTensor(idx[None, :, None])
    is_diag = (I == J)

    D2_ij = ((X_i - X_j) ** 2).sum(-1)  # (N,N,1)
    eps = 1e-18
    inv_r = (1.0 / (D2_ij + eps).sqrt())
    K_ij = K_E * inv_r  # Laplace kernel

    V = (K_ij * (1 - is_diag) * Sigma_j * Area_j).sum(dim=1).view(N)
    if self_integrals is not None:
        V = V + self_integrals * sigma * areas

    if logger is not None:
        logger.debug("KeOps matvec completed.", N=int(N), device=str(device))
    return V


def _bem_potential_targets_keops(
    targets: Tensor,
    src_centroids: Tensor,
    areas: Tensor,
    sigma: Tensor,
    logger: Optional[JsonlLogger] = None,
    kernel: Optional[SingleLayerKernel] = None,
) -> Tensor:
    """
    KeOps-based non-differentiable potential at arbitrary targets.

    Currently only supports the Laplace single-layer kernel.
    """
    if not USE_KEOPS or LazyTensor is None:
        raise RuntimeError("KeOps backend not available.")

    if kernel is not None and not isinstance(kernel, LaplaceSingleLayerKernel):
        raise ValueError(
            "KeOps potential backend currently only supports LaplaceSingleLayerKernel."
        )

    device = targets.device
    dtype = targets.dtype
    M, N = int(targets.shape[0]), int(sigma.shape[0])

    if M == 0 or N == 0:
        return torch.zeros(M, device=device, dtype=dtype)

    # (M,1,3) and (1,N,3) layouts
    X_i = LazyTensor(targets[:, None, :])  # (M,1,3)
    X_j = LazyTensor(src_centroids[None, :, :])  # (1,N,3)
    Sigma_j = LazyTensor(sigma[None, :, None])  # (1,N,1)
    Area_j = LazyTensor(areas[None, :, None])  # (1,N,1)

    D2_ij = ((X_i - X_j) ** 2).sum(-1)  # (M,N,1)
    eps = 1e-18
    inv_r = 1.0 / (D2_ij + eps).sqrt()
    K_ij = K_E * inv_r  # Laplace kernel

    V = (K_ij * Sigma_j * Area_j).sum(dim=1).view(M)

    if logger is not None:
        logger.debug(
            "KeOps potential targets completed.",
            M=int(M),
            N=int(N),
            device=str(device),
        )
    return V


def _bem_E_field_targets_keops(
    targets: Tensor,
    src_centroids: Tensor,
    areas: Tensor,
    sigma: Tensor,
    logger: Optional[JsonlLogger] = None,
    kernel: Optional[SingleLayerKernel] = None,
) -> Tensor:
    """
    KeOps-based non-differentiable E-field at arbitrary targets.

    Currently only supports the Laplace single-layer kernel.
    """
    if not USE_KEOPS or LazyTensor is None:
        raise RuntimeError("KeOps backend not available.")

    if kernel is not None and not isinstance(kernel, LaplaceSingleLayerKernel):
        raise ValueError(
            "KeOps E-field backend currently only supports LaplaceSingleLayerKernel."
        )

    device = targets.device
    dtype = targets.dtype
    M, N = int(targets.shape[0]), int(sigma.shape[0])

    if M == 0 or N == 0:
        return torch.zeros(M, 3, device=device, dtype=dtype)

    # (M,1,3) and (1,N,3) layouts
    X_i = LazyTensor(targets[:, None, :])  # (M,1,3)
    X_j = LazyTensor(src_centroids[None, :, :])  # (1,N,3)
    SigmaA_j = LazyTensor((sigma * areas)[None, :, None])  # (1,N,1)

    D_ij = X_i - X_j  # (M,N,3)
    D2_ij = (D_ij ** 2).sum(-1)  # (M,N,1)
    eps = 1e-18
    inv_r = 1.0 / (D2_ij + eps).sqrt()
    inv_r3 = inv_r * inv_r * inv_r  # (M,N,1)

    coef_ij = K_E * SigmaA_j * inv_r3  # (M,N,1)
    E_ij = coef_ij * D_ij  # (M,N,3)
    E = E_ij.sum(dim=1).view(M, 3)

    if logger is not None:
        logger.debug(
            "KeOps E-field targets completed.",
            M=int(M),
            N=int(N),
            device=str(device),
        )
    return E


# --------------------------------------------------------------------------------------
# Public non-diff matvec: GPU-friendly, backend-selectable
# --------------------------------------------------------------------------------------


def bem_matvec_gpu(
    sigma: Tensor,
    src_centroids: Tensor,
    areas: Tensor,
    *,
    tile_size: int = 1024,
    self_integrals: Optional[Tensor] = None,
    logger: Optional[JsonlLogger] = None,
    use_keops: bool = False,
    kernel: Optional[SingleLayerKernel] = None,
    backend: str = "auto",
    matvec_impl: Optional[Callable[..., Tensor]] = None,
    **kwargs,
) -> Tensor:
    """
    Matrix-free potential: V = Sum_j K_ij * (sigma_j * area_j)

    Arguments
    ---------
    sigma : (N,) tensor
        Surface charge density on each panel.
    src_centroids : (N,3) tensor
        Panel centroids.
    areas : (N,) tensor
        Panel areas.

    Keyword-only
    ------------
    tile_size : int
        Tile size for Torch-based implementations.
    self_integrals : (N,) tensor or None
        Optional diagonal replacement.
    logger : JsonlLogger or None
        Logger for diagnostics.
    use_keops : bool
        Legacy flag; prefer backend="keops" or backend="auto".
    kernel : SingleLayerKernel or None
        Green's function / physics prior. Defaults to LaplaceSingleLayerKernel.
    backend : {"auto", "torch_tiled", "keops", "external"}
        Backend selection.
    matvec_impl : callable or None
        Custom matvec implementation used when backend="external".
    kwargs :
        - self_correction : alias for self_integrals (for compatibility).
        - use_near_quad : accepted but currently ignored; kept for API stability.

    Notes
    -----
    - This function is intentionally non-differentiable (uses no_grad through
      the internal Torch path).
    - It is safe to use as the A(x) callback for GMRES.
    """
    # compatibility alias for older call sites / tests
    if "self_correction" in kwargs and self_integrals is None:
        self_integrals = kwargs.get("self_correction")

    # Accept but ignore near-field quadrature flag for now
    if "use_near_quad" in kwargs and logger is not None:
        logger.debug(
            "bem_matvec_gpu called with use_near_quad; "
            "near-field quadrature not implemented in this backend."
        )

    if backend not in {"auto", "torch_tiled", "keops", "external"}:
        raise ValueError(f"Unknown BEM backend: {backend!r}")

    ker = kernel or DEFAULT_SINGLE_LAYER_KERNEL
    N = int(sigma.shape[0])
    tile_size = _ensure_tile_size(tile_size)

    # Optional external backend hook (e.g., FMM or H-matrix)
    if backend == "external":
        if matvec_impl is None:
            raise ValueError("backend='external' requires matvec_impl.")
        return matvec_impl(
            sigma=sigma,
            src_centroids=src_centroids,
            areas=areas,
            tile_size=tile_size,
            self_integrals=self_integrals,
            logger=logger,
            kernel=ker,
            **kwargs,
        )

    effective_backend = "torch_tiled"

    # Optional KeOps path (auto / explicit)
    if backend in {"auto", "keops"}:
        want_keops = (
            backend == "keops"
            or use_keops
            or os.environ.get("EDE_BEM_USE_KEOPS", "0") == "1"
        )

        if want_keops:
            if not USE_KEOPS:
                if logger is not None:
                    logger.warning(
                        "KeOps requested but not available; falling back to torch tiled."
                    )
            elif N < 2048:
                if logger is not None:
                    logger.debug("N too small for KeOps; using torch tiled.", N=int(N))
            else:
                try:
                    out = _bem_matvec_keops(
                        sigma=sigma,
                        src_centroids=src_centroids,
                        areas=areas,
                        self_integrals=self_integrals,
                        logger=logger,
                        kernel=ker,
                    )
                    effective_backend = "keops"
                    if logger is not None:
                        logger.info(
                            "BEM matvec using KeOps backend.",
                            N=int(N),
                            kernel=ker.name,
                        )
                    return out
                except Exception as exc:  # pragma: no cover - defensive
                    if logger is not None:
                        logger.error(
                            "KeOps matvec failed; falling back to torch tiled.",
                            error=str(exc),
                            exc_info=True,
                        )

    # Torch tiled path
    V = _bem_matvec_torch_tiled(
        sigma=sigma,
        src_centroids=src_centroids,
        areas=areas,
        tile_size=tile_size,
        self_integrals=self_integrals,
        logger=logger,
        kernel=ker,
    )

    if logger is not None:
        logger.info(
            "BEM matvec completed.",
            backend=effective_backend,
            N=int(N),
            tile_size=int(tile_size),
            kernel=ker.name,
        )
    return V


# --------------------------------------------------------------------------------------
# Batched matvec for dictionary building / sparse regression (Pattern 1)
# --------------------------------------------------------------------------------------


def bem_matvec_batched(
    sigma: Tensor,
    src_centroids: Tensor,
    areas: Tensor,
    *,
    tile_size: int = 1024,
    self_integrals: Optional[Tensor] = None,
    kernel: Optional[SingleLayerKernel] = None,
    logger: Optional[JsonlLogger] = None,
) -> Tensor:
    """
    Batched matrix-vector apply for dictionary building / sparse regression.

    Parameters
    ----------
    sigma : (N,) or (B, N) tensor
        If 1D, behaves like `bem_matvec_diff`.
        If 2D, B independent sigma vectors are applied in one pass.

    Returns
    -------
    V : (N,) or (B, N) tensor
    """
    if sigma.ndim == 1:
        # Call the differentiable version as this path is for AI/discovery
        return bem_matvec_diff(
            sigma,
            src_centroids,
            areas,
            tile_size=tile_size,
            self_integrals=self_integrals,
            kernel=kernel,
        )

    if sigma.ndim != 2:
        raise ValueError("sigma must have shape (N,) or (B, N).")

    ker = kernel or DEFAULT_SINGLE_LAYER_KERNEL
    B, N = sigma.shape
    device, dtype = sigma.device, sigma.dtype

    tile_size = _ensure_tile_size(tile_size)

    V = torch.zeros(B, N, device=device, dtype=dtype)
    if N == 0:
        return V

    assert src_centroids.shape[0] == N, "src_centroids and sigma must have the same length"
    assert areas.shape[0] == N, "areas and sigma must have the same length"

    for i0 in range(0, N, tile_size):
        i1 = min(i0 + tile_size, N)
        chunk = src_centroids[i0:i1]  # (T,3)
        diff = chunk[:, None, :] - src_centroids[None, :, :]  # (T,N,3)
        r = torch.linalg.norm(diff, dim=-1).clamp_min(1e-12)  # (T,N)
        K = ker.potential(diff, r)  # (T,N)

        # Diagonal indices
        arng = torch.arange(i0, i1, device=device)
        local_idx = torch.arange(i1 - i0, device=device)

        if self_integrals is not None:
            # replace diagonal
            K[local_idx, arng] = self_integrals[arng]
        else:
            # zero diagonal (consistency with FMM/KeOps)
            K[local_idx, arng] = 0.0

        # Broadcast across batch: (1,T,N) * (B,1,N) * (1,1,N) -> (B,T,N)
        contrib = (
            K[None, :, :] * sigma[:, None, :] * areas[None, None, :]
        )
        V[:, i0:i1] = contrib.sum(dim=-1)

    if logger is not None:
        logger.debug(
            "Batched matvec completed.",
            B=int(B),
            N=int(N),
            tile_size=int(tile_size),
            kernel=ker.name,
        )
    return V


# --------------------------------------------------------------------------------------
# Non-diff potentials / fields at targets (GPU aware, KeOps-capable)
# --------------------------------------------------------------------------------------


def bem_potential_targets(
    targets: Tensor,
    src_centroids: Tensor,
    areas: Tensor,
    sigma: Tensor,
    tile_size: int = 1024,
    *,
    logger: Optional[JsonlLogger] = None,
    use_keops: bool = False,
    kernel: Optional[SingleLayerKernel] = None,
    backend: str = "auto",
) -> Tensor:
    """
    Evaluate induced potential at arbitrary targets due to panel charges (non-diff wrapper).

    Backend selection is analogous to `bem_matvec_gpu`.
    """
    if backend not in {"auto", "torch_tiled", "keops"}:
        raise ValueError(f"Unknown backend for bem_potential_targets: {backend!r}")

    ker = kernel or DEFAULT_SINGLE_LAYER_KERNEL
    M, N = int(targets.shape[0]), int(sigma.shape[0])
    tile_size = _ensure_tile_size(tile_size)

    effective_backend = "torch_tiled"

    if backend in {"auto", "keops"}:
        want_keops = (
            backend == "keops"
            or use_keops
            or os.environ.get("EDE_BEM_USE_KEOPS", "0") == "1"
        )
        if want_keops:
            if not USE_KEOPS:
                if logger is not None:
                    logger.warning(
                        "KeOps requested for potential targets but not available; "
                        "falling back to torch tiled."
                    )
            else:
                try:
                    out = _bem_potential_targets_keops(
                        targets=targets,
                        src_centroids=src_centroids,
                        areas=areas,
                        sigma=sigma,
                        logger=logger,
                        kernel=ker,
                    )
                    effective_backend = "keops"
                    if logger is not None:
                        logger.info(
                            "BEM potential targets using KeOps backend.",
                            M=int(M),
                            N=int(N),
                            kernel=ker.name,
                        )
                    return out
                except Exception as exc:  # pragma: no cover - defensive
                    if logger is not None:
                        logger.error(
                            "KeOps potential targets failed; falling back to torch tiled.",
                            error=str(exc),
                            exc_info=True,
                        )

    # Torch path
    with torch.no_grad():
        V = _bem_potential_targets_core_torch(
            targets=targets,
            src_centroids=src_centroids,
            areas=areas,
            sigma=sigma,
            tile_size=tile_size,
            kernel=ker,
        )
        if not torch.all(torch.isfinite(V)):
            if logger is not None:
                logger.error(
                    "Non-finite entries detected in bem_potential_targets output; "
                    "clamping to zero.",
                )
            V = torch.where(torch.isfinite(V), V, torch.zeros_like(V))

    if logger is not None:
        logger.info(
            "BEM potential targets completed.",
            backend=effective_backend,
            M=int(M),
            N=int(N),
            tile_size=int(tile_size),
            kernel=ker.name,
        )
    return V


def bem_E_field_targets(
    targets: Tensor,
    src_centroids: Tensor,
    areas: Tensor,
    sigma: Tensor,
    tile_size: int = 1024,
    *,
    logger: Optional[JsonlLogger] = None,
    use_keops: bool = False,
    kernel: Optional[SingleLayerKernel] = None,
    backend: str = "auto",
) -> Tensor:
    """
    Evaluate induced E-field at arbitrary targets due to panel charges (non-diff wrapper).

    Returns
    -------
    Tensor of shape [M, 3]
    """
    if backend not in {"auto", "torch_tiled", "keops"}:
        raise ValueError(f"Unknown backend for bem_E_field_targets: {backend!r}")

    ker = kernel or DEFAULT_SINGLE_LAYER_KERNEL
    M, N = int(targets.shape[0]), int(sigma.shape[0])
    tile_size = _ensure_tile_size(tile_size)

    effective_backend = "torch_tiled"

    if backend in {"auto", "keops"}:
        want_keops = (
            backend == "keops"
            or use_keops
            or os.environ.get("EDE_BEM_USE_KEOPS", "0") == "1"
        )
        if want_keops:
            if not USE_KEOPS:
                if logger is not None:
                    logger.warning(
                        "KeOps requested for E-field targets but not available; "
                        "falling back to torch tiled."
                    )
            else:
                try:
                    out = _bem_E_field_targets_keops(
                        targets=targets,
                        src_centroids=src_centroids,
                        areas=areas,
                        sigma=sigma,
                        logger=logger,
                        kernel=ker,
                    )
                    effective_backend = "keops"
                    if logger is not None:
                        logger.info(
                            "BEM E-field targets using KeOps backend.",
                            M=int(M),
                            N=int(N),
                            kernel=ker.name,
                        )
                    return out
                except Exception as exc:  # pragma: no cover - defensive
                    if logger is not None:
                        logger.error(
                            "KeOps E-field targets failed; falling back to torch tiled.",
                            error=str(exc),
                            exc_info=True,
                        )

    with torch.no_grad():
        E = _bem_E_field_targets_core_torch(
            targets=targets,
            src_centroids=src_centroids,
            areas=areas,
            sigma=sigma,
            tile_size=tile_size,
            kernel=ker,
        )
        if not torch.all(torch.isfinite(E)):
            if logger is not None:
                logger.error(
                    "Non-finite entries detected in bem_E_field_targets output; "
                    "clamping to zero.",
                )
            E = torch.where(torch.isfinite(E), E, torch.zeros_like(E))

    if logger is not None:
        logger.info(
            "BEM E-field targets completed.",
            backend=effective_backend,
            M=int(M),
            N=int(N),
            tile_size=int(tile_size),
            kernel=ker.name,
        )
    return E


# --------------------------------------------------------------------------------------
# Explicit differentiable public APIs (Pattern 3)
# --------------------------------------------------------------------------------------


def bem_matvec_diff(
    sigma: Tensor,
    src_centroids: Tensor,
    areas: Tensor,
    *,
    tile_size: int = 1024,
    self_integrals: Optional[Tensor] = None,
    kernel: Optional[SingleLayerKernel] = None,
) -> Tensor:
    """
    Differentiable single-layer matvec.

    Use this inside differentiable optimization loops (Pattern 3).
    """
    return _bem_matvec_core_torch(
        centroids=src_centroids,
        areas=areas,
        sigma=sigma,
        self_integrals=self_integrals,
        tile_size=tile_size,
        kernel=kernel,
    )


def bem_potential_targets_diff(
    targets: Tensor,
    src_centroids: Tensor,
    areas: Tensor,
    sigma: Tensor,
    tile_size: int = 1024,
    kernel: Optional[SingleLayerKernel] = None,
) -> Tensor:
    """
    Differentiable induced potential at arbitrary targets.
    """
    return _bem_potential_targets_core_torch(
        targets=targets,
        src_centroids=src_centroids,
        areas=areas,
        sigma=sigma,
        tile_size=tile_size,
        kernel=kernel,
    )


def bem_E_field_targets_diff(
    targets: Tensor,
    src_centroids: Tensor,
    areas: Tensor,
    sigma: Tensor,
    tile_size: int = 1024,
    kernel: Optional[SingleLayerKernel] = None,
) -> Tensor:
    """
    Differentiable induced E-field at arbitrary targets.
    """
    return _bem_E_field_targets_core_torch(
        targets=targets,
        src_centroids=src_centroids,
        areas=areas,
        sigma=sigma,
        tile_size=tile_size,
        kernel=kernel,
    )


__all__ = [
    # core kernels
    "_bem_matvec_core_torch",
    "_bem_potential_targets_core_torch",
    "_bem_E_field_targets_core_torch",
    # non-diff APIs
    "bem_matvec_gpu",
    "bem_matvec_batched",
    "bem_potential_targets",
    "bem_E_field_targets",
    # diff APIs
    "bem_matvec_diff",
    "bem_potential_targets_diff",
    "bem_E_field_targets_diff",
    # kernel abstractions
    "SingleLayerKernel",
    "LaplaceSingleLayerKernel",
    "DEFAULT_SINGLE_LAYER_KERNEL",
    "have_keops",
]
================================================================================
===== END FILE: code\bem_kernel.py =====
================================================================================

================================================================================
===== BEGIN FILE: code\collocation.py =====
================================================================================

from __future__ import annotations

import logging
import math
from typing import Any, Dict, List, Optional, Tuple, Union

import numpy as np
import torch
from electrodrive.utils.config import EPS_0, K_E

from electrodrive.orchestration.parser import CanonicalSpec
from electrodrive.core.images import (
    AnalyticSolution,
    potential_plane_halfspace,
    potential_sphere_grounded,
    potential_line_cylinder2d_grounded,
    potential_parallel_planes_subset,
)
from electrodrive.learn.encoding import encode_spec, ENCODING_DIM
from electrodrive.fmm3d.logging_utils import ConsoleLogger
from electrodrive.debug import bem_intercept

try:
    # BEM is optional for CPU-only / minimal installs.
    from electrodrive.core.bem import bem_solve, BEMSolution  # type: ignore
    from electrodrive.utils.config import BEMConfig

    BEM_AVAILABLE = True
except Exception:  # pragma: no cover - handled gracefully at runtime
    from typing import Any as _AnyType  # fallback for type checking

    bem_solve = None  # type: ignore
    BEMSolution = _AnyType  # type: ignore
    BEMConfig = _AnyType  # type: ignore
    BEM_AVAILABLE = False


logger = logging.getLogger("EDE.Learn.Collocation")


class _NullLogger:
    """Minimal no-op logger for BEM oracles when we don't want console spam.

    Matches the .info/.warning/.error interface expected by bem_solve but
    silently drops all messages. Callers can still pass an explicit logger
    via bem_cfg["logger"] when verbose logging is desired.
    """

    def info(self, *args: Any, **kwargs: Any) -> None:
        pass

    def debug(self, *args: Any, **kwargs: Any) -> None:
        pass

    def warning(self, *args: Any, **kwargs: Any) -> None:
        pass

    def error(self, *args: Any, **kwargs: Any) -> None:
        pass


OracleSolution = Union[AnalyticSolution, "BEMSolution"]


# ---------------------------------------------------------------------------
# Analytic oracle selection (mirrors electrodrive.learn.dataset)
# ---------------------------------------------------------------------------


def _solve_analytic(spec: CanonicalSpec) -> Optional[AnalyticSolution]:
    """
    Try to construct an AnalyticSolution for a small set of canonical
    geometries.

    This mirrors the logic historically implemented in the learning
    stack and is intentionally conservative: if any of the structural
    checks fail, we return None and let the caller fall back to BEM.
    """
    ctypes = (
        sorted({c.get("type") for c in spec.conductors})
        if spec.conductors
        else []
    )

    # --- 1) Single grounded plane + single point charge ---
    if (
        ctypes == ["plane"]
        and len(spec.conductors) == 1
        and len(spec.charges) == 1
        and spec.charges[0]["type"] == "point"
    ):
        q = spec.charges[0]["q"]
        r0 = tuple(spec.charges[0]["pos"])
        c = spec.conductors[0]
        if (
            c.get("z", 0.0) == 0.0
            and c.get("potential", 0.0) == 0.0
            and r0[2] > 0
        ):
            return potential_plane_halfspace(q, r0)

    # --- 2) Single grounded sphere + single point charge ---
    if (
        ctypes == ["sphere"]
        and len(spec.conductors) == 1
        and len(spec.charges) == 1
        and spec.charges[0]["type"] == "point"
    ):
        q = spec.charges[0]["q"]
        r0 = tuple(spec.charges[0]["pos"])
        c = spec.conductors[0]
        radius = c.get("radius")
        center = tuple(c.get("center", [0.0, 0.0, 0.0]))
        if radius is not None and c.get("potential", 0.0) == 0.0:
            return potential_sphere_grounded(
                q,
                r0,
                center,
                float(radius),
            )

    # --- 3) Cylinder / line-charge 2D image construction ---
    if (
        ("cylinder" in ctypes or "cylinder2D" in ctypes)
        and len(spec.conductors) == 1
        and len(spec.charges) == 1
        and spec.charges[0]["type"] in ("line_charge", "line")
    ):
        lambda_c = spec.charges[0].get("lambda")
        r0_2d = spec.charges[0].get("pos_2d")
        c = spec.conductors[0]
        radius = c.get("radius")
        potential = c.get("potential", 0.0)
        if (
            lambda_c is not None
            and r0_2d is not None
            and radius is not None
            and potential == 0.0
        ):
            return potential_line_cylinder2d_grounded(
                float(lambda_c),
                float(radius),
                tuple(r0_2d),
            )

    # --- 4) Parallel grounded planes + central point charge ---
    if (
        ctypes == ["plane"]
        and len(spec.conductors) == 2
        and len(spec.charges) == 1
        and spec.charges[0]["type"] == "point"
    ):
        z1 = spec.conductors[0].get("z")
        z2 = spec.conductors[1].get("z")
        p1 = spec.conductors[0].get("potential", 0.0)
        p2 = spec.conductors[1].get("potential", 0.0)
        if (
            z1 is not None
            and z2 is not None
            and p1 == 0.0
            and p2 == 0.0
            and abs(z1 + z2) < 1e-6
        ):
            d = abs(float(z1))
            q = spec.charges[0]["q"]
            r0 = tuple(spec.charges[0]["pos"])
            if abs(r0[2]) < d:
                return potential_parallel_planes_subset(
                    q,
                    r0,
                    d,
                    N_terms=30,
                )

    return None


# ---------------------------------------------------------------------------
# Oracle selection / BEM configuration
# ---------------------------------------------------------------------------


def get_oracle_solution(
    spec: CanonicalSpec,
    mode: str,
    bem_cfg: Dict[str, Any],
) -> Optional[OracleSolution]:
    """
    Select and construct a field oracle for a given spec.

    For analytic / image-charge geometries we expect the analytic shortcut
    and the BEM oracle to agree on a shared set of collocation points.

    For BEM oracles, we bias toward:
      * fp64 for numerical stability
      * GPU if available (do not force CPU)
      * near-field quadrature at evaluation points
        (but not in the GMRES matvec, which is expensive and CPU-only)
    """
    sol: Optional[OracleSolution] = None

    # 1) Analytic path (if explicitly requested or allowed by "auto").
    if mode in ("analytic", "auto"):
        try:
            sol = _solve_analytic(spec)
        except Exception:
            sol = None

    # 2) BEM oracle path.
    if sol is None and mode in ("bem", "auto") and BEM_AVAILABLE:
        try:
            cfg = BEMConfig()

            # Apply caller overrides first.
            if bem_cfg is None:
                bem_cfg = {}

            # Allow callers to override the BEM logger explicitly; by default
            # we use a quiet in-memory logger to avoid stdout/stderr issues.
            log_obj = bem_cfg.get("logger", None)
            if log_obj is None:
                log_obj = _NullLogger()

            has_near_quad_cfg = "use_near_quadrature" in bem_cfg
            has_near_quad_mv_cfg = "use_near_quadrature_matvec" in bem_cfg
            for k, v in bem_cfg.items():
                if k == "logger":
                    # handled separately
                    continue
                try:
                    setattr(cfg, k, v)
                except Exception:
                    continue

            # fp64 for stability.
            cfg.fp64 = True
            # IMPORTANT: do NOT force use_gpu here. Let cfg.use_gpu and the
            # caller config decide. On your machine, GPU is the fast path.

            # Disable near-smoothing; we want the raw Green's function.
            if hasattr(cfg, "near_alpha"):
                cfg.near_alpha = 0.0

            # Refinement: allow at least 3 passes if the caller didn't
            # already ask for more.
            try:
                base_max = int(getattr(cfg, "max_refine_passes", 3) or 3)
            except Exception:
                base_max = 3
            cfg.max_refine_passes = max(base_max, 3)

            try:
                base_min = int(getattr(cfg, "min_refine_passes", 1) or 1)
            except Exception:
                base_min = 1
            cfg.min_refine_passes = max(base_min, 1)

            # Use tight GMRES tolerance; don't loosen it.
            try:
                gmres_tol = float(getattr(cfg, "gmres_tol", 5e-8))
            except Exception:
                gmres_tol = 5e-8
            cfg.gmres_tol = min(gmres_tol, 5e-8)

            # Evaluation near-quadrature: good for potentials near surfaces.
            if hasattr(cfg, "use_near_quadrature") and not has_near_quad_cfg:
                cfg.use_near_quadrature = True
            if hasattr(cfg, "use_near_quadrature_matvec") and not has_near_quad_mv_cfg:
                # Default behaviour: keep GMRES matvec inexpensive unless the
                # caller explicitly opts in via bem_cfg.
                cfg.use_near_quadrature_matvec = False

            # Use either the caller-provided logger or a quiet no-op logger by
            # default. Callers can still pass ConsoleLogger() explicitly via
            # bem_cfg["logger"] if they want stdout JSON logs.
            out = bem_solve(spec, cfg, log_obj)  # type: ignore[arg-type]
            if isinstance(out, dict) and "solution" in out:
                sol = out["solution"]
        except Exception as e:  # pragma: no cover - defensive
            logger.error("BEM oracle failed: %s", e)

    return sol


# ---------------------------------------------------------------------------
# Collocation sampling + oracle evaluation
# ---------------------------------------------------------------------------

# Simple identity-based cache so repeated calls for the *same* CanonicalSpec
# (e.g. across epochs in ElectrostaticsJITDataset) reuse the expensive BEM
# solution instead of re-solving from scratch.
_ORACLE_CACHE: Dict[
    Tuple[int, str, Tuple[Tuple[str, str], ...]], OracleSolution
] = {}


def _bem_cfg_cache_key(bem_cfg: Dict[str, Any]) -> Tuple[Tuple[str, str], ...]:
    """
    Represent a config dict as a sorted tuple of stringified (k, v) pairs,
    which is stable enough for caching purposes.
    """
    return tuple(sorted((str(k), repr(v)) for k, v in bem_cfg.items()))


def _empty_batch(device: torch.device, dtype: torch.dtype) -> Dict[str, torch.Tensor]:
    """Return an all-empty collocation batch on the requested device/dtype."""
    return {
        "X": torch.zeros(0, 3, device=device, dtype=dtype),
        "V_gt": torch.zeros(0, device=device, dtype=dtype),
        "is_boundary": torch.zeros(0, device=device, dtype=torch.bool),
        "mask_finite": torch.zeros(0, device=device, dtype=torch.bool),
        "encoding": torch.zeros(0, ENCODING_DIM, device=device, dtype=dtype),
    }


def _infer_geom_type_from_spec(spec: CanonicalSpec) -> str:
    """
    Heuristic geometry label used for the fast analytic paths.

    This roughly matches the geometry heuristics used for encoding and
    curriculum synthesis.
    """
    ctypes = (
        sorted({c.get("type") for c in spec.conductors})
        if spec.conductors
        else []
    )
    if ctypes == ["plane"]:
        if len(spec.conductors) == 1:
            return "plane"
        if len(spec.conductors) == 2:
            return "parallel_planes"
    if ctypes == ["sphere"] and len(spec.conductors) == 1:
        return "sphere"
    if ("cylinder" in ctypes or "cylinder2D" in ctypes) and len(spec.conductors) == 1:
        return "cylinder2D"
    if ("torus" in ctypes or "toroid" in ctypes) and len(spec.conductors) == 1:
        return "torus"
    return "unknown"


def _infer_bbox_for_spec(spec: CanonicalSpec) -> float:
    """
    Heuristic bounding-box extent for collocation sampling.

    For planes we mirror the finite BEM plane patch extent used in
    electrodrive.core.bem_mesh.generate_mesh (L = max(8, 16 * dmin)).
    For spheres / cylinders we use a modest multiple of the radius and
    fall back to a global default otherwise.
    """
    bbox = 10.0

    conductors = getattr(spec, "conductors", None) or []
    charges = getattr(spec, "charges", None) or []

    if not conductors:
        return bbox

    for c in conductors:
        ctype = c.get("type")
        if ctype == "plane":
            z = float(c.get("z", 0.0))
            dmin = 0.3
            for ch in charges:
                if ch.get("type") != "point":
                    continue
                try:
                    zq = float(ch["pos"][2])
                except Exception:
                    continue
                dmin = max(dmin, abs(zq - z))
            L = max(8.0, 16.0 * dmin)
            return float(L)

        if ctype == "sphere":
            try:
                r = float(c.get("radius", 1.0))
            except Exception:
                continue
            return float(4.0 * r)

        if ctype in ("cylinder", "cylinder2D"):
            try:
                r = float(c.get("radius", 1.0))
            except Exception:
                continue
            return float(4.0 * r)

        if ctype in ("torus", "toroid"):
            try:
                R = float(c.get("major_radius", c.get("radius", 1.0)))
                a = float(c.get("minor_radius", 0.25 * R))
            except Exception:
                continue
            return float(4.0 * (R + a))

    return bbox


def _sample_points_for_spec(
    spec: CanonicalSpec,
    n_points: int,
    ratio_boundary: float,
    rng: np.random.Generator,
) -> Tuple[np.ndarray, torch.Tensor]:
    """
    Sample interior + boundary points for a given spec.

    This is a direct, RNG-parameterised transplant of the logic in
    ElectrostaticsJITDataset._sample_and_evaluate, but split out so it
    can be reused by the discovery engine.
    """
    N = int(n_points)
    N_boundary = int(N * float(ratio_boundary))
    N_interior = N - N_boundary
    bbox = _infer_bbox_for_spec(spec)

    # Interior: uniform box sampling
    points_int = rng.uniform(-bbox / 2.0, bbox / 2.0, (N_interior, 3))

    # For finite plane patches (single plane or parallel planes), restrict
    # interior sampling in x/y (and now z) to a central band so that the
    # finite BEM geometry is a good approximation to the infinite-plane
    # analytic shortcuts used in the image-charge formulas.
    try:
        geom = _infer_geom_type_from_spec(spec)
    except Exception:
        geom = "unknown"

    if geom in ("plane", "parallel_planes"):
        # Restrict x/y to the central 40% of the patch in each direction.
        alpha = 0.4
        points_int[:, 0] *= alpha
        points_int[:, 1] *= alpha

        # Additionally, restrict z to a band around the planes and any point
        # charges, rather than the full [-bbox/2, +bbox/2] extent. This avoids
        # sampling deep far-field regions where a finite patch deviates most
        # from the infinite-plane analytic model.
        conductors = getattr(spec, "conductors", None) or []
        charges = getattr(spec, "charges", None) or []
        z_vals: List[float] = []

        for c in conductors:
            if c.get("type") == "plane":
                try:
                    zc = float(c.get("z", 0.0))
                    z_vals.append(zc)
                except Exception:
                    continue

        for ch in charges:
            if ch.get("type") == "point":
                try:
                    pos = ch.get("pos") or ch.get("position")
                    if pos is not None:
                        zq = float(pos[2])
                        z_vals.append(zq)
                except Exception:
                    continue

        if z_vals and N_interior > 0:
            z_min = min(z_vals)
            z_max = max(z_vals)
            z_center = 0.5 * (z_min + z_max)
            # Half-span at least 0.3, plus a modest margin beyond the
            # extremal conductor/charge positions.
            half_span = max(0.3, 0.5 * (z_max - z_min))
            z_lo = z_center - 2.0 * half_span
            z_hi = z_center + 2.0 * half_span
            # Clamp to the original bbox in case of pathological specs.
            z_lo = max(z_lo, -bbox / 2.0)
            z_hi = min(z_hi, bbox / 2.0)
            if z_hi <= z_lo:
                # Fallback: use a central band of the original box.
                z_lo = -0.25 * bbox
                z_hi = 0.25 * bbox
            points_int[:, 2] = rng.uniform(z_lo, z_hi, size=N_interior)

    # Boundary: per-conductor sampling, reusing the same shape heuristics
    points_bnd_list: List[np.ndarray] = []
    conductors = getattr(spec, "conductors", None) or []
    if N_boundary > 0 and conductors:
        N_per = max(1, N_boundary // len(conductors))
        for c in conductors:
            ctype = c.get("type")
            if ctype == "plane":
                z = float(c.get("z", 0.0))
                # For plane/parallel_planes, restrict boundary sampling in x/y
                # to the same central region we use for interior points. This
                # avoids over-sampling near the patch edges where finite-patch
                # BEM and infinite-plane analytic shortcuts differ most.
                if geom in ("plane", "parallel_planes"):
                    alpha = 0.4
                    span = (bbox / 2.0) * alpha
                else:
                    span = bbox / 2.0
                xy = rng.uniform(-span, span, (N_per, 2))
                points_bnd_list.append(
                    np.c_[xy, np.full(N_per, z, dtype=float)]
                )
            elif ctype == "sphere":
                r = float(c.get("radius", 1.0))
                center = np.array(
                    c.get("center", [0.0, 0.0, 0.0]),
                    dtype=float,
                )
                vec = rng.standard_normal((N_per, 3))
                vec /= np.linalg.norm(vec, axis=1, keepdims=True) + 1e-12
                # Sample slightly off the surface
                eps = 1e-3 * r
                points_bnd_list.append(vec * (r + eps) + center)
            elif ctype in ("cylinder", "cylinder2D"):
                r = float(c.get("radius", 1.0))
                phi = rng.uniform(0.0, 2.0 * math.pi, N_per)
                z = rng.uniform(-bbox / 2.0, bbox / 2.0, N_per)
                points_bnd_list.append(
                    np.stack(
                        [
                            r * np.cos(phi),
                            r * np.sin(phi),
                            z,
                        ],
                        axis=1,
                    )
                )
            elif ctype in ("torus", "toroid"):
                R = float(c.get("major_radius", c.get("radius", 1.0)))
                a = float(c.get("minor_radius", 0.25 * R))
                center = np.array(
                    c.get("center", [0.0, 0.0, 0.0]),
                    dtype=float,
                )
                u = rng.uniform(0.0, 2.0 * math.pi, N_per)
                v = rng.uniform(0.0, 2.0 * math.pi, N_per)
                cosu = np.cos(u)
                sinu = np.sin(u)
                cosv = np.cos(v)
                sinv = np.sin(v)
                x = (R + a * cosv) * cosu
                y = (R + a * cosv) * sinu
                z = a * sinv
                pts = np.stack([x, y, z], axis=1) + center
                # Slightly push outward along approximate normal to avoid duplicate surface points.
                eps = 1e-3 * max(a, R)
                nx = cosv * cosu
                ny = cosv * sinu
                nz = sinv
                pts += np.stack([nx, ny, nz], axis=1) * eps
                points_bnd_list.append(pts)

    if points_bnd_list:
        points_bnd = np.vstack(points_bnd_list)
    else:
        points_bnd = np.empty((0, 3), dtype=float)

    N_bnd = points_bnd.shape[0]
    if N_bnd > 0:
        points_np = np.vstack([points_int, points_bnd])
    else:
        points_np = points_int

    N_total = points_np.shape[0]
    is_boundary = torch.zeros(N_total, dtype=torch.bool)
    if N_bnd > 0:
        is_boundary[-N_bnd:] = True
    return points_np, is_boundary


def _evaluate_oracle_on_points(
    spec: CanonicalSpec,
    solution: OracleSolution,
    geom_type: str,
    points_np: np.ndarray,
    device: torch.device,
    dtype: torch.dtype,
) -> torch.Tensor:
    """
    Evaluate an oracle (analytic or BEM) on a batch of 3D points.

    The analytic path keeps the optimised vectorised implementations for
    the common curriculum geometries (plane, sphere, cylinder2D) and falls
    back to AnalyticSolution.eval otherwise.  The BEM path uses
    BEMSolution.eval_V_E_batched when available.

    Note
    ----
    The fast analytic paths below intentionally work in the same "well-
    scaled" reduced units as the historical learning stack: they omit the
    global Coulomb constant K_E = 1 / (4π ε₀). As a result, BEM and
    analytic results differ by a fixed 1 / EPS_0 scale factor; unit tests
    compensate by rescaling BEM outputs when comparing analytic vs BEM.
    """
    # Analytic solution branch ------------------------------------------------
    if isinstance(solution, AnalyticSolution):
        fast_done = False
        V_gt: Optional[torch.Tensor] = None

        try:
            # 1) Grounded plane at z=0 with one point charge
            if (
                geom_type == "plane"
                and len(spec.conductors) == 1
                and len(spec.charges) == 1
                and spec.charges[0]["type"] == "point"
            ):
                c = spec.conductors[0]
                if (
                    c.get("type") == "plane"
                    and abs(c.get("z", 0.0)) < 1e-12
                    and c.get("potential", 0.0) == 0.0
                ):
                    q = float(spec.charges[0]["q"])
                    x0, y0, z0 = map(float, spec.charges[0]["pos"])
                    R = points_np - np.array([x0, y0, z0], dtype=np.float64)
                    Rm = points_np - np.array([x0, y0, -z0], dtype=np.float64)
                    r = np.linalg.norm(R, axis=1).clip(1e-9, None)
                    rm = np.linalg.norm(Rm, axis=1).clip(1e-9, None)
                    V_gt_np = K_E * (q / r - q / rm)
                    V_gt = torch.from_numpy(V_gt_np).to(device=device, dtype=dtype)
                    fast_done = True

            # 2) Grounded sphere (centered or shifted) with one point charge
            if (
                not fast_done
                and geom_type == "sphere"
                and len(spec.conductors) == 1
                and len(spec.charges) == 1
                and spec.charges[0]["type"] == "point"
            ):
                c = spec.conductors[0]
                if c.get("type") == "sphere" and c.get("potential", 0.0) == 0.0:
                    a = float(c.get("radius"))
                    cx, cy, cz = map(float, c.get("center", [0.0, 0.0, 0.0]))
                    q = float(spec.charges[0]["q"])
                    x0, y0, z0 = map(float, spec.charges[0]["pos"])
                    r0c = np.array([x0 - cx, y0 - cy, z0 - cz], dtype=np.float64)
                    r0_norm = float(np.linalg.norm(r0c)) + 1e-12
                    q_img = -(a / r0_norm) * q
                    r_img = (a * a / (r0_norm * r0_norm)) * r0c
                    r_img_world = np.array([cx, cy, cz], dtype=np.float64) + r_img
                    R = points_np - np.array([x0, y0, z0], dtype=np.float64)
                    Ri = points_np - r_img_world
                    r = np.linalg.norm(R, axis=1).clip(1e-9, None)
                    ri = np.linalg.norm(Ri, axis=1).clip(1e-9, None)
                    # Reduced units: drop the 1/ε₀ factor from K_E
                    V_gt_np = K_E * (q / r + q_img / ri)
                    V_gt = torch.from_numpy(V_gt_np).to(device=device, dtype=dtype)
                    fast_done = True

            # 3) Grounded cylinder (infinite) with 2D line charge
            #    V = (λ / (2π)) * ln(ρ / ρ'), with image at (a^2 / ρ0^2) * r0_2d
            if (
                not fast_done
                and geom_type in ("cylinder2D", "cylinder")
                and len(spec.conductors) == 1
                and len(spec.charges) == 1
                and spec.charges[0]["type"] in ("line_charge", "line")
            ):
                c = spec.conductors[0]
                if c.get("type") in ("cylinder", "cylinder2D") and c.get(
                    "potential", 0.0
                ) == 0.0:
                    a = float(c.get("radius"))
                    lam = float(spec.charges[0].get("lambda"))
                    x0, y0 = map(float, spec.charges[0].get("pos_2d"))
                    rho0 = math.hypot(x0, y0) + 1e-12
                    xi = (a * a / (rho0 * rho0)) * x0
                    yi = (a * a / (rho0 * rho0)) * y0
                    dx = points_np[:, 0] - x0
                    dy = points_np[:, 1] - y0
                    dxi = points_np[:, 0] - xi
                    dyi = points_np[:, 1] - yi
                    rho = np.sqrt(dx * dx + dy * dy).clip(1e-12, None)
                    rhoi = np.sqrt(dxi * dxi + dyi * dyi).clip(1e-12, None)
                    # Reduced units: omit global K_E prefactor
                    V_gt_np = (K_E * lam / EPS_0) * np.log(rho / rhoi)
                    V_gt = torch.from_numpy(V_gt_np).to(device=device, dtype=dtype)
                    fast_done = True
        except Exception:
            # Any failure here just drops us back to the slower scalar path.
            fast_done = False
            V_gt = None

        if not fast_done or V_gt is None:
            # `solution.eval` returns SI potentials that already include K_E.
            # The learning stack expects reduced units with the 1/ε₀ factor
            # stripped, i.e. V_reduced = ε₀ * V_SI.
            V_gt_np = np.array(
                [solution.eval(tuple(p)) for p in points_np],
                dtype=np.float64,
            )
            V_gt = torch.from_numpy(V_gt_np).to(device=device, dtype=dtype)

        return V_gt

    # BEM solution branch -----------------------------------------------------
    if BEM_AVAILABLE and hasattr(solution, "eval_V_E_batched"):
        sol_device = getattr(solution, "_device", "cpu")
        sol_dtype = getattr(solution, "_dtype", torch.float64)
        pts = torch.tensor(points_np, device=sol_device, dtype=sol_dtype)
        with torch.no_grad():
            V_gt_t, _ = solution.eval_V_E_batched(pts)  # type: ignore[operator]
        return V_gt_t.detach().to(device=device, dtype=dtype).view(-1)

    # As a last resort, treat it as a scalar-eval oracle (keep whatever units
    # the underlying solution uses; this path is rarely hit in the learning
    # stack and is not part of the BEM-vs-analytic unit bridge).
    V_gt_np = np.array(
        [solution.eval(tuple(p)) for p in points_np],
        dtype=np.float64,
    )
    return torch.from_numpy(V_gt_np).to(device=device, dtype=dtype)


def make_collocation_batch_for_spec(
    spec: CanonicalSpec,
    n_points: int,
    ratio_boundary: float,
    supervision_mode: str,  # "analytic" | "bem" | "auto"
    device: torch.device,
    dtype: torch.dtype,
    *,
    rng: Optional[np.random.Generator] = None,
    bem_oracle_config: Optional[Dict[str, Any]] = None,
    encoding: Optional[torch.Tensor] = None,
    geom_type: Optional[str] = None,
) -> Dict[str, torch.Tensor]:
    """
    Build a collocation batch (points + oracle targets) for a single spec.

    Parameters
    ----------
    spec:
        CanonicalSpec describing boundary conditions and sources.
    n_points:
        Target number of collocation points (interior + boundary).  The
        actual number may differ by at most O(#conductors) due to
        per-conductor rounding, matching the historical dataset logic.
    ratio_boundary:
        Fraction of points that should lie on the boundary.  Remaining
        points are drawn from a fixed bounding box for the interior.
    supervision_mode:
        ``"analytic"``, ``"bem"`` or ``"auto"`` — forwarded to
        :func:`get_oracle_solution`.
    device, dtype:
        Desired output device and dtype for ``"X"``, ``"V_gt"`` and
        ``"encoding"`` tensors.

    Other Parameters
    ----------------
    rng:
        Optional :class:`numpy.random.Generator` used for sampling.  If
        omitted, a fresh default RNG is constructed.
    bem_oracle_config:
        Optional dict of overrides for :class:`BEMConfig`; if omitted, a
        default config is used.
    encoding:
        Optional precomputed encoding vector for ``spec``.  If omitted,
        :func:`encode_spec` is called internally.
    geom_type:
        Optional geometry label (e.g. ``"plane"`` / ``"sphere"`` /
        ``"parallel_planes"``).  If omitted, we infer a label from
        ``spec`` via :func:`_infer_geom_type_from_spec`.

    Returns
    -------
    batch : Dict[str, torch.Tensor]
        Dictionary with keys:

        - ``"X"``:          [N, 3] collocation points
        - ``"V_gt"``:       [N] oracle potential values
        - ``"is_boundary"``: [N] bool mask
        - ``"mask_finite"``: [N] bool mask of finite targets
        - ``"encoding"``:   [N, ENCODING_DIM] broadcast spec encoding
    """
    device = torch.device(device)
    if rng is None:
        rng = np.random.default_rng()
    if bem_oracle_config is None:
        bem_oracle_config = {}

    # Oracle selection + identity-based cache --------------------------------
    cache_key = (id(spec), str(supervision_mode), _bem_cfg_cache_key(bem_oracle_config))
    solution = _ORACLE_CACHE.get(cache_key)
    if solution is None:
        solution = get_oracle_solution(spec, supervision_mode, bem_oracle_config)
        if solution is None:
            # No oracle available (e.g. BEM not installed and no analytic path).
            return _empty_batch(device=device, dtype=dtype)
        _ORACLE_CACHE[cache_key] = solution

    # Sample collocation points ----------------------------------------------
    points_np, is_boundary = _sample_points_for_spec(
        spec,
        n_points=n_points,
        ratio_boundary=ratio_boundary,
        rng=rng,
    )
    N_total = points_np.shape[0]
    if N_total == 0:
        return _empty_batch(device=device, dtype=dtype)

    is_boundary = is_boundary.to(device=device)

    # Encoding: either reuse caller-provided or build from spec.
    if encoding is None:
        encoding_single = encode_spec(spec).to(device=device, dtype=dtype)
    else:
        encoding_single = encoding.to(device=device, dtype=dtype)
    if encoding_single.dim() == 1:
        encoding_single = encoding_single.unsqueeze(0)

    encoding_batch = encoding_single.repeat(N_total, 1)

    # Evaluate oracle ---------------------------------------------------------
    if geom_type is None:
        geom_type = _infer_geom_type_from_spec(spec)

    V_gt = _evaluate_oracle_on_points(
        spec,
        solution,
        geom_type,
        points_np,
        device=device,
        dtype=dtype,
    )
    mask_finite = torch.isfinite(V_gt)

    X = torch.from_numpy(points_np).to(device=device, dtype=dtype)

    # Live intercept for diagnostics (does not affect correctness).
    try:
        ctx = bem_intercept.maybe_start_intercept(
            spec, test_name="collocation", bem_cfg=None
        )
        if ctx is not None:
            needs_eps_scaling = geom_type in ("plane", " sphere", "parallel_planes")
            bem_intercept.attach_bem_or_analytic_collocation(
                ctx,
                supervision_mode,
                geom_type,
                X,
                V_gt,
                is_boundary,
                mask_finite,
                ratio_boundary=float(ratio_boundary),
                needs_eps_scaling=needs_eps_scaling,
            )
            bem_intercept.finalize(ctx)
    except Exception:
        # Intercept must never break core logic.
        pass

    return {
        "X": X,
        "V_gt": V_gt,
        "is_boundary": is_boundary,
        "mask_finite": mask_finite,
        "encoding": encoding_batch,
    }

================================================================================
===== END FILE: code\collocation.py =====
================================================================================

================================================================================
===== BEGIN FILE: code\export_mid_axis_sweep_table.py =====
================================================================================

"""
Export axis sweep BEM metrics to CSV.
"""
from __future__ import annotations

import json
from pathlib import Path

import pandas as pd


def main() -> None:
    data = json.load(open("runs/torus/stage4_metrics_mid_axis_sweep_bem.json"))
    rows = []
    for rec in data:
        m = rec["metrics"]
        rows.append(
            {
                "z": rec["z"],
                "mean_rel": m.get("mean_rel"),
                "inner_mean_rel": m.get("inner_mean_rel"),
                "max_rel": m.get("max_rel"),
            }
        )
    df = pd.DataFrame(rows)
    out_csv = Path("staging/tables/mid_axis_sweep_bem.csv")
    out_csv.parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(out_csv, index=False)


if __name__ == "__main__":
    main()

================================================================================
===== END FILE: code\export_mid_axis_sweep_table.py =====
================================================================================

================================================================================
===== BEGIN FILE: code\mid_torus_axis_sweep.py =====
================================================================================

"""
Axis sweep for the fixed mid-torus 2-ring + 4-point geometry.

Keeps geometry from mid_bem_highres_trial02 fixed and re-solves only weights
as the source charge moves along the symmetry axis. Runs Stage-4 style metrics,
high-res BEM diagnostics, and an optional FMM matvec sanity check.
"""
from __future__ import annotations

import argparse
import copy
import json
import math
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Sequence, Tuple

import numpy as np
import torch

from electrodrive.images.io import load_image_system, save_image_system
from electrodrive.images.search import assemble_basis_matrix, solve_l1_ista, ImageSystem
from electrodrive.learn.collocation import make_collocation_batch_for_spec, get_oracle_solution
from electrodrive.orchestration.parser import CanonicalSpec
from tools.mid_torus_bem_fmm_refine import (
    RingParams,
    PointParams,
    load_seed_params,
    build_elements,
    belts_inner,
    highres_bem_diag,
)
from tools.run_grandchallenge_experiments import evaluate_system
from electrodrive.core.bem_kernel import bem_matvec_gpu, DEFAULT_SINGLE_LAYER_KERNEL

try:
    from electrodrive.fmm3d.bem_fmm import make_laplace_fmm_backend
except Exception:
    make_laplace_fmm_backend = None


class _NullLogger:
    def info(self, *args, **kwargs):
        pass

    def debug(self, *args, **kwargs):
        pass

    def warning(self, *args, **kwargs):
        pass

    def error(self, *args, **kwargs):
        pass


logger = _NullLogger()


def parse_z_list(z_str: str) -> List[float]:
    return [float(s) for s in z_str.split(",") if s.strip()]


def move_charge(spec: CanonicalSpec, z: float) -> CanonicalSpec:
    spec_z = copy.deepcopy(spec)
    for ch in spec_z.charges:
        if ch.get("type") == "point":
            ch["pos"] = [0.0, 0.0, float(z)]
    return spec_z


def solve_fixed_geometry(
    spec: CanonicalSpec,
    elements: Sequence,
    reg_l1: float,
    per_type_reg: Dict[str, float],
    boundary_weight: float,
    n_points: int,
    ratio_boundary: float,
    device: torch.device,
    dtype: torch.dtype,
) -> ImageSystem:
    batch = make_collocation_batch_for_spec(
        spec=spec,
        n_points=n_points,
        ratio_boundary=ratio_boundary,
        supervision_mode="auto",
        device=device,
        dtype=dtype,
    )
    X = batch["X"]
    V_gt = batch["V_gt"]
    mask_finite = batch.get("mask_finite")
    if mask_finite is not None and mask_finite.shape == (X.shape[0],):
        mask = mask_finite.to(device=device) & torch.isfinite(V_gt)
    else:
        mask = torch.isfinite(V_gt)
    X = X[mask]
    V_gt = V_gt[mask]
    is_boundary = batch.get("is_boundary", torch.zeros(X.shape[0], device=device, dtype=torch.bool))[mask]

    A = assemble_basis_matrix(elements, X)
    target = V_gt
    if boundary_weight is not None and is_boundary is not None and is_boundary.shape == (X.shape[0],):
        alpha = float(max(0.0, min(1.0, boundary_weight)))
        beta = 1.0 - alpha
        row_weights = torch.where(
            is_boundary.to(device=device),
            torch.full_like(is_boundary, alpha, dtype=dtype),
            torch.full_like(is_boundary, beta, dtype=dtype),
        )
        rw_sqrt = torch.sqrt(row_weights).view(-1, 1)
        A = A * rw_sqrt
        target = target * rw_sqrt.view(-1)

    reg_vec = torch.tensor([float(per_type_reg.get(e.type, reg_l1)) for e in elements], device=device, dtype=dtype)
    weights, _ = solve_l1_ista(A, target, reg_l1=reg_l1, logger=logger, per_elem_reg=reg_vec)
    return ImageSystem(list(elements), weights)


@dataclass
class AxisSweepResult:
    z: float
    stage_metrics: Dict[str, float]
    bem_metrics: Dict[str, float]
    n_images: int
    type_counts: Dict[str, int]
    system_path: Path
    npz_path: Path
    reg_l1: float
    boundary_weight: float


def try_fmm_matvec(spec: CanonicalSpec, bem_cfg: Dict[str, object]) -> Tuple[bool, Dict[str, float]]:
    if make_laplace_fmm_backend is None:
        return False, {"error": "FMM backend unavailable"}
    try:
        sol = get_oracle_solution(spec, mode="bem", bem_cfg=bem_cfg)
        if sol is None:
            return False, {"error": "BEM oracle unavailable"}
        centroids = sol._C.detach().to(device="cpu", dtype=torch.float64)  # type: ignore[attr-defined]
        areas = sol._A.detach().to(device="cpu", dtype=torch.float64)  # type: ignore[attr-defined]
        sigma = sol._S.detach().to(device="cpu", dtype=torch.float64)  # type: ignore[attr-defined]
        tile_size = int(getattr(sol, "_tile", 512))  # type: ignore[attr-defined]
        fmm = make_laplace_fmm_backend(
            src_centroids=centroids,
            areas=areas,
            max_leaf_size=64,
            theta=0.6,
            use_dipole=True,
            logger=None,
        )
        V_ref = bem_matvec_gpu(
            sigma=sigma,
            src_centroids=centroids,
            areas=areas,
            tile_size=min(tile_size, 2048),
            self_integrals=None,
            logger=None,
            use_keops=False,
            kernel=DEFAULT_SINGLE_LAYER_KERNEL,
            backend="torch_tiled",
        )
        V_fmm = bem_matvec_gpu(
            sigma=sigma,
            src_centroids=centroids,
            areas=areas,
            tile_size=min(tile_size, 2048),
            self_integrals=None,
            logger=None,
            use_keops=False,
            kernel=DEFAULT_SINGLE_LAYER_KERNEL,
            backend="external",
            matvec_impl=fmm.matvec,
        )
        diff = torch.linalg.norm(V_ref - V_fmm)
        denom = torch.linalg.norm(V_ref).clamp_min(1e-12)
        rel = float((diff / denom).item())
        return True, {"rel_l2_err": rel, "n_panels": int(centroids.shape[0])}
    except Exception as exc:
        return False, {"error": str(exc)}


def main() -> None:
    parser = argparse.ArgumentParser(description="Axis sweep for fixed 2-ring + 4-point geometry on mid torus.")
    parser.add_argument("--z-list", type=str, default="0.4,0.5,0.6,0.7,0.8,0.9")
    parser.add_argument("--n-colloc", type=int, default=3072)
    parser.add_argument("--ratio-boundary", type=float, default=0.8)
    parser.add_argument("--reg-l1", type=float, default=4e-4)
    parser.add_argument("--point-reg-mult", type=float, default=4.0)
    parser.add_argument("--boundary-weight", type=float, default=0.9)
    parser.add_argument("--nr", type=int, default=220)
    parser.add_argument("--nz", type=int, default=220)
    parser.add_argument("--out-metrics", type=Path, default=Path("runs/torus/stage4_metrics_mid_axis_sweep_stage4.json"))
    parser.add_argument("--out-bem-metrics", type=Path, default=Path("runs/torus/stage4_metrics_mid_axis_sweep_bem.json"))
    parser.add_argument("--discovered-root", type=Path, default=Path("runs/torus/discovered"))
    parser.add_argument("--diagnostics-root", type=Path, default=Path("runs/torus/diagnostics"))
    parser.add_argument("--geometry-path", type=Path, default=Path("runs/torus/discovered/mid_bem_highres_trial02/discovered_system.json"))
    parser.add_argument("--fmm-check", action="store_true", help="Attempt FMM matvec sanity check for z=0.7")
    args = parser.parse_args()

    root = Path(__file__).resolve().parents[1]
    spec = CanonicalSpec.from_json(json.load(open(root / "specs" / "torus_axis_point_mid.json")))
    torus = next(c for c in spec.conductors if c.get("type") in ("torus", "toroid"))
    center = torch.tensor(torus.get("center", [0.0, 0.0, 0.0]), device="cuda" if torch.cuda.is_available() else "cpu", dtype=torch.float32)
    device = center.device
    dtype = torch.float32

    rings_seed, pts_seed = load_seed_params(root / args.geometry_path)
    belts = belts_inner(spec)

    bem_cfg = {
        "use_gpu": True,
        "fp64": True,
        "initial_h": 0.15,
        "max_refine_passes": 5,
        "min_refine_passes": 2,
        "gmres_tol": 1e-8,
        "target_bc_inf_norm": 1e-8,
        "use_near_quadrature": True,
        "use_near_quadrature_matvec": False,
        "tile_mem_divisor": 2.5,
        "target_vram_fraction": 0.9,
        "logger": logger,
    }

    z_vals = parse_z_list(args.z_list)
    stage_metrics: List[Dict[str, object]] = []
    bem_metrics: List[Dict[str, object]] = []

    for z in z_vals:
        spec_z = move_charge(spec, z)
        elems = build_elements(rings_seed, pts_seed, center=center, device=device, dtype=dtype)
        per_type_reg = {"poloidal_ring": args.reg_l1, "point": args.reg_l1 * args.point_reg_mult}
        system = solve_fixed_geometry(
            spec=spec_z,
            elements=elems,
            reg_l1=args.reg_l1,
            per_type_reg=per_type_reg,
            boundary_weight=args.boundary_weight,
            n_points=args.n_colloc,
            ratio_boundary=args.ratio_boundary,
            device=device,
            dtype=dtype,
        )
        # Stage-style metrics
        stage_res = evaluate_system(spec_z, system, n_eval=args.n_colloc, ratio_boundary=args.ratio_boundary, belts=belts)
        sys_dir = root / args.discovered_root / f"mid_axis_sweep_z{z:.2f}"
        save_image_system(system, sys_dir / "discovered_system.json", metadata={"z": z, "reg_l1": args.reg_l1, "boundary_weight": args.boundary_weight})

        stage_rec = {
            "z": z,
            "metrics": stage_res.metrics,
            "n_images": len(system.elements),
            "type_counts": stage_res.type_counts,
            "reg_l1": args.reg_l1,
            "boundary_weight": args.boundary_weight,
            "system_path": str(sys_dir / "discovered_system.json"),
        }
        stage_metrics.append(stage_rec)

        npz_path = root / args.diagnostics_root / f"mid_axis_sweep_z{z:.2f}.npz"
        try:
            bem_stats = highres_bem_diag(spec_z, system, npz_path, nr=args.nr, nz=args.nz, bem_cfg=bem_cfg)
        except Exception as exc:
            bem_stats = {"error": str(exc)}
        bem_rec = {
            "z": z,
            "metrics": bem_stats,
            "n_images": len(system.elements),
            "type_counts": stage_res.type_counts,
            "reg_l1": args.reg_l1,
            "boundary_weight": args.boundary_weight,
            "system_path": str(sys_dir / "discovered_system.json"),
            "npz_path": str(npz_path),
        }
        bem_metrics.append(bem_rec)
        print(f"[axis_sweep] z={z:.2f} stage_metrics={stage_res.metrics} bem_metrics={bem_stats}")

    args.out_metrics.parent.mkdir(parents=True, exist_ok=True)
    args.out_bem_metrics.parent.mkdir(parents=True, exist_ok=True)
    json.dump(stage_metrics, open(root / args.out_metrics, "w"), indent=2)
    json.dump(bem_metrics, open(root / args.out_bem_metrics, "w"), indent=2)
    print(f"Saved stage metrics to {root / args.out_metrics}")
    print(f"Saved BEM metrics to {root / args.out_bem_metrics}")

    if args.fmm_check:
        ok, stats = try_fmm_matvec(move_charge(spec, 0.7), bem_cfg)
        print(f"[FMM-check] ok={ok} stats={stats}")


if __name__ == "__main__":
    main()

================================================================================
===== END FILE: code\mid_torus_axis_sweep.py =====
================================================================================

================================================================================
===== BEGIN FILE: code\mid_torus_axis_weight_dataset.py =====
================================================================================

"""
Build a dense weight dataset for the fixed mid-torus 2-ring + 4-point geometry.

Reuses the geometry from mid_bem_highres_trial02, solves only for weights for a
list of axis source positions, and saves:
- discovered_system.json per z
- a consolidated JSON with weights, ordering metadata, and Stage-style metrics.
"""
from __future__ import annotations

import argparse
import json
from dataclasses import asdict
from pathlib import Path
from typing import Dict, List

import torch

from electrodrive.images.io import save_image_system
from electrodrive.orchestration.parser import CanonicalSpec
from tools.mid_torus_bem_fmm_refine import (
    RingParams,
    PointParams,
    load_seed_params,
    build_elements,
    belts_inner,
)
from tools.mid_torus_axis_sweep import move_charge, solve_fixed_geometry, _NullLogger
from tools.run_grandchallenge_experiments import evaluate_system


def _default_z_list() -> List[float]:
    return [round(0.40 + 0.05 * i, 2) for i in range(11)]  # 0.40 ... 0.90


def main() -> None:
    parser = argparse.ArgumentParser(description="Dense axis weight dataset for fixed 2-ring + 4-point geometry.")
    parser.add_argument("--z-list", type=str, default=",".join(f"{z:.2f}" for z in _default_z_list()))
    parser.add_argument("--geometry-path", type=Path, default=Path("runs/torus/discovered/mid_bem_highres_trial02/discovered_system.json"))
    parser.add_argument("--out-json", type=Path, default=Path("runs/torus/mid_axis_weights.json"))
    parser.add_argument("--discovered-root", type=Path, default=Path("runs/torus/discovered"))
    parser.add_argument("--n-colloc", type=int, default=4096)
    parser.add_argument("--ratio-boundary", type=float, default=0.8)
    parser.add_argument("--reg-l1", type=float, default=4e-4)
    parser.add_argument("--point-reg-mult", type=float, default=4.0)
    parser.add_argument("--boundary-weight", type=float, default=0.9)
    args = parser.parse_args()

    root = Path(__file__).resolve().parents[1]
    spec = CanonicalSpec.from_json(json.load(open(root / "specs" / "torus_axis_point_mid.json")))
    torus = next(c for c in spec.conductors if c.get("type") in ("torus", "toroid"))
    center = torch.tensor(torus.get("center", [0.0, 0.0, 0.0]), device="cuda" if torch.cuda.is_available() else "cpu", dtype=torch.float32)
    device = center.device
    dtype = torch.float32

    rings_seed, pts_seed = load_seed_params(root / args.geometry_path)
    belts = belts_inner(spec)
    per_type_reg = {"poloidal_ring": args.reg_l1, "point": args.reg_l1 * args.point_reg_mult}

    z_vals = [float(z) for z in args.z_list.split(",") if z.strip()]
    records: List[Dict[str, object]] = []

    for z in z_vals:
        spec_z = move_charge(spec, z)
        elems = build_elements(rings_seed, pts_seed, center=center, device=device, dtype=dtype)
        system = solve_fixed_geometry(
            spec=spec_z,
            elements=elems,
            reg_l1=args.reg_l1,
            per_type_reg=per_type_reg,
            boundary_weight=args.boundary_weight,
            n_points=args.n_colloc,
            ratio_boundary=args.ratio_boundary,
            device=device,
            dtype=dtype,
        )
        stage = evaluate_system(spec_z, system, n_eval=args.n_colloc, ratio_boundary=args.ratio_boundary, belts=belts)
        sys_dir = root / args.discovered_root / f"mid_axis_sweep_z{z:.2f}"
        save_image_system(system, sys_dir / "discovered_system.json", metadata={"z": z, "reg_l1": args.reg_l1, "boundary_weight": args.boundary_weight})
        rec = {
            "z": z,
            "weights": system.weights.detach().cpu().tolist(),
            "metrics": stage.metrics,
            "n_images": len(system.elements),
            "type_counts": stage.type_counts,
            "system_path": str(sys_dir / "discovered_system.json"),
            "reg_l1": args.reg_l1,
            "boundary_weight": args.boundary_weight,
            "n_colloc": args.n_colloc,
            "ratio_boundary": args.ratio_boundary,
        }
        records.append(rec)
        print(f"[dataset] z={z:.2f} weights={rec['weights']}")

    meta = {
        "geometry_path": str(args.geometry_path),
        "rings": [asdict(r) for r in rings_seed],
        "points": [asdict(p) for p in pts_seed],
        "basis_order": ["ring1", "ring2", "pt1", "pt2", "pt3", "pt4"],
        "reg_l1": args.reg_l1,
        "point_reg_mult": args.point_reg_mult,
        "boundary_weight": args.boundary_weight,
        "n_colloc": args.n_colloc,
        "ratio_boundary": args.ratio_boundary,
    }
    out = {"meta": meta, "records": records}
    out_path = root / args.out_json
    out_path.parent.mkdir(parents=True, exist_ok=True)
    json.dump(out, open(out_path, "w"), indent=2)
    print(f"Saved weight dataset to {out_path}")


if __name__ == "__main__":
    main()

================================================================================
===== END FILE: code\mid_torus_axis_weight_dataset.py =====
================================================================================

================================================================================
===== BEGIN FILE: code\mid_torus_axis_weight_svd.py =====
================================================================================

"""
SVD and low-rank diagnostics for the mid-torus axis weight dataset.

Loads runs/torus/mid_axis_weights.json, computes singular values, reconstructs
rank-r weight families, and runs BEM diagnostics for selected z positions.
"""
from __future__ import annotations

import argparse
import json
from pathlib import Path
from typing import Dict, List, Sequence

import numpy as np
import torch

from electrodrive.images.search import ImageSystem
from electrodrive.orchestration.parser import CanonicalSpec
from tools.mid_torus_bem_fmm_refine import (
    load_seed_params,
    build_elements,
    highres_bem_diag,
)
from tools.mid_torus_axis_sweep import move_charge


def reconstruct_weights(U: np.ndarray, S: np.ndarray, VT: np.ndarray, rank: int) -> np.ndarray:
    Ur = U[:, :rank]
    Sr = S[:rank]
    VTr = VT[:rank, :]
    return (Ur * Sr.reshape(1, -1)) @ VTr


def main() -> None:
    parser = argparse.ArgumentParser(description="SVD analysis and BEM truncation diagnostics for axis weights.")
    parser.add_argument("--dataset", type=Path, default=Path("runs/torus/mid_axis_weights.json"))
    parser.add_argument("--svd-out", type=Path, default=Path("runs/torus/mid_axis_weight_svd.json"))
    parser.add_argument("--metrics-out", type=Path, default=Path("runs/torus/stage4_metrics_mid_axis_weight_svd_bem.json"))
    parser.add_argument("--diagnostics-root", type=Path, default=Path("runs/torus/diagnostics"))
    parser.add_argument("--ranks", type=str, default="2,3")
    parser.add_argument("--z-bem", type=str, default="0.40,0.60,0.70,0.90")
    parser.add_argument("--nr", type=int, default=200)
    parser.add_argument("--nz", type=int, default=200)
    args = parser.parse_args()

    root = Path(__file__).resolve().parents[1]
    data = json.load(open(root / args.dataset))
    meta = data["meta"]
    records = data["records"]
    z_vals = [float(rec["z"]) for rec in records]
    W = np.stack([rec["weights"] for rec in records], axis=1)  # shape (6, M)

    U, S, VT = np.linalg.svd(W, full_matrices=False)
    sigma_rel = (S / S[0]).tolist()
    rank_thresh = {}
    for tol in (1e-1, 1e-2, 1e-3):
        rank_thresh[str(tol)] = int(np.sum(S / S[0] > tol))
    svd_info = {
        "singular_values": S.tolist(),
        "singular_values_rel": sigma_rel,
        "rank_thresholds": rank_thresh,
        "z_values": z_vals,
    }
    Path(root / args.svd_out).parent.mkdir(parents=True, exist_ok=True)
    json.dump(svd_info, open(root / args.svd_out, "w"), indent=2)
    print("Singular values (normalized):", sigma_rel)
    print("Rank thresholds:", rank_thresh)

    # Prep geometry
    spec = CanonicalSpec.from_json(json.load(open(root / "specs" / "torus_axis_point_mid.json")))
    rings_seed, pts_seed = load_seed_params(root / meta["geometry_path"])
    torus = next(c for c in spec.conductors if c.get("type") in ("torus", "toroid"))
    center = torch.tensor(torus.get("center", [0.0, 0.0, 0.0]), device="cuda" if torch.cuda.is_available() else "cpu", dtype=torch.float32)
    device = center.device
    dtype = torch.float32

    ranks = [int(r) for r in args.ranks.split(",") if r.strip()]
    z_eval = [float(z) for z in args.z_bem.split(",") if z.strip()]

    metrics: List[Dict[str, object]] = []
    bem_cfg = {
        "use_gpu": True,
        "fp64": True,
        "initial_h": 0.15,
        "max_refine_passes": 4,
        "min_refine_passes": 2,
        "gmres_tol": 1e-8,
        "target_bc_inf_norm": 1e-8,
        "use_near_quadrature": True,
        "use_near_quadrature_matvec": False,
        "tile_mem_divisor": 2.5,
        "target_vram_fraction": 0.9,
    }

    # Map z -> weights (full) for quick lookup
    weights_full: Dict[float, Sequence[float]] = {float(rec["z"]): rec["weights"] for rec in records}
    for z in z_eval:
        spec_z = move_charge(spec, z)
        elems = build_elements(rings_seed, pts_seed, center=center, device=device, dtype=dtype)
        # Full weights
        w_full = torch.tensor(weights_full[z], device=device, dtype=dtype)
        sys_full = ImageSystem(elems, w_full)
        npz_full = root / args.diagnostics_root / f"mid_axis_weight_rankfull_z{z:.2f}.npz"
        stats_full = highres_bem_diag(spec_z, sys_full, npz_full, nr=args.nr, nz=args.nz, bem_cfg=bem_cfg)
        rec_full = {
            "z": z,
            "rank": "full",
            "metrics": stats_full,
            "npz_path": str(npz_full),
        }
        metrics.append(rec_full)
        print(f"[BEM full] z={z:.2f} stats={stats_full}")

        # Low-rank reconstructions
        for r in ranks:
            Wr = reconstruct_weights(U, S, VT, r)
            w_r = torch.tensor(Wr[:, z_vals.index(z)], device=device, dtype=dtype)
            sys_r = ImageSystem(elems, w_r)
            npz_r = root / args.diagnostics_root / f"mid_axis_weight_rank{r}_z{z:.2f}.npz"
            stats_r = highres_bem_diag(spec_z, sys_r, npz_r, nr=args.nr, nz=args.nz, bem_cfg=bem_cfg)
            rec_r = {
                "z": z,
                "rank": r,
                "metrics": stats_r,
                "npz_path": str(npz_r),
            }
            metrics.append(rec_r)
            print(f"[BEM rank {r}] z={z:.2f} stats={stats_r}")

    Path(root / args.metrics_out).parent.mkdir(parents=True, exist_ok=True)
    json.dump(metrics, open(root / args.metrics_out, "w"), indent=2)
    print(f"Saved BEM diagnostics to {root / args.metrics_out}")


if __name__ == "__main__":
    main()

================================================================================
===== END FILE: code\mid_torus_axis_weight_svd.py =====
================================================================================

================================================================================
===== BEGIN FILE: code\mid_torus_bem_fmm_refine.py =====
================================================================================

"""
High-accuracy BEM/FMM refinement for mid-torus 2-ring + 4-point systems.

Runs a small high-res BEM refinement around the current best geometry (trial003),
attempts FMM diagnostics (if available), and logs metrics/diagnostics.
"""
from __future__ import annotations

import json
import math
import random
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Sequence, Tuple, Optional

import numpy as np
import torch

from electrodrive.images.basis import PoloidalRingBasis, PointChargeBasis, ImageBasisElement
from electrodrive.images.io import load_image_system, save_image_system
from electrodrive.images.search import assemble_basis_matrix, solve_l1_ista, ImageSystem
from electrodrive.learn.collocation import get_oracle_solution
from electrodrive.orchestration.parser import CanonicalSpec
from tools.run_grandchallenge_experiments import evaluate_system


class _NullLogger:
    def info(self, *args, **kwargs):
        pass

    def warning(self, *args, **kwargs):
        pass

    def error(self, *args, **kwargs):
        pass


logger = _NullLogger()


@dataclass
class RingParams:
    radius: float
    delta_r: float
    order: int


@dataclass
class PointParams:
    rho: float
    phi: float
    z: float


def load_seed_params(path: Path) -> Tuple[List[RingParams], List[PointParams]]:
    sys = load_image_system(path)
    rings: List[RingParams] = []
    pts: List[PointParams] = []
    for elem in sys.elements:
        if elem.type == "poloidal_ring":
            p = elem.params
            rings.append(
                RingParams(
                    radius=float(p["radius"]),
                    delta_r=float(p.get("delta_r", 0.0)),
                    order=int(p.get("order", 0)),
                )
            )
        elif elem.type == "point":
            pos = torch.as_tensor(elem.params["position"]).view(-1).cpu().numpy()
            rho = float(np.linalg.norm(pos[:2]))
            phi = float(math.atan2(pos[1], pos[0]))
            pts.append(PointParams(rho=rho, phi=phi, z=float(pos[2])))
    rings.sort(key=lambda r: r.order)
    pts.sort(key=lambda p: p.phi)
    return rings, pts


def belts_inner(spec: CanonicalSpec) -> List[Tuple[float, float]]:
    torus = next(c for c in spec.conductors if c.get("type") in ("torus", "toroid"))
    R = float(torus.get("major_radius", torus.get("radius", 1.0)))
    a = float(torus.get("minor_radius", 0.25 * R))
    belts: List[Tuple[float, float]] = []
    for r in (R - a, R - 0.75 * a, R - 0.5 * a, R, R + 0.5 * a):
        for z in (0.0, 0.2 * a, -0.2 * a):
            belts.append((r, z))
    return belts


def clamp(val: float, lo: float, hi: float) -> float:
    return max(lo, min(hi, val))


def perturb(
    rings: Sequence[RingParams],
    pts: Sequence[PointParams],
    R: float,
    a: float,
    jitter_scale: float,
    extra_point_prob: float = 0.1,
) -> Tuple[List[RingParams], List[PointParams]]:
    rho_lo, rho_hi = R - 0.8 * a, R + 0.8 * a
    z_lo, z_hi = -0.4 * a, 0.4 * a
    rng = random.random
    pr: List[RingParams] = []
    for r in rings:
        radius = clamp(r.radius + random.uniform(-jitter_scale, jitter_scale), 0.9 * R, 1.1 * R)
        delta_r = clamp(r.delta_r + random.uniform(-0.5 * jitter_scale, 0.5 * jitter_scale), 0.2 * r.delta_r, 1.5 * r.delta_r)
        order = r.order if rng() > 0.1 else (0 if r.order == 2 else 2)
        pr.append(RingParams(radius=radius, delta_r=delta_r, order=order))
    pp: List[PointParams] = []
    for p in pts:
        rho = clamp(p.rho + random.uniform(-jitter_scale, jitter_scale), rho_lo, rho_hi)
        phi = p.phi + math.radians(random.uniform(-10.0, 10.0))
        z = clamp(p.z + random.uniform(-jitter_scale, jitter_scale), z_lo, z_hi)
        pp.append(PointParams(rho=rho, phi=phi, z=z))
    if rng() < extra_point_prob:
        base = random.choice(pp)
        rho = clamp(base.rho + random.uniform(-2 * jitter_scale, 2 * jitter_scale), rho_lo, rho_hi)
        phi = base.phi + math.radians(random.uniform(-20.0, 20.0))
        z = clamp(base.z + random.uniform(-2 * jitter_scale, 2 * jitter_scale), z_lo, z_hi)
        pp.append(PointParams(rho=rho, phi=phi, z=z))
    return pr, pp


def build_elements(
    rings: Sequence[RingParams],
    pts: Sequence[PointParams],
    center: torch.Tensor,
    device: torch.device,
    dtype: torch.dtype,
) -> List[ImageBasisElement]:
    elems: List[ImageBasisElement] = []
    for r in rings:
        elems.append(
            PoloidalRingBasis(
                {
                    "center": center,
                    "radius": torch.tensor(r.radius, device=device, dtype=dtype),
                    "delta_r": torch.tensor(r.delta_r, device=device, dtype=dtype),
                    "order": torch.tensor(int(r.order), device=device),
                    "n_quad": torch.tensor(128, device=device),
                }
            )
        )
    for p in pts:
        x = p.rho * math.cos(p.phi)
        y = p.rho * math.sin(p.phi)
        pos = torch.tensor([x, y, p.z], device=device, dtype=dtype) + center
        elems.append(PointChargeBasis({"position": pos}))
    return elems


def solve_weights_fixed_geometry(
    spec: CanonicalSpec,
    elements: List[ImageBasisElement],
    reg_l1: float,
    per_type_reg: Dict[str, float],
    boundary_weight: float,
    belts: Optional[List[Tuple[float, float]]],
    device: torch.device,
    dtype: torch.dtype,
) -> ImageSystem:
    # Build collocation via evaluate_system helper (but we need dictionary for ISTA)
    # Reuse collocation from evaluate_system: it already uses make_collocation_batch_for_spec.
    from electrodrive.learn.collocation import make_collocation_batch_for_spec

    batch = make_collocation_batch_for_spec(
        spec=spec,
        n_points=2048,
        ratio_boundary=0.8,
        supervision_mode="auto",
        device=device,
        dtype=dtype,
    )
    X = batch["X"]
    V_gt = batch["V_gt"]
    mask_finite = batch.get("mask_finite")
    if mask_finite is not None and mask_finite.shape == (X.shape[0],):
        mask = mask_finite.to(device=device) & torch.isfinite(V_gt)
    else:
        mask = torch.isfinite(V_gt)
    X = X[mask]
    V_gt = V_gt[mask]
    is_boundary = batch.get("is_boundary", torch.zeros(X.shape[0], device=device, dtype=torch.bool))[mask]

    A = assemble_basis_matrix(elements, X)
    target = V_gt
    if boundary_weight is not None and is_boundary is not None and is_boundary.shape == (X.shape[0],):
        alpha = float(max(0.0, min(1.0, boundary_weight)))
        beta = 1.0 - alpha
        row_weights = torch.where(
            is_boundary.to(device=device),
            torch.full_like(is_boundary, alpha, dtype=dtype),
            torch.full_like(is_boundary, beta, dtype=dtype),
        )
        rw_sqrt = torch.sqrt(row_weights).view(-1, 1)
        A = A * rw_sqrt
        target = target * rw_sqrt.view(-1)

    reg_vec = torch.tensor([float(per_type_reg.get(e.type, reg_l1)) for e in elements], device=device, dtype=dtype)
    weights, _ = solve_l1_ista(A, target, reg_l1=reg_l1, logger=logger, per_elem_reg=reg_vec)
    return ImageSystem(elements, weights)


def highres_bem_diag(
    spec: CanonicalSpec,
    system: ImageSystem,
    out_npz: Path,
    nr: int = 220,
    nz: int = 220,
    bem_cfg: Optional[Dict[str, object]] = None,
) -> Dict[str, float]:
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    dtype = torch.float32
    torus = next(c for c in spec.conductors if c.get("type") in ("torus", "toroid"))
    R = float(torus.get("major_radius", torus.get("radius", 1.0)))
    a = float(torus.get("minor_radius", 0.25 * R))
    r_min, r_max = max(1e-6, R - 1.5 * a), R + 1.5 * a
    z_min, z_max = -1.5 * a, 1.5 * a
    r = np.linspace(r_min, r_max, nr)
    z = np.linspace(z_min, z_max, nz)
    rr, zz = np.meshgrid(r, z, indexing="ij")
    pts_np = np.stack([rr, np.zeros_like(rr), zz], axis=-1).reshape(-1, 3)
    pts = torch.tensor(pts_np, device=device, dtype=dtype)

    with torch.no_grad():
        V_img = system.potential(pts).view(nr, nz).cpu().numpy()
        sol = get_oracle_solution(spec, mode="bem", bem_cfg=bem_cfg or {})
        if sol is None:
            raise RuntimeError("BEM oracle unavailable")
        if hasattr(sol, "eval_V_E_batched"):
            V_bem, _ = sol.eval_V_E_batched(pts)  # type: ignore[attr-defined]
        else:
            V_bem = sol.eval(pts)  # type: ignore[attr-defined]
        V_bem = V_bem.view(nr, nz).cpu().numpy()
    abs_err = np.abs(V_img - V_bem)
    rel_err = abs_err / (np.abs(V_bem) + 1e-12)
    out_npz.parent.mkdir(parents=True, exist_ok=True)
    np.savez_compressed(out_npz, r=r, z=z, V_img=V_img, V_bem=V_bem, abs_err=abs_err, rel_err=rel_err)
    mask_inner = (rr >= R - a) & (rr <= R - 0.4 * a) & (np.abs(zz) <= 0.3 * a)
    stats = {
        "max_rel": float(rel_err.max()),
        "mean_rel": float(rel_err.mean()),
        "inner_mean_abs": float(abs_err[mask_inner].mean()),
        "inner_mean_rel": float(rel_err[mask_inner].mean()),
    }
    return stats


def attempt_fmm_diag(spec: CanonicalSpec, system: ImageSystem, out_npz: Path, nr: int = 220, nz: int = 220) -> Tuple[bool, Dict[str, float]]:
    """Attempt FMM oracle; return (ok, stats)."""
    try:
        sol = get_oracle_solution(spec, mode="fmm", bem_cfg={})  # type: ignore[arg-type]
    except Exception as exc:
        return False, {"error": str(exc)}
    if sol is None:
        return False, {"error": "FMM oracle unavailable"}
    # Reuse BEM grid eval
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    dtype = torch.float32
    torus = next(c for c in spec.conductors if c.get("type") in ("torus", "toroid"))
    R = float(torus.get("major_radius", torus.get("radius", 1.0)))
    a = float(torus.get("minor_radius", 0.25 * R))
    r_min, r_max = max(1e-6, R - 1.5 * a), R + 1.5 * a
    z_min, z_max = -1.5 * a, 1.5 * a
    r = np.linspace(r_min, r_max, nr)
    z = np.linspace(z_min, z_max, nz)
    rr, zz = np.meshgrid(r, z, indexing="ij")
    pts_np = np.stack([rr, np.zeros_like(rr), zz], axis=-1).reshape(-1, 3)
    pts = torch.tensor(pts_np, device=device, dtype=dtype)
    with torch.no_grad():
        V_img = system.potential(pts).view(nr, nz).cpu().numpy()
        if hasattr(sol, "eval_V_E_batched"):
            V_ref, _ = sol.eval_V_E_batched(pts)  # type: ignore[attr-defined]
        else:
            V_ref = sol.eval(pts)  # type: ignore[attr-defined]
        V_ref = V_ref.view(nr, nz).cpu().numpy()
    abs_err = np.abs(V_img - V_ref)
    rel_err = abs_err / (np.abs(V_ref) + 1e-12)
    out_npz.parent.mkdir(parents=True, exist_ok=True)
    np.savez_compressed(out_npz, r=r, z=z, V_img=V_img, V_ref=V_ref, abs_err=abs_err, rel_err=rel_err)
    mask_inner = (rr >= R - a) & (rr <= R - 0.4 * a) & (np.abs(zz) <= 0.3 * a)
    stats = {
        "max_rel": float(rel_err.max()),
        "mean_rel": float(rel_err.mean()),
        "inner_mean_abs": float(abs_err[mask_inner].mean()),
        "inner_mean_rel": float(rel_err[mask_inner].mean()),
    }
    return True, stats


def main() -> None:
    root = Path(__file__).resolve().parents[1]
    spec = CanonicalSpec.from_json(json.load(open(root / "specs" / "torus_axis_point_mid.json")))
    torus = next(c for c in spec.conductors if c.get("type") in ("torus", "toroid"))
    R = float(torus.get("major_radius", torus.get("radius", 1.0)))
    a = float(torus.get("minor_radius", 0.25 * R))
    center = torch.tensor(torus.get("center", [0.0, 0.0, 0.0]), device="cuda" if torch.cuda.is_available() else "cpu", dtype=torch.float32)
    device = center.device
    dtype = center.dtype

    seed_path = root / "runs/torus/discovered/mid_local_seed5500358_trial003/discovered_system.json"
    rings_seed, pts_seed = load_seed_params(seed_path)
    belts = belts_inner(spec)

    # High-res BEM config
    bem_cfg = {
        "use_gpu": True,
        "fp64": True,
        "initial_h": 0.15,
        "max_refine_passes": 5,
        "min_refine_passes": 2,
        "gmres_tol": 1e-8,
        "target_bc_inf_norm": 1e-8,
        "use_near_quadrature": True,
        "use_near_quadrature_matvec": False,
        "tile_mem_divisor": 2.5,
        "target_vram_fraction": 0.9,
    }

    trials = []
    n_trials = 12
    jitter = 0.02
    for i in range(n_trials):
        random.seed(10_000 + i)
        pr, pp = perturb(rings_seed, pts_seed, R=R, a=a, jitter_scale=jitter, extra_point_prob=0.05)
        elems = build_elements(pr, pp, center=center, device=device, dtype=dtype)
        reg_l1 = random.choice([2e-4, 3e-4, 4e-4, 6e-4])
        bw = random.choice([0.9, 0.95])
        per_type_reg = {"poloidal_ring": reg_l1 * 1.0, "point": reg_l1 * 4.0}
        system = solve_weights_fixed_geometry(spec, elems, reg_l1=reg_l1, per_type_reg=per_type_reg, boundary_weight=bw, belts=belts, device=device, dtype=dtype)
        tag = f"mid_bem_highres_trial{i:02d}"
        npz_path = root / "runs/torus/diagnostics" / f"{tag}.npz"
        try:
            stats = highres_bem_diag(spec, system, npz_path, bem_cfg=bem_cfg)
        except Exception as exc:  # fallback to standard BEM if highres fails
            stats = {"error": str(exc)}
        type_counts: Dict[str, int] = {}
        for e in system.elements:
            type_counts[e.type] = type_counts.get(e.type, 0) + 1
        rec = {
            "run": tag,
            "rings": [r.__dict__ for r in pr],
            "points": [p.__dict__ for p in pp],
            "reg_l1": reg_l1,
            "boundary_weight": bw,
            "metrics": stats,
            "n_images": len(system.elements),
            "type_counts": type_counts,
        }
        trials.append(rec)
        # Persist discovered system
        save_image_system(system, root / f"runs/torus/discovered/{tag}/discovered_system.json", metadata={"reg_l1": reg_l1, "boundary_weight": bw})
        print(f"[BEM trial {i}] stats {stats}")

    out_metrics = root / "runs/torus/stage4_metrics_mid_bem_highres_local.json"
    json.dump(trials, out_metrics.open("w"), indent=2)
    print(f"Saved {len(trials)} highres BEM trials to {out_metrics}")

    # Attempt FMM diag on baseline/seed/trial003 and best BEM trial
    baseline = load_image_system(root / "runs/torus/discovered/mid_baseline_eigen/discovered_system.json", device=device, dtype=dtype)
    seed_sys = load_image_system(root / "runs/torus/discovered/mid_random_seed5500358/discovered_system.json", device=device, dtype=dtype)
    trial003 = load_image_system(root / "runs/torus/discovered/mid_local_seed5500358_trial003/discovered_system.json", device=device, dtype=dtype)

    candidates_fmm = {
        "baseline": baseline,
        "seed": seed_sys,
        "trial003": trial003,
    }
    # pick best BEM trial by mean_rel if available
    best_bem = None
    best_val = math.inf
    for rec in trials:
        m = rec["metrics"]
        if "mean_rel" in m and m["mean_rel"] < best_val:
            best_val = m["mean_rel"]
            best_bem = rec["run"]
    if best_bem:
        best_sys = load_image_system(root / f"runs/torus/discovered/{best_bem}/discovered_system.json", device=device, dtype=dtype)
        candidates_fmm["best_bem"] = best_sys

    fmm_stats: Dict[str, Dict[str, float]] = {}
    for name, sys in candidates_fmm.items():
        ok, stats = attempt_fmm_diag(spec, sys, root / f"runs/torus/diagnostics/mid_{name}_fmm.npz")
        stats["ok"] = ok
        fmm_stats[name] = stats
        print(f"[FMM] {name} stats {stats}")

    json.dump(fmm_stats, open(root / "runs/torus/diagnostics/mid_fmm_stats.json", "w"), indent=2)


if __name__ == "__main__":
    main()

================================================================================
===== END FILE: code\mid_torus_bem_fmm_refine.py =====
================================================================================

================================================================================
===== BEGIN FILE: code\mid_torus_local_geometry_explorer.py =====
================================================================================

"""
Mid-torus local geometry explorer around the 2-ring + 4-point seed.

Workflow:
- Load the mid-torus spec and the seed discovered system (2 poloidal rings + 4 points).
- Randomly perturb ring radii/delta_r/orders and point cylindrical coords (rho, phi, z),
  optionally adding 1–2 extra points near the torus surface.
- For each perturbed geometry, solve for weights with fixed geometry using the ISTA
  solver from electrodrive.images.search, then evaluate Stage4-style metrics.
- Rank interesting trials; optionally run BEM diagnostics for the top few.
Results are written to runs/torus/stage4_metrics_mid_local_geometry.json and diagnostics
under runs/torus/diagnostics/.
"""
from __future__ import annotations

import argparse
import json
import math
import random
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Sequence, Tuple

import numpy as np
import torch

from electrodrive.images.basis import PoloidalRingBasis, PointChargeBasis, ImageBasisElement
from electrodrive.images.io import load_image_system, save_image_system
from electrodrive.images.search import (
    assemble_basis_matrix,
    solve_l1_ista,
    get_collocation_data,
    ImageSystem,
)
from electrodrive.learn.collocation import get_oracle_solution
from electrodrive.orchestration.parser import CanonicalSpec
from tools.run_grandchallenge_experiments import evaluate_system


class _NullLogger:
    def info(self, *args, **kwargs):
        pass

    def warning(self, *args, **kwargs):
        pass

    def error(self, *args, **kwargs):
        pass


logger = _NullLogger()


@dataclass
class RingParams:
    radius: float
    delta_r: float
    order: int


@dataclass
class PointParams:
    rho: float
    phi: float
    z: float


@dataclass
class TrialRecord:
    run: str
    params: Dict[str, object]
    basis_types: List[str]
    n_images: int
    metrics: Dict[str, float]
    type_counts: Dict[str, int]
    reg_l1: float
    boundary_weight: float
    per_type_reg: Dict[str, float]


def load_seed_params(seed_path: Path) -> Tuple[List[RingParams], List[PointParams]]:
    system = load_image_system(seed_path)
    rings: List[RingParams] = []
    points: List[PointParams] = []
    for elem, w in zip(system.elements, system.weights.tolist()):
        if elem.type == "poloidal_ring":
            p = elem.params
            radius = float(p["radius"])
            delta_r = float(p.get("delta_r", 0.1))
            order = int(p.get("order", 0))
            rings.append(RingParams(radius, delta_r, order))
        elif elem.type == "point":
            pos = torch.as_tensor(elem.params["position"]).view(-1).cpu().numpy()
            rho = float(np.linalg.norm(pos[:2]))
            phi = float(math.atan2(pos[1], pos[0]))
            points.append(PointParams(rho, phi, float(pos[2])))
    # Keep deterministic ordering: sort rings by order, points by phi.
    rings.sort(key=lambda r: r.order)
    points.sort(key=lambda p: p.phi)
    return rings, points


def belts_inner(spec: CanonicalSpec) -> List[Tuple[float, float]]:
    torus = next(c for c in spec.conductors if c.get("type") in ("torus", "toroid"))
    R = float(torus.get("major_radius", torus.get("radius", 1.0)))
    a = float(torus.get("minor_radius", 0.25 * R))
    belts: List[Tuple[float, float]] = []
    for r in (R - a, R - 0.75 * a, R - 0.5 * a, R, R + 0.5 * a):
        for z in (0.0, 0.2 * a, -0.2 * a):
            belts.append((r, z))
    return belts


def clamp(val: float, lo: float, hi: float) -> float:
    return max(lo, min(hi, val))


def perturb_seed(
    rings: Sequence[RingParams],
    points: Sequence[PointParams],
    R: float,
    a: float,
    jitter_scale: float = 0.05,
    allow_extra_points: bool = True,
) -> Tuple[List[RingParams], List[PointParams]]:
    rng = random.random

    def jitter(val: float, width: float) -> float:
        return val + (random.uniform(-1.0, 1.0) * width)

    pert_rings: List[RingParams] = []
    for rp in rings:
        radius = clamp(jitter(rp.radius, 0.07), 0.9 * R, 1.1 * R)
        delta_r = clamp(jitter(rp.delta_r, 0.5 * rp.delta_r), 0.2 * rp.delta_r, 1.5 * rp.delta_r)
        order = rp.order
        if rng() < 0.15:
            order = 0 if order == 2 else 2
        pert_rings.append(RingParams(radius=radius, delta_r=delta_r, order=order))

    rho_lo, rho_hi = R - 0.8 * a, R + 0.8 * a
    z_lo, z_hi = -0.4 * a, 0.4 * a
    pert_points: List[PointParams] = []
    for pp in points:
        rho = clamp(pp.rho + random.uniform(-jitter_scale, jitter_scale), rho_lo, rho_hi)
        phi = pp.phi + math.radians(random.uniform(-15.0, 15.0))
        z = clamp(pp.z + random.uniform(-jitter_scale, jitter_scale), z_lo, z_hi)
        pert_points.append(PointParams(rho=rho, phi=phi, z=z))

    if allow_extra_points and rng() < 0.25:
        base = random.choice(pert_points)
        rho = clamp(base.rho + random.uniform(-2 * jitter_scale, 2 * jitter_scale), rho_lo, rho_hi)
        phi = base.phi + math.radians(random.uniform(-20.0, 20.0))
        z = clamp(base.z + random.uniform(-2 * jitter_scale, 2 * jitter_scale), z_lo, z_hi)
        pert_points.append(PointParams(rho=rho, phi=phi, z=z))

    return pert_rings, pert_points


def build_basis_from_params(
    rings: Sequence[RingParams],
    points: Sequence[PointParams],
    center: torch.Tensor,
    device: torch.device,
    dtype: torch.dtype,
) -> List[ImageBasisElement]:
    elems: List[ImageBasisElement] = []
    for rp in rings:
        elems.append(
            PoloidalRingBasis(
                {
                    "center": center,
                    "radius": torch.tensor(rp.radius, device=device, dtype=dtype),
                    "delta_r": torch.tensor(rp.delta_r, device=device, dtype=dtype),
                    "order": torch.tensor(int(rp.order), device=device),
                    "n_quad": torch.tensor(128, device=device),
                }
            )
        )
    for pp in points:
        x = pp.rho * math.cos(pp.phi)
        y = pp.rho * math.sin(pp.phi)
        pos = torch.tensor([x, y, pp.z], device=device, dtype=dtype) + center
        elems.append(PointChargeBasis({"position": pos}))
    return elems


def solve_fixed_geometry(
    spec: CanonicalSpec,
    elements: List[ImageBasisElement],
    reg_l1: float,
    per_type_reg: Dict[str, float],
    boundary_weight: float,
    device: torch.device,
    dtype: torch.dtype,
) -> ImageSystem:
    colloc = get_collocation_data(spec, logger=type("L", (), {"info": lambda *a, **k: None, "warning": lambda *a, **k: None, "error": lambda *a, **k: None})(), device=device, dtype=dtype, return_is_boundary=True)
    if len(colloc) == 3:
        X, V, is_boundary = colloc  # type: ignore[misc]
    else:
        X, V = colloc  # type: ignore[misc]
        is_boundary = None
    if X.shape[0] == 0:
        return ImageSystem([], torch.zeros(0, device=device, dtype=dtype))

    A = assemble_basis_matrix(elements, X)
    target = V

    if boundary_weight is not None and is_boundary is not None and is_boundary.shape == (X.shape[0],):
        alpha = float(max(0.0, min(1.0, boundary_weight)))
        beta = 1.0 - alpha
        is_boundary = is_boundary.to(device=device)
        row_weights = torch.where(
            is_boundary,
            torch.full_like(is_boundary, alpha, dtype=dtype),
            torch.full_like(is_boundary, beta, dtype=dtype),
        )
        rw_sqrt = torch.sqrt(row_weights).view(-1, 1)
        A = A * rw_sqrt
        target = target * rw_sqrt.view(-1)

    reg_vec = torch.tensor([float(per_type_reg.get(e.type, reg_l1)) for e in elements], device=device, dtype=dtype)
    weights, _ = solve_l1_ista(A, target, reg_l1=reg_l1, logger=logger, per_elem_reg=reg_vec)
    return ImageSystem(elements, weights)


def diag_stats(path: Path, R: float, a: float) -> Dict[str, float]:
    data = np.load(path)
    r = data["r"]
    z = data["z"]
    rr, zz = np.meshgrid(r, z, indexing="ij")
    abs_err = data["abs_err"]
    rel_err = data["rel_err"]
    mask_inner = (rr >= R - a) & (rr <= R - 0.4 * a) & (np.abs(zz) <= 0.3 * a)
    out: Dict[str, float] = {
        "max_rel": float(rel_err.max()),
        "mean_rel": float(rel_err.mean()),
    }
    if mask_inner.any():
        out["inner_mean_abs"] = float(abs_err[mask_inner].mean())
        out["inner_mean_rel"] = float(rel_err[mask_inner].mean())
    return out


def run_bem_diag(
    spec: CanonicalSpec,
    system: ImageSystem,
    out_npz: Path,
    nr: int = 200,
    nz: int = 200,
) -> Dict[str, float]:
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    dtype = torch.float32
    torus = next(c for c in spec.conductors if c.get("type") in ("torus", "toroid"))
    R = float(torus.get("major_radius", torus.get("radius", 1.0)))
    a = float(torus.get("minor_radius", 0.25 * R))
    r_min, r_max = max(1e-6, R - 1.5 * a), R + 1.5 * a
    z_min, z_max = -1.5 * a, 1.5 * a
    r_arr = np.linspace(r_min, r_max, nr)
    z_arr = np.linspace(z_min, z_max, nz)
    rr, zz = np.meshgrid(r_arr, z_arr, indexing="ij")
    xx = rr
    yy = np.zeros_like(rr)
    pts_np = np.stack([xx, yy, zz], axis=-1).reshape(-1, 3)
    pts = torch.tensor(pts_np, device=device, dtype=dtype)

    with torch.no_grad():
        V_img = system.potential(pts).view(nr, nz).cpu().numpy()
        sol = get_oracle_solution(spec, mode="bem", bem_cfg={})  # type: ignore[arg-type]
        if sol is None:
            raise RuntimeError("BEM oracle unavailable")
        if hasattr(sol, "eval_V_E_batched"):
            V_bem, _ = sol.eval_V_E_batched(pts)  # type: ignore[attr-defined]
        else:
            V_bem = sol.eval(pts)  # type: ignore[attr-defined]
        V_bem = V_bem.view(nr, nz).cpu().numpy()
    abs_err = np.abs(V_img - V_bem)
    rel_err = abs_err / (np.abs(V_bem) + 1e-12)

    out_npz.parent.mkdir(parents=True, exist_ok=True)
    np.savez_compressed(out_npz, r=r_arr, z=z_arr, V_img=V_img, V_bem=V_bem, abs_err=abs_err, rel_err=rel_err)
    return diag_stats(out_npz, R=R, a=a)


def main() -> None:
    ap = argparse.ArgumentParser(description="Local geometry explorer around mid 2-ring+4-point seed.")
    ap.add_argument("--trials", type=int, default=24, help="Number of perturbation trials.")
    ap.add_argument("--bem-top", type=int, default=3, help="Max candidates to BEM-check.")
    args = ap.parse_args()

    root = Path(__file__).resolve().parents[1]
    spec = CanonicalSpec.from_json(json.load(open(root / "specs" / "torus_axis_point_mid.json")))
    seed_path = root / "runs/torus/discovered/mid_random_seed5500358/discovered_system.json"
    baseline_path = root / "runs/torus/discovered/mid_baseline_eigen/discovered_system.json"
    rings_seed, points_seed = load_seed_params(seed_path)
    torus = next(c for c in spec.conductors if c.get("type") in ("torus", "toroid"))
    R = float(torus.get("major_radius", torus.get("radius", 1.0)))
    a = float(torus.get("minor_radius", 0.25 * R))

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    dtype = torch.float32
    center = torch.tensor(torus.get("center", [0.0, 0.0, 0.0]), device=device, dtype=dtype)
    belts = belts_inner(spec)

    records: List[TrialRecord] = []
    for idx in range(args.trials):
        rng_seed = random.randint(0, 10_000_000)
        random.seed(rng_seed)
        pr_rings, pr_points = perturb_seed(rings_seed, points_seed, R=R, a=a, allow_extra_points=True)
        elems = build_basis_from_params(pr_rings, pr_points, center=center, device=device, dtype=dtype)
        reg_l1 = random.choice([2e-4, 3e-4, 4e-4, 6e-4, 8e-4])
        bw = random.choice([0.85, 0.9, 0.95])
        per_type_reg = {
            "poloidal_ring": reg_l1 * random.uniform(0.8, 1.2),
            "point": reg_l1 * random.uniform(3.0, 5.0),
        }
        system = solve_fixed_geometry(spec, elems, reg_l1=reg_l1, per_type_reg=per_type_reg, boundary_weight=bw, device=device, dtype=dtype)
        eval_res = evaluate_system(spec, system, belts=belts)
        tag = f"mid_local_seed5500358_trial{idx:03d}"
        rec = TrialRecord(
            run=tag,
            params={
                "rings": [r.__dict__ for r in pr_rings],
                "points": [p.__dict__ for p in pr_points],
                "seed": rng_seed,
            },
            basis_types=["poloidal_ring", "point"],
            n_images=len(system.elements),
            metrics=eval_res.metrics,
            type_counts=eval_res.type_counts,
            reg_l1=reg_l1,
            boundary_weight=bw,
            per_type_reg=per_type_reg,
        )
        records.append(rec)
        print(f"[trial {idx:03d}] b_mae={eval_res.metrics.get('boundary_mae')} off_rel={eval_res.metrics.get('offaxis_rel')} n={len(system.elements)}")

    out_path = root / "runs/torus/stage4_metrics_mid_local_geometry.json"
    out_path.parent.mkdir(parents=True, exist_ok=True)
    json.dump([r.__dict__ for r in records], out_path.open("w"), indent=2)
    print(f"Saved {len(records)} trials to {out_path}")

    # Rank promising by boundary_mae then offaxis_rel
    records_sorted = sorted(records, key=lambda r: (r.metrics.get("boundary_mae", math.inf), r.metrics.get("offaxis_rel", math.inf)))
    top = records_sorted[: args.bem_top]
    print("[top for BEM]")
    for r in top:
        print(r.run, r.metrics)

    # BEM diagnostics on top candidates
    diag_out: Dict[str, Dict[str, float]] = {}
    for r in top:
        elems = build_basis_from_params(
            [RingParams(**rp) for rp in r.params["rings"]],  # type: ignore[arg-type]
            [PointParams(**pp) for pp in r.params["points"]],  # type: ignore[arg-type]
            center=center,
            device=device,
            dtype=dtype,
        )
        system = solve_fixed_geometry(spec, elems, reg_l1=r.reg_l1, per_type_reg=r.per_type_reg, boundary_weight=r.boundary_weight, device=device, dtype=dtype)
        diag_path = root / f"runs/torus/diagnostics/{r.run}.npz"
        stats = run_bem_diag(spec, system, diag_path)
        diag_out[r.run] = stats
        # Persist discovered system
        disc_path = root / f"runs/torus/discovered/{r.run}/discovered_system.json"
        save_image_system(system, disc_path, metadata={"run": r.run, "reg_l1": r.reg_l1, "boundary_weight": r.boundary_weight, "per_type_reg": r.per_type_reg})
        print(f"[BEM] {r.run} stats {stats} saved {diag_path}")

    # Save combined diag stats
    json.dump(diag_out, open(root / "runs/torus/diagnostics/mid_local_geometry_diag_stats.json", "w"), indent=2)


if __name__ == "__main__":
    main()

================================================================================
===== END FILE: code\mid_torus_local_geometry_explorer.py =====
================================================================================

================================================================================
===== BEGIN FILE: code\plot_mid_axis_rank_truncation_errors.py =====
================================================================================

"""
Plot mean_rel and inner_mean_rel for full vs rank-2/3 truncated weights across selected z.
"""
from __future__ import annotations

import json
from pathlib import Path

import matplotlib.pyplot as plt


def main() -> None:
    metrics_path = Path("runs/torus/stage4_metrics_mid_axis_weight_svd_bem.json")
    data = json.load(open(metrics_path))
    z_vals = sorted({float(rec["z"]) for rec in data})
    ranks = ["full", 2, 3]

    def collect(metric_name: str):
        res = {r: [] for r in ranks}
        for z in z_vals:
            recs = [r for r in data if float(r["z"]) == z]
            for r in ranks:
                key = "full" if r == "full" else r
                rec = next((x for x in recs if x["rank"] == key), None)
                res[r].append(rec["metrics"].get(metric_name, float("nan")) if rec else float("nan"))
        return res

    mean_rel = collect("mean_rel")
    inner_rel = collect("inner_mean_rel")

    outdir = Path("staging/figures/paper")
    outdir.mkdir(parents=True, exist_ok=True)

    def plot_metric(vals: dict, title: str, fname: str):
        fig, ax = plt.subplots(figsize=(6, 4))
        for r in ranks:
            ax.plot(z_vals, vals[r], "-o", label=f"rank {r}")
        ax.set_xlabel("z (axis)")
        ax.set_ylabel(title)
        ax.set_title(title)
        ax.grid(True, alpha=0.3)
        ax.legend()
        fig.tight_layout()
        fig.savefig(outdir / fname, dpi=200)
        plt.close(fig)

    plot_metric(mean_rel, "mean_rel", "fig5_rank_truncation_mean_rel.png")
    plot_metric(inner_rel, "inner_mean_rel", "fig5_rank_truncation_inner_mean_rel.png")


if __name__ == "__main__":
    main()

================================================================================
===== END FILE: code\plot_mid_axis_rank_truncation_errors.py =====
================================================================================

================================================================================
===== BEGIN FILE: code\plot_mid_axis_svd_singulars.py =====
================================================================================

"""
Plot singular values (relative) of the axis weight matrix.
"""
from __future__ import annotations

import json
from pathlib import Path

import matplotlib.pyplot as plt


def main() -> None:
    data = json.load(open("runs/torus/mid_axis_weight_svd.json"))
    sigma_rel = data["singular_values_rel"]
    out_path = Path("staging/figures/paper/fig4_singular_values.png")

    fig, ax = plt.subplots(figsize=(5, 4))
    ax.semilogy(range(1, len(sigma_rel) + 1), sigma_rel, "-o")
    ax.axhline(0.1, color="gray", linestyle="--", linewidth=1)
    ax.axhline(0.01, color="gray", linestyle=":", linewidth=1)
    ax.set_xlabel("mode index")
    ax.set_ylabel("sigma_i / sigma_1")
    ax.set_title("Axis weight singular values")
    ax.grid(True, which="both", alpha=0.3)
    out_path.parent.mkdir(parents=True, exist_ok=True)
    fig.tight_layout()
    fig.savefig(out_path, dpi=200)
    plt.close(fig)


if __name__ == "__main__":
    main()

================================================================================
===== END FILE: code\plot_mid_axis_svd_singulars.py =====
================================================================================

================================================================================
===== BEGIN FILE: code\plot_mid_axis_sweep_metrics.py =====
================================================================================

"""
Plot axis sweep BEM metrics vs z for mid-torus fixed-geometry runs.
"""
from __future__ import annotations

import json
from pathlib import Path

import matplotlib.pyplot as plt


def main() -> None:
    metrics_path = Path("runs/torus/stage4_metrics_mid_axis_sweep_bem.json")
    out_path = Path("staging/figures/paper/fig3_axis_sweep_errors_vs_z.png")
    data = json.load(open(metrics_path))
    z = [float(rec["z"]) for rec in data]
    mean_rel = [rec["metrics"].get("mean_rel", float("nan")) for rec in data]
    inner_rel = [rec["metrics"].get("inner_mean_rel", float("nan")) for rec in data]
    max_rel = [rec["metrics"].get("max_rel", float("nan")) for rec in data]

    fig, ax = plt.subplots(1, 1, figsize=(6, 4))
    ax.plot(z, mean_rel, "-o", label="mean_rel")
    ax.plot(z, inner_rel, "-s", label="inner_mean_rel")
    ax.set_xlabel("z (axis)")
    ax.set_ylabel("relative error")
    ax.grid(True, alpha=0.3)
    ax.legend()

    ax2 = ax.twinx()
    ax2.plot(z, max_rel, "--", color="gray", alpha=0.5, label="max_rel")
    ax2.set_ylabel("max_rel")
    fig.legend(loc="upper center", bbox_to_anchor=(0.5, -0.1), ncol=3)

    out_path.parent.mkdir(parents=True, exist_ok=True)
    fig.tight_layout()
    fig.savefig(out_path, dpi=200, bbox_inches="tight")
    plt.close(fig)


if __name__ == "__main__":
    main()

================================================================================
===== END FILE: code\plot_mid_axis_sweep_metrics.py =====
================================================================================

================================================================================
===== BEGIN FILE: code\plot_mid_axis_weights_vs_z.py =====
================================================================================

"""
Plot weights vs z (rings and points) and optional mode coefficients from SVD.
"""
from __future__ import annotations

import argparse
import json
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np


def plot_weights(z, W, basis_order, out_path: Path):
    z = np.array(z)
    fig, axes = plt.subplots(2, 1, figsize=(7, 6), sharex=True)
    # Rings (assumed first two entries)
    axes[0].plot(z, W[0], "-o", label=basis_order[0])
    axes[0].plot(z, W[1], "-o", label=basis_order[1])
    axes[0].set_ylabel("weight")
    axes[0].set_title("Ring weights vs z")
    axes[0].grid(True, alpha=0.3)
    axes[0].legend()
    # Points
    for i in range(2, W.shape[0]):
        axes[1].plot(z, W[i], "-o", label=basis_order[i])
    axes[1].set_xlabel("z (axis)")
    axes[1].set_ylabel("weight")
    axes[1].set_title("Point weights vs z")
    axes[1].grid(True, alpha=0.3)
    axes[1].legend()
    fig.tight_layout()
    out_path.parent.mkdir(parents=True, exist_ok=True)
    fig.savefig(out_path, dpi=200)
    plt.close(fig)


def plot_mode_coeffs(z, U, S, Vt, r_max: int, out_path: Path):
    z = np.array(z)
    coeffs = np.diag(S) @ Vt  # shape (6, M)
    fig, ax = plt.subplots(figsize=(7, 4))
    for i in range(min(r_max, coeffs.shape[0])):
        ax.plot(z, coeffs[i], "-o", label=f"mode {i+1}")
    ax.set_xlabel("z (axis)")
    ax.set_ylabel("mode coefficient")
    ax.set_title("Axis weight mode coefficients vs z")
    ax.grid(True, alpha=0.3)
    ax.legend()
    fig.tight_layout()
    out_path.parent.mkdir(parents=True, exist_ok=True)
    fig.savefig(out_path, dpi=200)
    plt.close(fig)


def main() -> None:
    ap = argparse.ArgumentParser(description="Plot axis weight behavior vs z.")
    ap.add_argument("--weights-json", type=Path, default=Path("runs/torus/mid_axis_weights.json"))
    ap.add_argument("--svd-json", type=Path, default=Path("runs/torus/mid_axis_weight_svd.json"))
    ap.add_argument("--outdir", type=Path, default=Path("staging/figures/paper"))
    args = ap.parse_args()

    data = json.load(open(args.weights_json))
    basis_order = data["meta"]["basis_order"]
    z_vals = [float(rec["z"]) for rec in data["records"]]
    W = np.stack([rec["weights"] for rec in data["records"]], axis=1)  # (6, M)

    plot_weights(z_vals, W, basis_order, args.outdir / "fig9_weights_vs_z.png")

    try:
        svd = json.load(open(args.svd_json))
        U = np.array(svd["U"]) if "U" in svd else None
    except Exception:
        U = None
    if U is None:
        # reconstruct from numpy SVD for mode coefficients
        U, S, Vt = np.linalg.svd(W, full_matrices=False)
    else:
        S = np.array(svd["singular_values"])
        Vt = np.array(svd["VT"])
    plot_mode_coeffs(z_vals, U, S, Vt, r_max=3, out_path=args.outdir / "fig9b_mode_coeffs_vs_z.png")


if __name__ == "__main__":
    main()

================================================================================
===== END FILE: code\plot_mid_axis_weights_vs_z.py =====
================================================================================

================================================================================
===== BEGIN FILE: code\plot_mid_candidate_metric_summary.py =====
================================================================================

"""
Plot and export summary metrics for baseline→seed→trial003→trial02.
"""
from __future__ import annotations

import json
from pathlib import Path

import matplotlib.pyplot as plt
import pandas as pd


def main() -> None:
    data = json.load(open("runs/torus/mid_candidate_metrics_combined.json"))
    order = ["baseline", "seed", "trial003", "bem_highres_trial02"]
    labels = ["baseline", "seed (2R+4P)", "trial003", "trial02 (hi-res)"]

    rows = []
    for key, label in zip(order, labels):
        m = data[key]
        rows.append(
            {
                "name": label,
                "n_images": {"baseline": 12, "seed": 6, "trial003": 6, "bem_highres_trial02": 6}[key],
                "mean_rel": m["mean_rel"],
                "inner_mean_rel": m["inner_mean_rel"],
                "max_rel": m["max_rel"],
            }
        )
    df = pd.DataFrame(rows)

    out_csv = Path("staging/tables/mid_candidate_metrics_summary.csv")
    out_csv.parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(out_csv, index=False)

    # Plot mean_rel and inner_mean_rel bars
    fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=False)
    axes[0].bar(df["name"], df["mean_rel"], color="steelblue")
    axes[0].set_title("mean_rel")
    axes[0].set_ylabel("relative error")
    axes[0].tick_params(axis="x", rotation=20)

    axes[1].bar(df["name"], df["inner_mean_rel"], color="darkorange")
    axes[1].set_title("inner_mean_rel")
    axes[1].tick_params(axis="x", rotation=20)

    fig.suptitle("Mid-torus candidate metrics (BEM)", fontsize=12)
    fig.tight_layout()
    out_fig = Path("staging/figures/paper/fig10_candidate_metrics_summary.png")
    out_fig.parent.mkdir(parents=True, exist_ok=True)
    fig.savefig(out_fig, dpi=200)
    plt.close(fig)


if __name__ == "__main__":
    main()

================================================================================
===== END FILE: code\plot_mid_candidate_metric_summary.py =====
================================================================================

================================================================================
===== BEGIN FILE: code\plot_mid_torus_error_histogram.py =====
================================================================================

"""
Histogram of relative error for the best system (mid_bem_highres_trial02).
"""
from __future__ import annotations

import argparse
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np


def main() -> None:
    parser = argparse.ArgumentParser()
    parser.add_argument("--npz", type=Path, default=Path("runs/torus/diagnostics/mid_bem_highres_trial02.npz"))
    parser.add_argument("--out", type=Path, default=Path("staging/figures/paper/fig8_error_histogram_z0.70.png"))
    args = parser.parse_args()

    data = np.load(args.npz)
    rel = data["rel_err"].ravel()
    rel = rel[np.isfinite(rel)]

    fig, ax = plt.subplots(figsize=(6, 4))
    ax.hist(rel, bins=100, log=True, color="steelblue", alpha=0.8)
    ax.set_xlabel("relative error")
    ax.set_ylabel("count (log)")
    ax.set_title("Error distribution (best system z≈0.70)")
    fig.tight_layout()
    args.out.parent.mkdir(parents=True, exist_ok=True)
    fig.savefig(args.out, dpi=200)
    plt.close(fig)


if __name__ == "__main__":
    main()

================================================================================
===== END FILE: code\plot_mid_torus_error_histogram.py =====
================================================================================

================================================================================
===== BEGIN FILE: code\plot_mid_torus_error_maps.py =====
================================================================================

"""
Plot r–z error fields from NPZ diagnostics for mid-torus experiments with consistent styling.

Generates:
- Baseline vs best (abs/rel) maps with shared limits and torus overlay.
- Full vs rank-2 comparison at selected z (0.60 and 0.90) with shared limits and overlay.
"""
from __future__ import annotations

import argparse
import json
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np

from electrodrive.orchestration.parser import CanonicalSpec


def _load_npz(path: Path):
    data = np.load(path)
    return data["r"], data["z"], data.get("abs_err"), data.get("rel_err")


def _torus_outline(spec: CanonicalSpec):
    torus = next(c for c in spec.conductors if c.get("type") in ("torus", "toroid"))
    R = float(torus.get("major_radius", torus.get("radius", 1.0)))
    a = float(torus.get("minor_radius", 0.25 * R))
    theta = np.linspace(0, 2 * np.pi, 400)
    r = R + a * np.cos(theta)
    z = a * np.sin(theta)
    return r, z


def _bounds(*fields):
    arr = np.concatenate([f.ravel() for f in fields if f is not None])
    arr = arr[np.isfinite(arr)]
    if arr.size == 0:
        return None, None
    return 0.0, np.nanpercentile(arr, 99)


def _plot_field(r, z, field, title: str, out_path: Path, overlay_r, overlay_z, vmin=None, vmax=None):
    fig, ax = plt.subplots(figsize=(6, 4))
    im = ax.imshow(
        field,
        origin="lower",
        aspect="auto",
        extent=[z.min(), z.max(), r.min(), r.max()],
        vmin=vmin,
        vmax=vmax,
        cmap="viridis",
    )
    ax.plot(overlay_z, overlay_r, color="white", linewidth=1.2, alpha=0.9)
    ax.set_xlabel("z")
    ax.set_ylabel("r")
    ax.set_title(title)
    fig.colorbar(im, ax=ax, label="error")
    out_path.parent.mkdir(parents=True, exist_ok=True)
    fig.tight_layout()
    fig.savefig(out_path, dpi=200)
    plt.close(fig)


def main() -> None:
    parser = argparse.ArgumentParser(description="Plot mid-torus error maps from NPZ diagnostics.")
    parser.add_argument("--baseline", type=Path, default=Path("runs/torus/diagnostics/mid_baseline_eigen.npz"))
    parser.add_argument("--best", type=Path, default=Path("runs/torus/diagnostics/mid_bem_highres_trial02.npz"))
    parser.add_argument("--rankfull_z060", type=Path, default=Path("runs/torus/diagnostics/mid_axis_weight_rankfull_z0.60.npz"))
    parser.add_argument("--rank2_z060", type=Path, default=Path("runs/torus/diagnostics/mid_axis_weight_rank2_z0.60.npz"))
    parser.add_argument("--rankfull_z090", type=Path, default=Path("runs/torus/diagnostics/mid_axis_weight_rankfull_z0.90.npz"))
    parser.add_argument("--rank2_z090", type=Path, default=Path("runs/torus/diagnostics/mid_axis_weight_rank2_z0.90.npz"))
    parser.add_argument("--spec", type=Path, default=Path("specs/torus_axis_point_mid.json"))
    parser.add_argument("--outdir", type=Path, default=Path("staging/figures/paper"))
    args = parser.parse_args()

    spec = CanonicalSpec.from_json(json.load(open(args.spec)))
    tor_r, tor_z = _torus_outline(spec)

    # Baseline vs best (z=0.7)
    r, z, abs_b, rel_b = _load_npz(args.baseline)
    _, _, abs_best, rel_best = _load_npz(args.best)
    vmin_abs, vmax_abs = _bounds(abs_b, abs_best)
    vmin_rel, vmax_rel = _bounds(rel_b, rel_best)
    _plot_field(r, z, abs_b, "Baseline abs err (eigen-only)", args.outdir / "fig2a_baseline_abs.png", tor_r, tor_z, vmin_abs, vmax_abs)
    _plot_field(r, z, rel_b, "Baseline rel err", args.outdir / "fig2b_baseline_rel.png", tor_r, tor_z, vmin_rel, vmax_rel)
    _plot_field(r, z, abs_best, "Best (2R+4P) abs err", args.outdir / "fig2c_best_abs.png", tor_r, tor_z, vmin_abs, vmax_abs)
    _plot_field(r, z, rel_best, "Best (2R+4P) rel err", args.outdir / "fig2d_best_rel.png", tor_r, tor_z, vmin_rel, vmax_rel)

    # Full vs rank2 at z=0.60
    r, z, abs_full60, rel_full60 = _load_npz(args.rankfull_z060)
    _, _, abs_r2_60, rel_r2_60 = _load_npz(args.rank2_z060)
    vmin_abs60, vmax_abs60 = _bounds(abs_full60, abs_r2_60)
    vmin_rel60, vmax_rel60 = _bounds(rel_full60, rel_r2_60)
    _plot_field(r, z, abs_full60, "Full (r=6) abs err z=0.60", args.outdir / "fig6a_full_abs_z0.60.png", tor_r, tor_z, vmin_abs60, vmax_abs60)
    _plot_field(r, z, rel_full60, "Full (r=6) rel err z=0.60", args.outdir / "fig6b_full_rel_z0.60.png", tor_r, tor_z, vmin_rel60, vmax_rel60)
    _plot_field(r, z, abs_r2_60, "Rank-2 abs err z=0.60", args.outdir / "fig6c_rank2_abs_z0.60.png", tor_r, tor_z, vmin_abs60, vmax_abs60)
    _plot_field(r, z, rel_r2_60, "Rank-2 rel err z=0.60", args.outdir / "fig6d_rank2_rel_z0.60.png", tor_r, tor_z, vmin_rel60, vmax_rel60)

    # Full vs rank2 at z=0.90 (failure mode)
    r, z, abs_full90, rel_full90 = _load_npz(args.rankfull_z090)
    _, _, abs_r2_90, rel_r2_90 = _load_npz(args.rank2_z090)
    vmin_abs90, vmax_abs90 = _bounds(abs_full90, abs_r2_90)
    vmin_rel90, vmax_rel90 = _bounds(rel_full90, rel_r2_90)
    _plot_field(r, z, abs_full90, "Full (r=6) abs err z=0.90", args.outdir / "fig7a_full_abs_z0.90.png", tor_r, tor_z, vmin_abs90, vmax_abs90)
    _plot_field(r, z, rel_full90, "Full (r=6) rel err z=0.90", args.outdir / "fig7b_full_rel_z0.90.png", tor_r, tor_z, vmin_rel90, vmax_rel90)
    _plot_field(r, z, abs_r2_90, "Rank-2 abs err z=0.90", args.outdir / "fig7c_rank2_abs_z0.90.png", tor_r, tor_z, vmin_abs90, vmax_abs90)
    _plot_field(r, z, rel_r2_90, "Rank-2 rel err z=0.90", args.outdir / "fig7d_rank2_rel_z0.90.png", tor_r, tor_z, vmin_rel90, vmax_rel90)


if __name__ == "__main__":
    main()

================================================================================
===== END FILE: code\plot_mid_torus_error_maps.py =====
================================================================================

================================================================================
===== BEGIN FILE: code\plot_mid_torus_geometry_cross_section.py =====
================================================================================

"""
Plot r–z cross section of the mid-torus geometry with rings and points annotated.
"""
from __future__ import annotations

import argparse
import json
import math
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import torch

from electrodrive.images.io import load_image_system
from electrodrive.orchestration.parser import CanonicalSpec


def torus_outline(R: float, a: float, n: int = 400):
    theta = np.linspace(0, 2 * np.pi, n)
    r = R + a * np.cos(theta)
    z = a * np.sin(theta)
    return r, z


def extract_rings_points(sys):
    rings = []
    points = []
    for elem in sys.elements:
        if elem.type == "poloidal_ring":
            p = elem.params
            rings.append({"radius": float(p["radius"]), "delta_r": float(p.get("delta_r", 0.0)), "order": int(p.get("order", 0))})
        elif elem.type == "point":
            pos = torch.as_tensor(elem.params["position"]).view(-1).cpu().numpy()
            rho = float(math.hypot(pos[0], pos[1]))
            points.append({"rho": rho, "z": float(pos[2])})
    rings.sort(key=lambda r: r["radius"])
    return rings, points


def main() -> None:
    ap = argparse.ArgumentParser(description="Plot mid-torus geometry cross-section with rings and points.")
    ap.add_argument("--spec", type=Path, default=Path("specs/torus_axis_point_mid.json"))
    ap.add_argument("--system", type=Path, default=Path("runs/torus/discovered/mid_bem_highres_trial02/discovered_system.json"))
    ap.add_argument("--out", type=Path, default=Path("staging/figures/paper/fig1b_geometry_cross_section.png"))
    args = ap.parse_args()

    spec = CanonicalSpec.from_json(json.load(open(args.spec)))
    torus = next(c for c in spec.conductors if c.get("type") in ("torus", "toroid"))
    R = float(torus.get("major_radius", torus.get("radius", 1.0)))
    a = float(torus.get("minor_radius", 0.25 * R))

    sys = load_image_system(args.system, device="cpu", dtype=torch.float32)
    rings, points = extract_rings_points(sys)

    fig, ax = plt.subplots(figsize=(7, 5))
    r_out, z_out = torus_outline(R, a)
    ax.plot(r_out, z_out, color="white", linewidth=1.5, alpha=0.9, label="torus outline")

    ring_color = "magenta"
    for idx, rinfo in enumerate(rings):
        ax.axvline(rinfo["radius"], color=ring_color, linestyle="--", linewidth=2.0, alpha=0.9, label="ring" if idx == 0 else None)
        ax.text(rinfo["radius"], 0.9 * a, f"ring {idx+1}", color=ring_color, ha="center", va="bottom", fontsize=9)

    point_color = "tab:orange"
    for j, p in enumerate(points):
        ax.scatter(p["rho"], p["z"], color=point_color, edgecolors="k", s=60, zorder=5, label="point" if j == 0 else None)
        ax.text(p["rho"], p["z"], f"P{j+1}", color="k", fontsize=8, ha="left", va="bottom")

    ax.set_xlabel("r")
    ax.set_ylabel("z")
    ax.set_title("Mid-torus geometry: 2 poloidal rings + 4 points")
    ax.set_aspect("equal", adjustable="box")
    ax.grid(True, alpha=0.2)
    handles, labels = ax.get_legend_handles_labels()
    if handles:
        ax.legend(loc="upper right")
    fig.tight_layout()
    args.out.parent.mkdir(parents=True, exist_ok=True)
    fig.savefig(args.out, dpi=300, bbox_inches="tight")
    plt.close(fig)


if __name__ == "__main__":
    main()

================================================================================
===== END FILE: code\plot_mid_torus_geometry_cross_section.py =====
================================================================================

================================================================================
===== BEGIN FILE: code\run_grandchallenge_experiments.py =====
================================================================================

"""
Grand Challenge experiment runner for torus + parallel-plane specs.

Runs discovery with experimental bases/solver options and logs Stage-4-like
metrics to JSON files under runs/.
"""
from __future__ import annotations

import json
import math
import os
import time
from collections import Counter
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional

import torch
import numpy as np

from electrodrive.images.search import discover_images, ImageSystem
from electrodrive.orchestration.parser import CanonicalSpec
from electrodrive.learn.collocation import make_collocation_batch_for_spec, get_oracle_solution


def _sparsity90(weights: torch.Tensor) -> int:
    w_abs = torch.abs(weights.detach()).cpu()
    if w_abs.numel() == 0:
        return 0
    total = float(w_abs.sum())
    if total <= 0.0:
        return 0
    sorted_vals, _ = torch.sort(w_abs, descending=True)
    cumsum = torch.cumsum(sorted_vals, dim=0)
    thresh = 0.9 * total
    idx = torch.nonzero(cumsum >= thresh, as_tuple=False)
    if idx.numel() == 0:
        return int(w_abs.numel())
    return int(idx[0].item() + 1)


def _axis_points(spec: CanonicalSpec, n: int = 200) -> torch.Tensor:
    bbox = getattr(spec, "domain", {}).get("bbox", None)
    if bbox and len(bbox) == 2:
        z_min = float(bbox[0][2])
        z_max = float(bbox[1][2])
    else:
        z_min, z_max = -2.0, 2.0
    z = torch.linspace(z_min, z_max, n)
    zeros = torch.zeros_like(z)
    return torch.stack([zeros, zeros, z], dim=1)


@dataclass
class EvalResult:
    metrics: Dict[str, float]
    type_counts: Dict[str, int]


def evaluate_system(
    spec: CanonicalSpec,
    system: ImageSystem,
    n_eval: int = 2000,
    ratio_boundary: float = 0.7,
    belts: Optional[List[tuple[float, float]]] = None,
) -> EvalResult:
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    dtype = torch.float32

    # Make sure weights live on the eval device.
    system.weights = system.weights.to(device=device, dtype=dtype)

    batch = make_collocation_batch_for_spec(
        spec=spec,
        n_points=n_eval,
        ratio_boundary=ratio_boundary,
        supervision_mode="auto",
        device=device,
        dtype=dtype,
    )
    X = batch["X"]
    V_gt = batch["V_gt"]
    is_boundary = batch.get("is_boundary", torch.zeros(X.shape[0], device=device, dtype=torch.bool))
    mask_finite = batch.get("mask_finite", None)
    if mask_finite is not None and mask_finite.shape == (X.shape[0],):
        mask = mask_finite.to(device=device) & torch.isfinite(V_gt)
    else:
        mask = torch.isfinite(V_gt)

    X = X[mask]
    V_gt = V_gt[mask]
    is_boundary = is_boundary[mask]

    if X.numel() == 0:
        return EvalResult(metrics={}, type_counts={})

    V_pred = system.potential(X)
    diff = torch.abs(V_pred - V_gt)
    rel = diff / (torch.abs(V_gt) + 1e-12)

    boundary_mask = is_boundary.bool()
    interior_mask = ~boundary_mask

    belt_mask = torch.zeros_like(boundary_mask)
    if belts:
        r = torch.linalg.norm(X[:, :2], dim=1)
        z = X[:, 2]
        for r_t, z_t in belts:
            belt_mask |= (torch.abs(r - r_t) <= 0.05 * abs(r_t) + 1e-6) & (
                torch.abs(z - z_t) <= 0.1 * (abs(z_t) + 1e-6)
            )

    def _safe_mean(t: torch.Tensor) -> float:
        return float(t.mean().item()) if t.numel() > 0 else float("nan")

    metrics: Dict[str, float] = {}
    metrics["boundary_mae"] = _safe_mean(diff[boundary_mask])
    metrics["offaxis_mae"] = _safe_mean(diff[interior_mask])
    metrics["offaxis_rel"] = _safe_mean(rel[interior_mask])
    metrics["offaxis_belt_rel"] = _safe_mean(rel[belt_mask]) if belt_mask.any() else float("nan")

    # Axis metrics via oracle evaluation for stability.
    try:
        sol = get_oracle_solution(spec, mode="auto", bem_cfg={})  # type: ignore[arg-type]
        axis_pts = _axis_points(spec, n=256).to(device=device, dtype=dtype)
        if sol is not None and hasattr(sol, "eval_V_E_batched"):
            V_axis_gt, _ = sol.eval_V_E_batched(axis_pts)  # type: ignore[attr-defined]
        elif sol is not None and hasattr(sol, "eval"):
            V_axis_gt = sol.eval(axis_pts)  # type: ignore[attr-defined]
        else:
            V_axis_gt = None
        if V_axis_gt is not None:
            V_axis_pred = system.potential(axis_pts)
            axis_diff = torch.abs(V_axis_pred - V_axis_gt)
            axis_rel = axis_diff / (torch.abs(V_axis_gt) + 1e-12)
            metrics["axis_mae"] = _safe_mean(axis_diff)
            metrics["axis_rel"] = _safe_mean(axis_rel)
    except Exception:
        metrics["axis_mae"] = float("nan")
        metrics["axis_rel"] = float("nan")

    metrics["n_images"] = len(system.elements)
    metrics["sparsity90"] = _sparsity90(system.weights)
    type_counts = Counter(elem.type for elem in system.elements)
    metrics["type_counts"] = dict(type_counts)

    return EvalResult(metrics=metrics, type_counts=dict(type_counts))


def run_single(
    spec: CanonicalSpec,
    basis_types: List[str],
    n_max: int,
    reg_l1: float,
    restarts: int,
    per_type_reg: Optional[Dict[str, float]] = None,
    boundary_weight: Optional[float] = None,
    two_stage: bool = False,
    belts: Optional[List[tuple[float, float]]] = None,
) -> EvalResult:
    class _NullLogger:
        def info(self, *args, **kwargs):
            pass
        def warning(self, *args, **kwargs):
            pass
        def error(self, *args, **kwargs):
            pass

    logger = _NullLogger()
    system = discover_images(
        spec=spec,
        basis_types=basis_types,
        n_max=n_max,
        reg_l1=reg_l1,
        restarts=restarts,
        logger=logger,
        per_type_reg=per_type_reg,
        boundary_weight=boundary_weight,
        two_stage=two_stage,
    )
    return evaluate_system(spec, system, belts=belts)


def save_metrics(path: Path, metrics: List[Dict[str, object]]) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    with path.open("w", encoding="utf-8") as f:
        json.dump(metrics, f, indent=2)


def main() -> None:
    root = Path(__file__).resolve().parents[1]
    runs_root = root / "runs"

    specs = {
        "parallel": CanonicalSpec.from_json(json.load(open(root / "specs" / "parallel_planes_point.json"))),
        "torus_thin": CanonicalSpec.from_json(json.load(open(root / "specs" / "torus_axis_point_thin.json"))),
        "torus_mid": CanonicalSpec.from_json(json.load(open(root / "specs" / "torus_axis_point_mid.json"))),
    }

    results_parallel: List[Dict[str, object]] = []
    plane_grid = [
        (["point"], 4, 1e-2, 0, None, None),
        (["mirror_stack"], 8, 1e-3, 0, None, 0.7),
        (["point", "mirror_stack"], 8, 1e-3, 0, {"mirror_stack": 5e-4, "point": 1e-3}, 0.7),
        (["point", "mirror_stack"], 12, 3e-3, 0, {"mirror_stack": 1e-3, "point": 3e-3}, 0.9),
    ]
    for basis, n_max, reg, restarts, per_reg, bw in plane_grid:
        tag = f"parallel_{'_'.join(basis)}_n{n_max}_reg{reg}_bw{bw}"
        t0 = time.time()
        eval_res = run_single(
            specs["parallel"],
            basis,
            n_max=n_max,
            reg_l1=reg,
            restarts=restarts,
            per_type_reg=per_reg,
            boundary_weight=bw,
            two_stage=False,
        )
        rec: Dict[str, object] = {
            "spec": "parallel_planes_point",
            "run": tag,
            "basis_types": basis,
            "n_max": n_max,
            "reg_l1": reg,
            "boundary_weight": bw,
            "restarts": restarts,
            "metrics": eval_res.metrics,
            "type_counts": eval_res.type_counts,
            "elapsed_s": time.time() - t0,
        }
        results_parallel.append(rec)

    save_metrics(runs_root / "parallel_planes" / "stage4_metrics_grandchallenge.json", results_parallel)

    torus_results: List[Dict[str, object]] = []
    torus_grid = [
        (["point"], 8, 1e-2, 0, None, 0.5, False),
        (["point", "ring"], 12, 3e-3, 0, None, 0.5, False),
        (
            ["point", "poloidal_ring", "ring_ladder_inner"],
            12,
            3e-3,
            1,
            {"point": 4e-3, "poloidal_ring": 2e-3, "ring_ladder_inner": 2e-3},
            0.8,
            True,
        ),
        (
            ["point", "poloidal_ring", "ring_ladder_inner", "ring_ladder_outer", "toroidal_mode_cluster"],
            16,
            1e-3,
            1,
            {"point": 2e-3, "poloidal_ring": 8e-4, "ring_ladder_inner": 8e-4, "ring_ladder_outer": 8e-4, "toroidal_mode_cluster": 1e-3},
            0.8,
            True,
        ),
    ]

    for spec_key in ("torus_thin", "torus_mid"):
        for basis, n_max, reg, restarts, per_reg, bw, two_stage in torus_grid:
            tag = f"{spec_key}_{'_'.join(basis)}_n{n_max}_reg{reg}_bw{bw}_ts{two_stage}"
            t0 = time.time()
            eval_res = run_single(
                specs[spec_key],
                basis,
                n_max=n_max,
                reg_l1=reg,
                restarts=restarts,
                per_type_reg=per_reg,
                boundary_weight=bw,
                two_stage=two_stage,
            )
            rec: Dict[str, object] = {
                "spec": spec_key,
                "run": tag,
                "basis_types": basis,
                "n_max": n_max,
                "reg_l1": reg,
                "boundary_weight": bw,
                "restarts": restarts,
                "two_stage": two_stage,
                "metrics": eval_res.metrics,
                "type_counts": eval_res.type_counts,
                "elapsed_s": time.time() - t0,
            }
            torus_results.append(rec)

    save_metrics(runs_root / "torus" / "stage4_metrics_grandchallenge.json", torus_results)

    # Modes-enriched grids (family-aware)
    torus_mode_results: List[Dict[str, object]] = []
    belts_default = {
        "torus_thin": [(0.0, 0.0)],  # will be overridden below
        "torus_mid": [(0.0, 0.0)],
    }
    for spec_key in ("torus_thin", "torus_mid"):
        spec_obj = specs[spec_key]
        # derive R,a for belts
        torus = next(c for c in spec_obj.conductors if c.get("type") in ("torus", "toroid"))
        R = float(torus.get("major_radius", torus.get("radius", 1.0)))
        a = float(torus.get("minor_radius", 0.25 * R))
        belts = [
            (R - 0.5 * a, -0.2 * a),
            (R - 0.5 * a, 0.0),
            (R - 0.5 * a, 0.2 * a),
            (R, 0.0),
            (R + 0.5 * a, -0.2 * a),
            (R + 0.5 * a, 0.0),
            (R + 0.5 * a, 0.2 * a),
            (R + a, 0.0),
        ]
        belts_default[spec_key] = belts

    torus_mode_grid = []
    for spec_key in ("torus_thin", "torus_mid"):
        torus_mode_grid.extend(
            [
                (spec_key, ["point", "toroidal_eigen_mode_boundary"], 12, 1e-3, {"point": 2e-3, "toroidal_eigen_mode_boundary": 8e-4}, 0.8, False),
                (spec_key, ["point", "toroidal_eigen_mode_offaxis"], 12, 1e-3, {"point": 3e-3, "toroidal_eigen_mode_offaxis": 8e-4}, 0.5, False),
                (spec_key, ["point", "poloidal_ring", "toroidal_eigen_mode_boundary", "ring_ladder_inner"], 16, 1e-3, {"point": 3e-3, "poloidal_ring": 1e-3, "ring_ladder_inner": 1e-3, "toroidal_eigen_mode_boundary": 8e-4}, 0.8, True),
                (spec_key, ["point", "poloidal_ring", "toroidal_eigen_mode_offaxis", "ring_ladder_inner"], 16, 1e-3, {"point": 4e-3, "poloidal_ring": 1e-3, "ring_ladder_inner": 1e-3, "toroidal_eigen_mode_offaxis": 8e-4}, 0.5, True),
            ]
        )

    for spec_key, basis, n_max, reg, per_reg, bw, two_stage in torus_mode_grid:
        tag = f"{spec_key}_{'_'.join(basis)}_n{n_max}_reg{reg}_bw{bw}_ts{two_stage}"
        t0 = time.time()
        eval_res = run_single(
            specs[spec_key],
            basis,
            n_max=n_max,
            reg_l1=reg,
            restarts=1,
            per_type_reg=per_reg,
            boundary_weight=bw,
            two_stage=two_stage,
            belts=belts_default[spec_key],
        )
        rec: Dict[str, object] = {
            "spec": spec_key,
            "run": tag,
            "basis_types": basis,
            "n_max": n_max,
            "reg_l1": reg,
            "boundary_weight": bw,
            "restarts": 1,
            "two_stage": two_stage,
            "per_type_reg": per_reg,
            "metrics": eval_res.metrics,
            "type_counts": eval_res.type_counts,
            "elapsed_s": time.time() - t0,
        }
        torus_mode_results.append(rec)

    save_metrics(runs_root / "torus" / "stage4_metrics_modes_families.json", torus_mode_results)

    # Robust evaluation of top mode-family runs (best boundary / best off-axis-belt per spec)
    robust_results: List[Dict[str, object]] = []
    for spec_key in ("torus_thin", "torus_mid"):
        subset = [r for r in torus_mode_results if r.get("spec") == spec_key]
        if not subset:
            continue
        best_boundary = min(subset, key=lambda r: r["metrics"]["boundary_mae"])
        boundary_floor = best_boundary["metrics"]["boundary_mae"] * 3.0
        filt = [r for r in subset if r["metrics"]["boundary_mae"] <= boundary_floor]
        best_off = min(filt, key=lambda r: r["metrics"].get("offaxis_belt_rel", math.inf))
        for rec in {best_boundary["run"]: best_boundary, best_off["run"]: best_off}.values():
            system = discover_images(
                spec=specs[spec_key],
                basis_types=rec["basis_types"],
                n_max=rec["n_max"],
                reg_l1=rec["reg_l1"],
                restarts=rec["restarts"],
                logger=type("L", (), {"info": lambda *a, **k: None, "warning": lambda *a, **k: None, "error": lambda *a, **k: None})(),
                per_type_reg=rec.get("per_type_reg") or None,
                boundary_weight=rec.get("boundary_weight"),
                two_stage=rec.get("two_stage", False),
            )
            eval_res = evaluate_system(
                specs[spec_key],
                system,
                n_eval=6000,
                ratio_boundary=0.8,
                belts=belts_default[spec_key],
            )
            robust_results.append(
                {
                    "spec": spec_key,
                    "run": rec["run"],
                    "basis_types": rec["basis_types"],
                    "metrics": eval_res.metrics,
                    "type_counts": eval_res.type_counts,
                }
            )

    save_metrics(runs_root / "torus" / "stage4_metrics_modes_families_robust.json", robust_results)

    # Phase 4: inner-rim localized primitives
    print("[inner-rim] building belts and grid...")
    inner_rim_results: List[Dict[str, object]] = []
    belts_inner: Dict[str, List[tuple[float, float]]] = {}
    for spec_key in ("torus_thin", "torus_mid"):
        spec_obj = specs[spec_key]
        torus = next(c for c in spec_obj.conductors if c.get("type") in ("torus", "toroid"))
        R = float(torus.get("major_radius", torus.get("radius", 1.0)))
        a = float(torus.get("minor_radius", 0.25 * R))
        r_vals = [R - a, R - 0.75 * a, R - 0.5 * a]
        z_vals = [0.0, 0.2 * a, -0.2 * a]
        belts = []
        for r in r_vals:
            for z in z_vals:
                belts.append((r, z))
        belts_inner[spec_key] = belts

    inner_rim_grid = []
    for spec_key in ("torus_thin", "torus_mid"):
        inner_rim_grid.extend(
            [
                (spec_key, ["point", "toroidal_eigen_mode_boundary"], 12, 1e-3, {"point": 2e-3, "toroidal_eigen_mode_boundary": 8e-4}, 0.8, False),
                (spec_key, ["point", "poloidal_ring", "toroidal_eigen_mode_boundary", "ring_ladder_inner"], 16, 1e-3, {"point": 3e-3, "poloidal_ring": 1e-3, "ring_ladder_inner": 1e-3, "toroidal_eigen_mode_boundary": 8e-4}, 0.8, True),
                (spec_key, ["point", "toroidal_eigen_mode_boundary", "inner_rim_arc"], 12, 8e-4, {"point": 2e-3, "toroidal_eigen_mode_boundary": 8e-4, "inner_rim_arc": 8e-4}, 0.8, False),
                (spec_key, ["point", "toroidal_eigen_mode_boundary", "inner_rim_ribbon"], 12, 8e-4, {"point": 2e-3, "toroidal_eigen_mode_boundary": 8e-4, "inner_rim_ribbon": 8e-4}, 0.8, False),
                (spec_key, ["point", "toroidal_eigen_mode_boundary", "inner_rim_arc", "inner_rim_ribbon", "inner_patch_ring"], 16, 8e-4, {"point": 3e-3, "toroidal_eigen_mode_boundary": 8e-4, "inner_rim_arc": 8e-4, "inner_rim_ribbon": 8e-4, "inner_patch_ring": 1e-3}, 0.8, True),
                (spec_key, ["point", "inner_rim_arc", "inner_rim_ribbon", "inner_patch_ring"], 12, 1e-3, {"point": 4e-3, "inner_rim_arc": 1e-3, "inner_rim_ribbon": 1e-3, "inner_patch_ring": 1e-3}, 0.7, False),
            ]
        )

    print(f"[inner-rim] grid size: {len(inner_rim_grid)}")
    for spec_key, basis, n_max, reg, per_reg, bw, two_stage in inner_rim_grid:
        tag = f"{spec_key}_{'_'.join(basis)}_n{n_max}_reg{reg}_bw{bw}_ts{two_stage}_inner"
        t0 = time.time()
        print(f"[inner-rim] running {tag}")
        eval_res = run_single(
            specs[spec_key],
            basis,
            n_max=n_max,
            reg_l1=reg,
            restarts=1,
            per_type_reg=per_reg,
            boundary_weight=bw,
            two_stage=two_stage,
            belts=belts_inner[spec_key],
        )
        rec: Dict[str, object] = {
            "spec": spec_key,
            "run": tag,
            "basis_types": basis,
            "n_max": n_max,
            "reg_l1": reg,
            "boundary_weight": bw,
            "restarts": 1,
            "two_stage": two_stage,
            "per_type_reg": per_reg,
            "metrics": eval_res.metrics,
            "type_counts": eval_res.type_counts,
            "elapsed_s": time.time() - t0,
        }
        inner_rim_results.append(rec)

    print("[inner-rim] saving primary metrics")
    save_metrics(runs_root / "torus" / "stage4_metrics_inner_rim.json", inner_rim_results)

    # Robust inner-rim evaluation: best boundary and best belt under boundary filter
    inner_rim_robust: List[Dict[str, object]] = []
    for spec_key in ("torus_thin", "torus_mid"):
        subset = [r for r in inner_rim_results if r.get("spec") == spec_key]
        if not subset:
            continue
        best_boundary = min(subset, key=lambda r: r["metrics"]["boundary_mae"])
        boundary_floor = best_boundary["metrics"]["boundary_mae"] * 3.0
        filt = [r for r in subset if r["metrics"]["boundary_mae"] <= boundary_floor]
        best_off = min(filt, key=lambda r: r["metrics"].get("offaxis_belt_rel", math.inf))
        for rec in {best_boundary["run"]: best_boundary, best_off["run"]: best_off}.values():
            system = discover_images(
                spec=specs[spec_key],
                basis_types=rec["basis_types"],
                n_max=rec["n_max"],
                reg_l1=rec["reg_l1"],
                restarts=rec["restarts"],
                logger=type("L", (), {"info": lambda *a, **k: None, "warning": lambda *a, **k: None, "error": lambda *a, **k: None})(),
                per_type_reg=rec.get("per_type_reg") or None,
                boundary_weight=rec.get("boundary_weight"),
                two_stage=rec.get("two_stage", False),
            )
            eval_res = evaluate_system(
                specs[spec_key],
                system,
                n_eval=6000,
                ratio_boundary=0.8,
                belts=belts_inner[spec_key],
            )
            inner_rim_robust.append(
                {
                    "spec": spec_key,
                    "run": rec["run"],
                    "basis_types": rec["basis_types"],
                    "metrics": eval_res.metrics,
                    "type_counts": eval_res.type_counts,
                }
            )

    print("[inner-rim] saving robust metrics")
    save_metrics(runs_root / "torus" / "stage4_metrics_inner_rim_robust.json", inner_rim_robust)

    # Refined inner-rim arcs (rich_inner_rim) for near-contact thin torus
    print("[inner-rim] running refined thin rich_inner_rim grid...")
    inner_rim_refined: List[Dict[str, object]] = []
    refined_grid = [
        (
            "torus_thin",
            ["point", "toroidal_eigen_mode_boundary", "inner_rim_arc", "rich_inner_rim"],
            12,
            8e-4,
            {"point": 2e-3, "toroidal_eigen_mode_boundary": 8e-4, "inner_rim_arc": 8e-4},
            0.8,
            False,
        )
    ]
    for spec_key, basis, n_max, reg, per_reg, bw, two_stage in refined_grid:
        tag = f"{spec_key}_{'_'.join(basis)}_n{n_max}_reg{reg}_bw{bw}_ts{two_stage}_rich_inner"
        t0 = time.time()
        eval_res = run_single(
            specs[spec_key],
            basis,
            n_max=n_max,
            reg_l1=reg,
            restarts=1,
            per_type_reg=per_reg,
            boundary_weight=bw,
            two_stage=two_stage,
            belts=belts_inner[spec_key],
        )
        inner_rim_refined.append(
            {
                "spec": spec_key,
                "run": tag,
                "basis_types": basis,
                "n_max": n_max,
                "reg_l1": reg,
                "boundary_weight": bw,
                "restarts": 1,
                "two_stage": two_stage,
                "per_type_reg": per_reg,
                "metrics": eval_res.metrics,
                "type_counts": eval_res.type_counts,
                "elapsed_s": time.time() - t0,
            }
        )
    save_metrics(runs_root / "torus" / "stage4_metrics_inner_rim_refined.json", inner_rim_refined)



if __name__ == "__main__":
    main()

================================================================================
===== END FILE: code\run_grandchallenge_experiments.py =====
================================================================================

================================================================================
===== BEGIN FILE: code\search.py =====
================================================================================

from __future__ import annotations

from typing import Any, Dict, List, Tuple, Optional

import hashlib
import os

import numpy as np
import torch

from electrodrive.images.basis import (
    ImageBasisElement,
    generate_candidate_basis,
    build_dictionary,
)
# NOTE: images currently depends on learn.collocation for collocation sampling.
# In a future refactor, this should move to a shared core.collocation module.
from electrodrive.learn.collocation import make_collocation_batch_for_spec
from electrodrive.orchestration.parser import CanonicalSpec
from electrodrive.utils.logging import JsonlLogger


class ImageSystem:
    """A concrete image system: basis elements + weights."""

    def __init__(self, elements: List[ImageBasisElement], weights: torch.Tensor):
        self.elements = elements
        self.weights = weights
        if weights.numel() > 0:
            self.device = weights.device
            self.dtype = weights.dtype
        else:
            self.device = torch.device("cpu")
            self.dtype = torch.float32

    def potential(self, targets: torch.Tensor) -> torch.Tensor:
        """Evaluate the image-system potential at a batch of points."""
        V = torch.zeros(
            targets.shape[0],
            device=targets.device,
            dtype=targets.dtype,
        )
        for elem, w in zip(self.elements, self.weights):
            V = V + w.to(targets.dtype) * elem.potential(targets)
        return V


def _make_collocation_rng() -> np.random.Generator:
    """Deterministic RNG for image-discovery collocation sampling.

    Uses a fixed base seed and optionally folds in EDE_RUN_ID to keep
    runs reproducible but still vary across run IDs.
    """
    base_seed = 12345
    run_id = os.getenv("EDE_RUN_ID", "")
    if run_id:
        h = hashlib.sha1(run_id.encode("utf-8")).digest()
        run_hash = int.from_bytes(h[:8], "little") & 0xFFFFFFFF
        seed = (base_seed ^ run_hash) & 0xFFFFFFFF
    else:
        seed = base_seed
    return np.random.default_rng(seed)


def get_collocation_data(
    spec: CanonicalSpec,
    logger: JsonlLogger,
    device: torch.device,
    dtype: torch.dtype,
    return_is_boundary: bool = False,
) -> Tuple[torch.Tensor, torch.Tensor] | Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
    """Build collocation points + targets for a given spec.

    This delegates to :func:`make_collocation_batch_for_spec` from the
    learning stack so that analytic shortcuts and BEM fallbacks are
    shared between training and the sparse image discovery path.

    Returns
    -------
    colloc_pts : torch.Tensor
        [N, 3] collocation points.
    target : torch.Tensor
        [N] oracle potential values.
    is_boundary : torch.Tensor (optional)
        [N] boolean mask of boundary points when requested.
    """
    device = torch.device(device)

    # Allow light-weight overrides for experimentation via environment.
    try:
        n_points_env = int(os.getenv("EDE_IMAGES_N_POINTS", "0"))
        n_points = n_points_env if n_points_env > 0 else 512
    except Exception:
        n_points = 512

    try:
        ratio_env = float(os.getenv("EDE_IMAGES_RATIO_BOUNDARY", "nan"))
        ratio_boundary = ratio_env if 0.0 < ratio_env < 1.0 else 0.5
    except Exception:
        ratio_boundary = 0.5

    rng = _make_collocation_rng()

    try:
        batch = make_collocation_batch_for_spec(
            spec=spec,
            n_points=n_points,
            ratio_boundary=ratio_boundary,
            supervision_mode="auto",
            device=device,
            dtype=dtype,
            rng=rng,
        )
    except Exception as e:  # defensive path
        logger.error(
            "Collocation batch construction failed.",
            error=str(e),
        )
        return (
            torch.empty(0, 3, device=device, dtype=dtype),
            torch.empty(0, device=device, dtype=dtype),
        )

    X = batch.get("X")
    V = batch.get("V_gt")

    if X is None or V is None or X.numel() == 0 or V.numel() == 0:
        logger.error(
            "Collocation helper returned an empty batch.",
            n_points_requested=int(n_points),
        )
        return (
            torch.empty(0, 3, device=device, dtype=dtype),
            torch.empty(0, device=device, dtype=dtype),
        )

    mask_finite = batch.get("mask_finite")
    if mask_finite is not None and mask_finite.shape == (X.shape[0],):
        mask = mask_finite.to(device=device, dtype=torch.bool) & torch.isfinite(V)
    else:
        mask = torch.isfinite(V)

    if not mask.any():
        logger.error(
            "Collocation batch has no finite targets.",
            n_points_total=int(X.shape[0]),
        )
        return (
            torch.empty(0, 3, device=device, dtype=dtype),
            torch.empty(0, device=device, dtype=dtype),
        )

    X_f = X[mask].to(device=device, dtype=dtype)
    V_f = V[mask].to(device=device, dtype=dtype)
    is_boundary_out: torch.Tensor | None = None

    N = int(X_f.shape[0])

    # Estimate boundary fraction if available.
    n_boundary = 0
    is_boundary = batch.get("is_boundary")
    if return_is_boundary and is_boundary is not None and is_boundary.shape == (X.shape[0],):
        is_boundary = is_boundary.to(device=device)
        n_boundary = int(is_boundary[mask].sum().item())
        is_boundary_out = is_boundary[mask]

    frac_boundary = float(n_boundary) / float(N) if N > 0 else 0.0

    V_min = float(V_f.min().item()) if N > 0 else float("nan")
    V_max = float(V_f.max().item()) if N > 0 else float("nan")

    logger.info(
        "Collocation data prepared.",
        n_points=N,
        n_boundary=n_boundary,
        frac_boundary=frac_boundary,
        V_min=V_min,
        V_max=V_max,
    )

    # Backward-compatible return: if no boundary mask requested, return two tensors.
    if is_boundary_out is None:
        return X_f, V_f
    return X_f, V_f, is_boundary_out


def assemble_basis_matrix(
    basis_set: List[ImageBasisElement],
    points: torch.Tensor,
) -> torch.Tensor:
    """Assemble A[N,K] with columns A[:, k] = basis_set[k].potential(points).

    This delegates to :func:`build_dictionary` in electrodrive.images.basis
    so that basis evaluation stays centralized.
    """
    return build_dictionary(
        basis_set,
        points,
        device=points.device,
        dtype=points.dtype,
    )


def solve_l1_ista(
    A: torch.Tensor,
    g: torch.Tensor,
    reg_l1: float,
    logger: JsonlLogger,
    max_iter: int = 1000,
    tol: float = 1e-6,
    per_elem_reg: Optional[torch.Tensor] = None,
) -> Tuple[torch.Tensor, List[int]]:
    """Solve the L1-regularised least-squares problem via ISTA.

    Minimises 0.5 * ||A w - g||_2^2 + reg_l1 * ||w||_1.

    The implementation is intentionally simple and robust rather than
    aggressively tuned; it is shared between all geometries and does not
    hard-code any problem-specific structure.
    """
    if A.numel() == 0 or g.numel() == 0:
        # Nothing to do; construct a correctly-shaped zero vector.
        K = A.shape[1] if A.ndim == 2 else 0
        return torch.zeros(K, device=A.device, dtype=A.dtype), []

    N_k = A.shape[1]

    # Estimate the Lipschitz constant L of A^T A using either SVD or a
    # short power iteration, falling back cleanly on failure.
    try:
        _, S, _ = torch.linalg.svd(A, full_matrices=False)
        L = float(S[0] ** 2) if S.numel() > 0 else 1.0
    except Exception:  # rarely hit in practice
        x = torch.randn(N_k, device=A.device, dtype=A.dtype)
        for _ in range(20):
            x = A.T @ (A @ x)
            n = torch.linalg.norm(x)
            if float(n) < 1e-9:
                break
            x = x / n
        L = float(torch.linalg.norm(A.T @ (A @ x))) or 1.0

    if L <= 0.0:
        logger.warning("ISTA: non-positive Lipschitz estimate, aborting.")
        return torch.zeros(N_k, device=A.device, dtype=A.dtype), []

    alpha = 1.0 / L
    thr = reg_l1 * alpha
    thr_vec: Optional[torch.Tensor] = None
    if per_elem_reg is not None:
        thr_vec = per_elem_reg.to(device=A.device, dtype=A.dtype) * alpha
    w = torch.zeros(N_k, device=A.device, dtype=A.dtype)

    last_rel_change: float = float("inf")

    for it in range(max_iter):
        w_prev = w.clone()
        r = A @ w - g
        grad = A.T @ r
        w = w - alpha * grad
        # Soft-thresholding (L1 proximal step).
        if thr_vec is not None:
            w = torch.sign(w) * torch.clamp(torch.abs(w) - thr_vec, min=0.0)
        else:
            w = torch.sign(w) * torch.clamp(torch.abs(w) - thr, min=0.0)
        num = float(torch.linalg.norm(w - w_prev))
        den = float(torch.linalg.norm(w) + 1e-9)
        if den > 0.0:
            last_rel_change = num / den
        if den > 0.0 and last_rel_change < tol:
            logger.info(
                "ISTA converged.",
                iters=int(it + 1),
                rel_change=float(last_rel_change),
            )
            break
    else:
        logger.warning(
            "ISTA did not converge.",
            max_iter=int(max_iter),
            final_rel_change=float(last_rel_change),
        )

    # Determine support using a relative threshold so that rescaling A or
    # g does not spuriously drive all coefficients below a fixed cutoff.
    w_abs = torch.abs(w)
    if w_abs.numel() == 0:
        support: List[int] = []
    else:
        max_abs = float(w_abs.max().item())
        if max_abs == 0.0:
            support = []
        else:
            rel_tol = 1e-6
            abs_tol = 1e-12
            thr_support = max(abs_tol, rel_tol * max_abs)
            support = torch.where(w_abs > thr_support)[0].tolist()

    return w, support


def optimize_parameters_lbfgs(
    system: ImageSystem,
    points: torch.Tensor,
    g: torch.Tensor,
    logger: JsonlLogger,
) -> ImageSystem:
    """
    Optional second-stage refinement using L-BFGS.

    We treat the image weights and any float Tensor-valued parameters in
    each ImageBasisElement (for example, point-charge positions) as
    optimization variables. The objective is the mean-squared error
    between the image-system potential and the oracle targets ``g`` on
    the supplied collocation points.

    This routine is deliberately defensive: it never raises to callers
    and falls back to the incoming system on failure.
    """
    # Trivial early-exit guards.
    if system.weights.numel() == 0:
        logger.info("L-BFGS skipped: empty image system.")
        return system
    if points.numel() == 0 or g.numel() == 0:
        logger.info("L-BFGS skipped: no collocation data passed in.")
        return system

    device = system.weights.device
    dtype = system.weights.dtype
    points = points.to(device=device, dtype=dtype)
    g = g.to(device=device, dtype=dtype)

    # Clone weights so we do not backprop through the ISTA step.
    w = system.weights.detach().clone().to(device=device, dtype=dtype)
    w.requires_grad_(True)
    system.weights = w

    params: List[torch.Tensor] = [w]

    # Promote any floating-point Tensor parameters inside basis elements.
    for elem in system.elements:
        new_params: Dict[str, torch.Tensor] = {}
        for name, value in elem.params.items():
            if isinstance(value, torch.Tensor) and value.is_floating_point():
                p = value.detach().clone().to(device=device, dtype=dtype)
                p.requires_grad_(True)
                new_params[name] = p
                params.append(p)
            else:
                new_params[name] = value
        elem.params = new_params

    # If only the weights are trainable, a closed-form least-squares
    # update is cheaper and more stable than running L-BFGS.
    if len(params) == 1:
        logger.info(
            "L-BFGS skipped: only weights are trainable; using LS re-fit."
        )
        try:
            with torch.no_grad():
                A = assemble_basis_matrix(system.elements, points)
                if A.numel() == 0:
                    return system
                # Normal equations with tiny Tikhonov regularisation.
                reg = 1e-8
                ATA = A.T @ A + reg * torch.eye(
                    A.shape[1], device=device, dtype=dtype
                )
                ATg = A.T @ g
                w_ls = torch.linalg.solve(ATA, ATg)
                return ImageSystem(system.elements, w_ls)
        except Exception as exc:  # defensive
            logger.warning(
                "Least-squares refinement failed; keeping original system.",
                error=str(exc),
            )
            return system

    # L-BFGS over weights + element parameters.
    try:
        max_iter_env = os.getenv("EDE_IMAGES_LBFGS_MAX_ITER", "")
        try:
            max_iter = int(max_iter_env) if max_iter_env else 50
        except Exception:
            max_iter = 50

        optimizer = torch.optim.LBFGS(
            params,
            lr=1.0,
            max_iter=max_iter,
            history_size=10,
            line_search_fn="strong_wolfe",
        )

        def closure() -> torch.Tensor:
            optimizer.zero_grad(set_to_none=True)
            V_pred = system.potential(points)
            loss = torch.mean((V_pred - g) ** 2)
            if not torch.isfinite(loss):
                # Abort cleanly if numerics blow up.
                return torch.tensor(float("inf"), device=device, dtype=dtype)
            loss.backward()
            return loss

        final_loss = optimizer.step(closure)
        try:
            loss_val = float(final_loss.detach().cpu())
        except Exception:
            loss_val = float("nan")
        logger.info(
            "L-BFGS refinement complete.",
            loss=loss_val,
            n_images=len(system.elements),
        )
    except Exception as exc:  # defensive
        logger.warning(
            "L-BFGS refinement failed; returning original system.",
            error=str(exc),
        )
        return system

    with torch.no_grad():
        new_weights = w.detach()
    return ImageSystem(system.elements, new_weights)


def discover_images(
    spec: CanonicalSpec,
    basis_types: List[str],
    n_max: int,
    reg_l1: float,
    restarts: int,
    logger: JsonlLogger,
    per_type_reg: Optional[Dict[str, float]] = None,
    boundary_weight: Optional[float] = None,
    two_stage: bool = False,
    nonlocal_types: Optional[List[str]] = None,
) -> ImageSystem:
    """Top-level entry point for sparse image discovery."""

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    dtype = torch.float32

    logger.info(
        "Sparse image discovery started.",
        basis_types=basis_types,
        n_max=int(n_max),
        reg_l1=float(reg_l1),
        device=str(device),
    )

    # 1) Propose candidate basis elements for this spec.
    candidates = generate_candidate_basis(
        spec,
        basis_types=basis_types,
        n_candidates=max(1, n_max * 4),
        device=device,
        dtype=dtype,
    )
    if not candidates:
        logger.warning(
            "No candidate basis elements generated for this configuration."
        )
        return ImageSystem([], torch.zeros(0, device=device, dtype=dtype))

    logger.info(
        "Generated candidate basis elements.",
        n_candidates=len(candidates),
    )

    # 2) Build collocation set from the oracle.
    colloc_out = get_collocation_data(
        spec,
        logger,
        device=device,
        dtype=dtype,
        return_is_boundary=boundary_weight is not None,
    )
    if isinstance(colloc_out, tuple) and len(colloc_out) == 3:
        colloc_pts, target, is_boundary = colloc_out  # type: ignore[misc]
    else:
        colloc_pts, target = colloc_out  # type: ignore[misc]
        is_boundary = None
    if colloc_pts.shape[0] == 0:
        logger.error(
            "Collocation data generation failed; returning empty image system."
        )
        return ImageSystem([], torch.zeros(0, device=device, dtype=dtype))

    # 3) Assemble dictionary and optional boundary weighting.
    A = assemble_basis_matrix(candidates, colloc_pts)

    row_weights = None
    if boundary_weight is not None and is_boundary is not None and is_boundary.shape == (colloc_pts.shape[0],):
        alpha = float(max(0.0, min(1.0, boundary_weight)))
        beta = 1.0 - alpha
        is_boundary = is_boundary.to(device=device)
        row_weights = torch.where(
            is_boundary,
            torch.full_like(is_boundary, alpha, dtype=dtype),
            torch.full_like(is_boundary, beta, dtype=dtype),
        )
        rw_sqrt = torch.sqrt(row_weights).view(-1, 1)
        A = A * rw_sqrt
        target = target * rw_sqrt.view(-1)

    per_elem_reg_vec: Optional[torch.Tensor] = None
    if per_type_reg:
        reg_list = []
        for elem in candidates:
            reg_list.append(float(per_type_reg.get(elem.type, reg_l1)))
        per_elem_reg_vec = torch.tensor(reg_list, device=device, dtype=dtype)

    def _run_solver(A_in: torch.Tensor, g_in: torch.Tensor, elems: List[ImageBasisElement], reg_vec: Optional[torch.Tensor]) -> Tuple[torch.Tensor, List[int]]:
        return solve_l1_ista(
            A_in,
            g_in,
            reg_l1,
            logger,
            per_elem_reg=reg_vec,
        )

    # Helper: assemble system from selected indices and weights.
    def _build_system(idx_list: List[int], weights_vec: torch.Tensor) -> ImageSystem:
        selected = [candidates[i] for i in idx_list]
        w_sel = weights_vec[: len(selected)]
        return ImageSystem(selected, w_sel)

    # Two-stage path: solve non-local then point cleanup on residual.
    if two_stage:
        nonlocal_types = nonlocal_types or [
            "ring",
            "ring_gauss",
            "poloidal_ring",
            "ring_ladder_inner",
            "ring_ladder_outer",
            "toroidal_mode_cluster",
        ]
        nonlocal_idx = [i for i, c in enumerate(candidates) if c.type in nonlocal_types]
        point_idx = [i for i, c in enumerate(candidates) if c.type == "point"]

        if not nonlocal_idx:
            two_stage = False  # fall back
        else:
            A_non = A[:, nonlocal_idx]
            reg_non = per_elem_reg_vec[nonlocal_idx] if per_elem_reg_vec is not None else None
            w_non, supp_non = _run_solver(A_non, target, [candidates[i] for i in nonlocal_idx], reg_non)

            target_res = target
            if supp_non:
                w_non_sel = w_non[supp_non]
                A_non_sel = A_non[:, supp_non]
                target_res = target - A_non_sel @ w_non_sel

            w_point = torch.zeros(len(point_idx), device=device, dtype=dtype)
            supp_point: List[int] = []
            if point_idx:
                A_point = A[:, point_idx]
                reg_point = per_elem_reg_vec[point_idx] if per_elem_reg_vec is not None else None
                w_point, supp_point = _run_solver(
                    A_point,
                    target_res,
                    [candidates[i] for i in point_idx],
                    reg_point,
                )

            combined_idx: List[int] = []
            combined_w: List[torch.Tensor] = []
            for j in supp_non:
                combined_idx.append(nonlocal_idx[j])
                combined_w.append(w_non[j])
            for j in supp_point:
                combined_idx.append(point_idx[j])
                combined_w.append(w_point[j])

            if not combined_idx:
                # Fall back to dense LS below.
                weights = torch.zeros(len(candidates), device=device, dtype=dtype)
                support_idx = []
            else:
                w_concat = torch.stack(combined_w) if combined_w else torch.zeros(0, device=device, dtype=dtype)
                # Enforce n_max globally.
                if len(combined_idx) > n_max:
                    abs_w = torch.abs(w_concat)
                    topk = torch.topk(abs_w, k=n_max, largest=True)
                    combined_idx = [combined_idx[i] for i in topk.indices.tolist()]
                    w_concat = w_concat[topk.indices]
                # LS refit on combined support.
                try:
                    A_sel = A[:, combined_idx][:, : len(combined_idx)]
                    reg_ls = 1e-8
                    ATA = A_sel.T @ A_sel + reg_ls * torch.eye(A_sel.shape[1], device=A_sel.device, dtype=A_sel.dtype)
                    ATg = A_sel.T @ target
                    w_ls = torch.linalg.solve(ATA, ATg)
                    w_concat = w_ls[: len(combined_idx)]
                except Exception as exc:
                    logger.warning("Two-stage LS refinement failed; keeping sparse weights.", error=str(exc))
                weights = torch.zeros(len(candidates), device=device, dtype=dtype)
                for idx_val, w_val in zip(combined_idx, w_concat):
                    weights[idx_val] = w_val
                support_idx = combined_idx
    # Standard single-stage path.
    if not two_stage:
        weights, support_idx = _run_solver(A, target, candidates, per_elem_reg_vec)

    # 4) If ISTA finds no clearly non-zero coefficients, fall back to a
    #    dense least-squares fit over all candidates instead of giving up.
    if not support_idx:
        logger.warning(
            "Sparse solver selected no non-zero image weights; "
            "falling back to dense least-squares fit."
        )
        try:
            if A.numel() == 0 or A.shape[1] == 0:
                return ImageSystem([], torch.zeros(0, device=device, dtype=dtype))

            # Normal equations with tiny Tikhonov regularisation.
            reg_ls = 1e-8
            ATA = A.T @ A + reg_ls * torch.eye(A.shape[1], device=device, dtype=dtype)
            ATg = A.T @ target
            w_ls = torch.linalg.solve(ATA, ATg)

            # Enforce n_max by keeping the largest-|w| coefficients.
            k = min(n_max, w_ls.numel())
            if k <= 0:
                return ImageSystem([], torch.zeros(0, device=device, dtype=dtype))

            topk = torch.topk(w_ls.abs(), k=k, largest=True)
            idx = topk.indices
            selected = [candidates[int(i)] for i in idx]
            w_sel = w_ls[idx]

            system = ImageSystem(selected, w_sel)

            if restarts > 0:
                system = optimize_parameters_lbfgs(
                    system,
                    colloc_pts,
                    target,
                    logger,
                )

            logger.info(
                "Image discovery complete (LS fallback).",
                n_images=len(system.elements),
            )
            return system
        except Exception as exc:  # defensive
            logger.warning(
                "Dense least-squares fallback failed; returning empty image system.",
                error=str(exc),
            )
            return ImageSystem([], torch.zeros(0, device=device, dtype=dtype))

    # 5) Sparse-support path: keep up to n_max ISTA-selected candidates.
    selected = [candidates[i] for i in support_idx][:n_max]
    w_sel = weights[support_idx][: len(selected)]

    # Optional LS refit on the selected support to improve fit quality.
    try:
        A_sel = A[:, support_idx][:, : len(selected)]
        if A_sel.numel() > 0 and A_sel.shape[1] > 0:
            reg_ls = 1e-8
            ATA = A_sel.T @ A_sel + reg_ls * torch.eye(
                A_sel.shape[1], device=A_sel.device, dtype=A_sel.dtype
            )
            ATg = A_sel.T @ target
            w_ls = torch.linalg.solve(ATA, ATg)
            w_sel = w_ls[: len(selected)]
    except Exception as exc:
        logger.warning("Least-squares refinement on support failed.", error=str(exc))
    system = ImageSystem(selected, w_sel)

    if restarts > 0:
        system = optimize_parameters_lbfgs(
            system,
            colloc_pts,
            target,
            logger,
        )

    logger.info(
        "Image discovery complete.",
        n_images=len(system.elements),
    )
    return system

================================================================================
===== END FILE: code\search.py =====
================================================================================

================================================================================
===== BEGIN FILE: code\test_stress.py =====
================================================================================

from __future__ import annotations

import math
import time

import pytest
import torch
from torch import Tensor

from electrodrive.utils.config import K_E
from electrodrive.fmm3d.config import FmmConfig
from electrodrive.fmm3d.tree import FmmTree
from electrodrive.fmm3d.interaction_lists import build_interaction_lists
from electrodrive.fmm3d.kernels_cpu import apply_p2p_cpu_tiled
# Use the actual, working factory from our BEM-FMM module
from electrodrive.fmm3d.bem_fmm import make_laplace_fmm_backend, LaplaceFmm3D
from electrodrive.core.bem_kernel import bem_matvec_gpu, DEFAULT_SINGLE_LAYER_KERNEL


# ------------------------------
# Helpers
# ------------------------------


def make_random_points(n: int, seed: int, mode: str = "uniform") -> tuple[Tensor, Tensor]:
    """
    Generate a synthetic system of point charges for FMM stress testing.
    Positions in [-1, 1]^3, charges ~ N(0,1), with different spatial structures.
    """
    torch.manual_seed(seed)
    if mode == "uniform":
        x = 2.0 * torch.rand(n, 3, dtype=torch.float64) - 1.0
    elif mode == "clusters":
        # two clusters separated in space
        n1 = n // 2
        n2 = n - n1
        c1 = torch.tensor([+0.5, 0.0, 0.0], dtype=torch.float64)
        c2 = torch.tensor([-0.5, 0.0, 0.0], dtype=torch.float64)
        x1 = c1 + 0.1 * torch.randn(n1, 3, dtype=torch.float64)
        x2 = c2 + 0.1 * torch.randn(n2, 3, dtype=torch.float64)
        x = torch.cat([x1, x2], dim=0)
    elif mode == "shell":
        # points approximately on a sphere of radius ~0.8
        r = 0.8
        u = torch.randn(n, 3, dtype=torch.float64)
        u = u / u.norm(dim=1, keepdim=True)
        x = r * u + 0.05 * torch.randn(n, 3, dtype=torch.float64)
    else:
        raise ValueError(f"Unknown mode={mode!r}")

    q = torch.randn(n, dtype=torch.float64)
    return x, q


def direct_potential(x: Tensor, q: Tensor, eps: float = 1e-12) -> Tensor:
    """
    Naive O(N^2) direct Laplace potential (for reference on moderate N).

    We include the Coulomb constant K_E so that this matches the
    physical scaling used by the FMM backend; this way, relative
    errors are purely geometric/algorithmic.
    """
    n = x.shape[0]
    # Use K_E to match physical units of FMM
    dx = x.unsqueeze(1) - x.unsqueeze(0)  # [n, n, 3]
    r = dx.norm(dim=-1).clamp_min(eps)    # [n, n]

    # exclude self-interaction: set diagonal to +inf so 1/r -> 0
    idx = torch.arange(n, device=x.device)
    r[idx, idx] = float("inf")

    kernel = K_E / r
    return (kernel * q.view(1, n)).sum(dim=1)


def rel_l2_err(phi: Tensor, phi_ref: Tensor) -> float:
    num = (phi - phi_ref).norm().item()
    den = phi_ref.norm().item()
    if den == 0.0:
        return 0.0 if num == 0.0 else math.inf
    return num / den


def make_test_bem_system(n_panels: int, dtype: torch.dtype, device: torch.device):
    """
    Create a synthetic BEM system (centroids, areas, rhs/sigma) for testing.

    This is intentionally simple and random but stable across runs
    (fixed seed) so that we can use it as a regression harness for
    BEM-FMM coupling.
    """
    torch.manual_seed(42)
    # Random centroids in [-1, 1]^3
    centroids = 2.0 * torch.rand(n_panels, 3, dtype=dtype, device=device) - 1.0
    # Random positive areas
    areas = torch.rand(n_panels, dtype=dtype, device=device) * 0.1 + 0.01
    # Random RHS (charge density sigma)
    rhs = torch.randn(n_panels, dtype=dtype, device=device)
    return (centroids, areas), rhs


# ------------------------------
# Fast Regression Test (Runs by default)
# ------------------------------


def test_fmm_stress_fast_m2l():
    """
    Fast regression test (not marked slow).

    Uses two separated clusters to FORCE valid M2L interactions.
    This ensures we aren't just testing P2P (Near-Field) on small N.

    With the corrected M2L/L2L operators at p=8, we expect very high
    accuracy here; if this test fails, it is a strong signal that
    something is broken in the far-field pipeline.
    """
    # Two clusters of 100 points each, separated by 10 units.
    # Box size ~2.0. Separation > 2.0 -> Guaranteed Multipole usage.
    n_per_cluster = 100
    shift = 10.0

    dtype = torch.float64
    device = torch.device("cpu")

    torch.manual_seed(555)
    # Cluster 1 at origin
    x1 = torch.randn(n_per_cluster, 3, dtype=dtype, device=device) * 0.5
    # Cluster 2 shifted far away
    x2 = torch.randn(n_per_cluster, 3, dtype=dtype, device=device) * 0.5
    x2[:, 0] += shift

    x = torch.cat([x1, x2])
    q_sigma = torch.randn(2 * n_per_cluster, dtype=dtype, device=device)
    areas = torch.ones_like(q_sigma)

    fmm_prod = make_laplace_fmm_backend(
        src_centroids=x,
        areas=areas,
        max_leaf_size=50,  # Small enough to split clusters, large enough to have depth
        theta=0.5,
        expansion_order=8,
    )

    phi_prod = fmm_prod.matvec(
        sigma=q_sigma,
        src_centroids=x,
        areas=areas,
        tile_size=1024,
        self_integrals=None,
    )

    phi_ref = direct_potential(x, q_sigma)
    err = rel_l2_err(phi_prod, phi_ref)

    print(f"\n[FAST-STRESS] n={len(x)}, separated clusters, err={err:.3e}")

    # If M2L (and subsequently L2L) works, this should be < 1e-5.
    # If the far-field operators are broken/flipped, this will be ~1e-1 to 1e0.
    assert err < 1e-5


# ------------------------------
# Slow FMM stress tests
# ------------------------------


@pytest.mark.slow
@pytest.mark.parametrize(
    "n_points, mode",
    [
        (2048, "uniform"),   # direct still okay
        (4096, "clusters"),  # direct borderline but fine once
        # (16384, "uniform"), # Commented out to keep test runtime reasonable for now
    ],
)
def test_fmm_stress_large_n(n_points: int, mode: str):
    """
    Stress test for the Laplace FMM backend (LaplaceFmm3D) directly:

    - larger N than accuracy tests,
    - different spatial distributions,
    - checks accuracy vs direct (for moderate N).

    This is our main "physics-level" regression test for the FMM point
    backend. It exercises the full pipeline: P2M, M2M, M2L, L2L, L2P,
    plus the interaction-list builder.
    """
    dtype = torch.float64
    device = torch.device("cpu")  # FMM implementation is CPU-only for now

    x, q_sigma = make_random_points(n_points, seed=123, mode=mode)
    x = x.to(dtype=dtype, device=device)
    q_sigma = q_sigma.to(dtype=dtype, device=device)

    # LaplaceFmm3D expects areas and sigma (surface charge density).
    # For point charges q, we can treat area=1.0 and sigma=q.
    areas = torch.ones_like(q_sigma)

    # Production config
    fmm_prod = make_laplace_fmm_backend(
        src_centroids=x,
        areas=areas,
        max_leaf_size=64,
        theta=0.5,
        expansion_order=8,
    )

    t0 = time.perf_counter()
    # Matvec computes V = Sum K(r) * sigma * area.
    # Since area=1, this is Sum K(r) * q.
    phi_prod = fmm_prod.matvec(
        sigma=q_sigma,
        src_centroids=x,
        areas=areas,
        tile_size=1024,
        self_integrals=None,
    )
    wall_fmm_prod = time.perf_counter() - t0

    # Reference: Direct evaluation
    t1 = time.perf_counter()
    # q_sigma is 'q' here since area=1.
    phi_ref = direct_potential(x, q_sigma)
    wall_ref = time.perf_counter() - t1
    ref_type = "direct"

    err = rel_l2_err(phi_prod, phi_ref)

    # Print a clear stress-test line
    print(
        f"\n[STRESS-FMM] n={n_points}, mode={mode}, "
        f"ref={ref_type}, rel_l2_err={err:.3e}, "
        f"t_prod={wall_fmm_prod:.3f}s, t_ref={wall_ref:.3f}s",
    )

    # UPDATED: With the M2L and L2L fixes and p=8, we expect high accuracy.
    # We keep the tolerance tight to catch regressions in the far-field math.
    assert err < 1e-5


# ------------------------------
# BEM + FMM stress tests
# ------------------------------


@pytest.mark.slow
@pytest.mark.parametrize(
    "n_panels, theta",
    [
        (128, 0.6),   # small system
        (512, 0.6),   # medium system
    ],
)
def test_bem_fmm_stress_scaling(n_panels: int, theta: float):
    """
    Stress test for BEM-FMM coupling via the official bem_matvec_gpu entry point.

    This checks that wiring FMM in as an "external" matvec produces the
    same result (up to a reasonably tight tolerance) as the internal
    dense/tiled BEM evaluation.
    """
    dtype = torch.float64
    device = torch.device("cpu")

    (centroids, areas), sigma = make_test_bem_system(
        n_panels=n_panels,
        dtype=dtype,
        device=device,
    )

    # 1. Create FMM backend
    fmm_backend = make_laplace_fmm_backend(
        src_centroids=centroids,
        areas=areas,
        max_leaf_size=64,
        theta=theta,
        expansion_order=8,
    )

    # 2. Run FMM matvec via the standard kernel API
    t0 = time.perf_counter()
    sol_fmm = bem_matvec_gpu(
        sigma=sigma,
        src_centroids=centroids,
        areas=areas,
        backend="external",
        matvec_impl=fmm_backend.matvec,
        tile_size=1024,
    )
    wall_fmm = time.perf_counter() - t0

    # 3. Reference: Dense Direct BEM
    t1 = time.perf_counter()
    sol_ref = bem_matvec_gpu(
        sigma=sigma,
        src_centroids=centroids,
        areas=areas,
        backend="torch_tiled",
        tile_size=1024,
    )
    wall_ref = time.perf_counter() - t1
    ref_type = "bem_direct"

    # Tolerance: BEM comparisons involve near-field quadrature differences
    # (Analytic vs FMM P2P Centroid). We keep this slightly looser than
    # the pure point test, but still tight enough to catch regressions.
    tol = 1e-2

    err = rel_l2_err(sol_fmm, sol_ref)

    print(
        f"\n[STRESS-BEM] panels={n_panels}, theta={theta}, ref={ref_type}, "
        f"rel_l2_err={err:.3e}, t_fmm={wall_fmm:.3f}s, t_ref={wall_ref:.3f}s",
    )

    assert err < tol

================================================================================
===== END FILE: code\test_stress.py =====
================================================================================

================================================================================
===== BEGIN FILE: code\visualize_mid_torus_images.py =====
================================================================================

"""
Visualize a torus image system (rings + points) with 3D rendering and r–z equipotential contours.

Usage:
    python tools/visualize_mid_torus_images.py \
        --spec specs/torus_axis_point_mid.json \
        --system runs/torus/discovered/mid_local_seed5500358_trial003/discovered_system.json \
        --out mid_torus_best.png
"""
from __future__ import annotations

import argparse
import json
from pathlib import Path
from typing import List, Tuple

import matplotlib.pyplot as plt
import matplotlib as mpl
import numpy as np
import torch

from electrodrive.orchestration.parser import CanonicalSpec
from electrodrive.images.io import load_image_system


def torus_surface(R: float, a: float, n_theta: int = 80, n_phi: int = 80) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    theta = np.linspace(0, 2 * np.pi, n_theta)
    phi = np.linspace(0, 2 * np.pi, n_phi)
    tt, pp = np.meshgrid(theta, phi, indexing="ij")
    x = (R + a * np.cos(tt)) * np.cos(pp)
    y = (R + a * np.cos(tt)) * np.sin(pp)
    z = a * np.sin(tt)
    return x, y, z


def cross_section_potential(system, R: float, a: float, nr: int = 200, nz: int = 200):
    r_min, r_max = max(1e-6, R - 1.5 * a), R + 1.5 * a
    z_min, z_max = -1.5 * a, 1.5 * a
    r = np.linspace(r_min, r_max, nr)
    z = np.linspace(z_min, z_max, nz)
    rr, zz = np.meshgrid(r, z, indexing="ij")
    pts = np.stack([rr, np.zeros_like(rr), zz], axis=-1).reshape(-1, 3)
    with torch.no_grad():
        V = system.potential(torch.tensor(pts, device=system.weights.device, dtype=system.weights.dtype))
    V = V.cpu().numpy().reshape(nr, nz)
    return r, z, V


def extract_elements(system) -> Tuple[List[dict], List[dict]]:
    rings: List[dict] = []
    points: List[dict] = []
    for elem, w in zip(system.elements, system.weights.tolist()):
        if elem.type == "poloidal_ring":
            p = elem.params
            rings.append(
                {
                    "radius": float(p["radius"]),
                    "delta_r": float(p.get("delta_r", 0.0)),
                    "order": int(p.get("order", 0)),
                    "weight": w,
                }
            )
        elif elem.type == "point":
            pos = torch.as_tensor(elem.params["position"]).view(-1).cpu().numpy()
            points.append({"pos": pos, "weight": w})
    return rings, points


def main() -> None:
    ap = argparse.ArgumentParser(description="Visualize torus image system with 3D surface and equipotentials.")
    ap.add_argument("--spec", type=str, required=True, help="Path to spec JSON.")
    ap.add_argument("--system", type=str, required=True, help="Path to discovered_system.json.")
    ap.add_argument("--out", type=str, default=None, help="Optional output image path.")
    ap.add_argument("--no-show", action="store_true", help="Skip interactive display.")
    ap.add_argument("--nr", type=int, default=200)
    ap.add_argument("--nz", type=int, default=200)
    args = ap.parse_args()

    spec = CanonicalSpec.from_json(json.load(open(args.spec)))
    system = load_image_system(Path(args.system), device="cuda" if torch.cuda.is_available() else "cpu", dtype=torch.float32)
    torus = next(c for c in spec.conductors if c.get("type") in ("torus", "toroid"))
    R = float(torus.get("major_radius", torus.get("radius", 1.0)))
    a = float(torus.get("minor_radius", 0.25 * R))

    # Build torus surface
    X, Y, Z = torus_surface(R, a, n_theta=120, n_phi=120)

    # Equipotential cross-section
    r, z, V = cross_section_potential(system, R, a, nr=args.nr, nz=args.nz)

    rings, points = extract_elements(system)

    # Styling
    cmap_surface = plt.get_cmap("plasma")
    cmap_contour = plt.get_cmap("viridis")
    norm_weights = mpl.colors.SymLogNorm(linthresh=1e-3, vmin=-max(abs(p["weight"]) for p in points + rings) if points or rings else -1, vmax=max(abs(p["weight"]) for p in points + rings) if points or rings else 1)

    fig = plt.figure(figsize=(14, 6))
    ax3d = fig.add_subplot(1, 2, 1, projection="3d")
    surf = ax3d.plot_surface(X, Y, Z, rstride=2, cstride=2, facecolors=cmap_surface((Z - Z.min()) / (Z.max() - Z.min() + 1e-9)), linewidth=0, antialiased=True, alpha=0.65, shade=True)
    ax3d.set_box_aspect([1, 1, 0.6])
    ax3d.set_xlabel("x"); ax3d.set_ylabel("y"); ax3d.set_zlabel("z")
    ax3d.set_title("Torus + Images")

    # Rings
    phi_ring = np.linspace(0, 2 * np.pi, 400)
    ring_color = "magenta"
    for i, rinfo in enumerate(rings):
        r_ring = rinfo["radius"]
        x_ring = r_ring * np.cos(phi_ring)
        y_ring = r_ring * np.sin(phi_ring)
        z_ring = np.zeros_like(phi_ring)
        ax3d.plot(x_ring, y_ring, z_ring, color=ring_color, linewidth=4.0, alpha=0.9, label="poloidal_ring" if i == 0 else None)

    # Points
    if points:
        pts = np.stack([p["pos"] for p in points], axis=0)
        w = np.array([p["weight"] for p in points])
        point_color = "tab:orange"
        ax3d.scatter(
            pts[:, 0],
            pts[:, 1],
            pts[:, 2],
            s=(120 + 240 * np.abs(w) / (np.abs(w).max() + 1e-9)),
            c=point_color,
            depthshade=True,
            edgecolors="k",
            linewidths=1.0,
            label="points",
        )

    # Equipotential contour plot
    ax2 = fig.add_subplot(1, 2, 2)
    cf = ax2.contourf(r, z, V.T, levels=40, cmap=cmap_contour)
    cs = ax2.contour(r, z, V.T, levels=10, colors="k", linewidths=0.6, alpha=0.5)
    torus_r = R + a * np.cos(np.linspace(0, 2 * np.pi, 400))
    torus_z = a * np.sin(np.linspace(0, 2 * np.pi, 400))
    ax2.plot(torus_r, torus_z, color="white", linewidth=1.5, alpha=0.9)
    # Overlay rings and points in r-z
    for idx, rinfo in enumerate(rings):
        ax2.axvline(rinfo["radius"], color=ring_color, linestyle="--", linewidth=1.5, alpha=0.9, label="ring" if idx == 0 else None)
    if points:
        rho_pts = np.linalg.norm(pts[:, :2], axis=1)
        ax2.scatter(rho_pts, pts[:, 2], color=point_color, edgecolors="k", s=50, zorder=5, label="points (r,z)")
    ax2.set_xlabel("r (x)"); ax2.set_ylabel("z"); ax2.set_title("Equipotential contours (y=0)")
    fig.colorbar(cf, ax=ax2, shrink=0.8, label="Potential (arb)")

    handles, labels = [], []
    h3, l3 = ax3d.get_legend_handles_labels()
    h2, l2 = ax2.get_legend_handles_labels()
    handles.extend(h3); handles.extend(h2)
    labels.extend(l3); labels.extend(l2)
    if handles:
        ax3d.legend(loc="upper right")
        ax2.legend(loc="upper right")
    fig.suptitle("Mid-torus image system visualization", fontsize=14)
    fig.tight_layout()

    if args.out:
        plt.savefig(args.out, dpi=300, bbox_inches="tight")
    if not args.no_show:
        plt.show()


if __name__ == "__main__":
    main()

================================================================================
===== END FILE: code\visualize_mid_torus_images.py =====
================================================================================

================================================================================
===== BEGIN FILE: flatten_repo.py =====
================================================================================

#!/usr/bin/env python
"""
flatten_repo.py

Walks the repository and writes a single text file containing:

  - All developer-relevant file paths (relative to repo root)
  - The full contents of each included file

Each file is delimited in the output with BEGIN/END markers.

Usage:
    python flatten_repo.py
    python flatten_repo.py --root PATH/TO/REPO --output repo_flattened.txt
"""

import argparse
import os
from pathlib import Path
from typing import Iterable, List

# Directories we typically don't care about
EXCLUDED_DIR_NAMES = {
    ".git",
    ".hg",
    ".svn",
    ".mypy_cache",
    ".pytest_cache",
    ".ruff_cache",
    ".idea",
    ".vscode",
    ".vs",
    "__pycache__",
    ".ipynb_checkpoints",
    ".DS_Store",
    ".cache",
    "build",
    "dist",
    "site-packages",
    ".venv",
    "venv",
    "env",
    ".env",
    ".eggs",
    "node_modules",  # keep if you really want node_modules contents
}

# File extensions that are usually NOT edited by devs
EXCLUDED_FILE_EXTS = {
    ".pyc",
    ".pyo",
    ".pyd",
    ".so",
    ".dll",
    ".dylib",
    ".o",
    ".obj",
    ".a",
    ".lib",
    ".npy",
    ".pkl",
    ".h5",
    ".hdf5",
    ".pt",
    ".ckpt",
    ".log",
    ".tmp",
    ".xlsx",
    ".csv",
    ".npz",
}

# File extensions that developers usually *do* work on
INCLUDED_FILE_EXTS = {
    # Python / CUDA / C / C++
    ".py",
    ".pyi",
    ".pyx",
    ".pxd",
    ".c",
    ".cpp",
    ".cc",
    ".cxx",
    ".h",
    ".hpp",
    ".hh",
    ".hxx",
    ".cu",
    ".cuh",
    # Build / config
    ".cmake",
    ".cfg",
    ".ini",
    ".toml",
    ".json",
    ".yml",
    ".yaml",
    ".xml",
    ".conf",
    # Shell / scripting
    ".sh",
    ".bash",
    ".ps1",
    ".bat",
    ".cmd",
    # Docs
    ".md",
    ".rst",
    ".txt",
    ".tex",
    # Other "texty" project files
    ".csv",
    ".tsv",
    ".tsx",
    ".ts",
    ".js",
}

# File *names* that are important even if they have no extension
IMPORTANT_FILENAMES = {
    "Makefile",
    "CMakeLists.txt",
    "Dockerfile",
    "LICENSE",
    "LICENSE.txt",
    "README",
    "README.md",
    "README.rst",
    ".gitignore",
    ".gitattributes",
    "pyproject.toml",
    "requirements.txt",
    "environment.yml",
    "Pipfile",
    "Pipfile.lock",
    "setup.py",
    "setup.cfg",
    "manage.py",
}


def should_skip_dir(dir_name: str) -> bool:
    """Return True if this directory name should be skipped entirely."""
    return dir_name in EXCLUDED_DIR_NAMES


def is_developer_file(path: Path) -> bool:
    """
    Decide whether a file is something developers are likely to work on.

    Heuristic: include if
      - extension in INCLUDED_FILE_EXTS, OR
      - basename in IMPORTANT_FILENAMES
    and NOT in EXCLUDED_FILE_EXTS.
    """
    if path.name in IMPORTANT_FILENAMES:
        return True

    ext = path.suffix.lower()

    if ext in EXCLUDED_FILE_EXTS:
        return False

    if ext in INCLUDED_FILE_EXTS:
        return True

    # By default, ignore unknown binary-ish extensions.
    return False


def collect_files(root: Path) -> List[Path]:
    """Walk the tree and collect all developer-relevant files."""
    files: List[Path] = []

    for dirpath, dirnames, filenames in os.walk(root):
        # Mutate dirnames in-place to skip excluded dirs
        dirnames[:] = [d for d in dirnames if not should_skip_dir(d)]

        dir_path = Path(dirpath)
        for fname in filenames:
            fpath = dir_path / fname
            if is_developer_file(fpath):
                files.append(fpath.relative_to(root))

    # Sort for deterministic output
    files.sort()
    return files


def write_files_with_contents(root: Path, paths: Iterable[Path], output_path: Path) -> None:
    """
    Write all files and their contents to a single text file.

    Each file is wrapped as:

        ===== BEGIN FILE: relative/path =====
        <contents>
        ===== END FILE: relative/path =====
    """
    with output_path.open("w", encoding="utf-8") as out:
        out.write("# Flattened repository file listing\n")
        out.write(f"# Root: {root}\n\n")

        for rel_path in paths:
            abs_path = root / rel_path
            out.write("=" * 80 + "\n")
            out.write(f"===== BEGIN FILE: {rel_path} =====\n")
            out.write("=" * 80 + "\n\n")

            try:
                with abs_path.open("r", encoding="utf-8", errors="replace") as f:
                    for line in f:
                        out.write(line)
            except Exception as e:
                # If we can't read the file, note the error and continue
                out.write(f"\n<<< ERROR READING FILE: {e} >>>\n")

            # Ensure there's a trailing newline, then write the end marker
            out.write("\n")
            out.write("=" * 80 + "\n")
            out.write(f"===== END FILE: {rel_path} =====\n")
            out.write("=" * 80 + "\n\n")


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description=(
            "Generate a .txt file containing developer-relevant files and their contents."
        )
    )
    parser.add_argument(
        "--root",
        type=str,
        default=".",
        help="Root of the repository (default: current directory).",
    )
    parser.add_argument(
        "--output",
        type=str,
        default="flattened_repo_with_contents.txt",
        help="Output text file (default: flattened_repo_with_contents.txt).",
    )
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    root = Path(args.root).resolve()
    output_path = Path(args.output).resolve()

    print(f"[flatten_repo] Scanning root: {root}")
    files = collect_files(root)
    print(f"[flatten_repo] Found {len(files)} developer-relevant files.")
    print(f"[flatten_repo] Writing contents to: {output_path}")

    write_files_with_contents(root, files, output_path)

    print(f"[flatten_repo] Done.")


if __name__ == "__main__":
    main()

================================================================================
===== END FILE: flatten_repo.py =====
================================================================================

================================================================================
===== BEGIN FILE: metrics\mid_axis_weight_svd.json =====
================================================================================

{
  "singular_values": [
    0.04324363767030891,
    0.017640318224031403,
    0.002552605340382901,
    0.0008470082620956454,
    0.00025397475335770995,
    0.00010701658112618546
  ],
  "singular_values_rel": [
    1.0,
    0.407928638162262,
    0.059028460090338804,
    0.019586887406495904,
    0.005873112601997613,
    0.00247473586616565
  ],
  "rank_thresholds": {
    "0.1": 2,
    "0.01": 4,
    "0.001": 6
  },
  "z_values": [
    0.4,
    0.45,
    0.5,
    0.55,
    0.6,
    0.65,
    0.7,
    0.75,
    0.8,
    0.85,
    0.9
  ]
}
================================================================================
===== END FILE: metrics\mid_axis_weight_svd.json =====
================================================================================

================================================================================
===== BEGIN FILE: metrics\mid_axis_weights.json =====
================================================================================

{
  "meta": {
    "geometry_path": "runs\\torus\\discovered\\mid_bem_highres_trial02\\discovered_system.json",
    "rings": [
      {
        "radius": 1.057252049446106,
        "delta_r": 0.08330611884593964,
        "order": 2
      },
      {
        "radius": 0.9534857869148254,
        "delta_r": 0.1868913322687149,
        "order": 2
      }
    ],
    "points": [
      {
        "rho": 0.8488895297050476,
        "phi": 1.6614855394135921,
        "z": 0.011433246545493603
      },
      {
        "rho": 0.9068986177444458,
        "phi": 1.7102155573228859,
        "z": 0.00732202036306262
      },
      {
        "rho": 0.8444581627845764,
        "phi": 3.0588329694610663,
        "z": -0.04171684384346008
      },
      {
        "rho": 0.8496426343917847,
        "phi": 3.130141493709352,
        "z": 0.08968504518270493
      }
    ],
    "basis_order": [
      "ring1",
      "ring2",
      "pt1",
      "pt2",
      "pt3",
      "pt4"
    ],
    "reg_l1": 0.0004,
    "point_reg_mult": 4.0,
    "boundary_weight": 0.9,
    "n_colloc": 4096,
    "ratio_boundary": 0.8
  },
  "records": [
    {
      "z": 0.4,
      "weights": [
        0.001306801801547408,
        0.008410651236772537,
        0.009251425974071026,
        -0.006085553672164679,
        -0.005418639630079269,
        0.009170474484562874
      ],
      "metrics": {
        "boundary_mae": 47727612.0,
        "offaxis_mae": 562163648.0,
        "offaxis_rel": 1.1908169984817505,
        "offaxis_belt_rel": 0.5082106590270996,
        "axis_mae": 15021761256.356148,
        "axis_rel": 0.9613116398846414,
        "n_images": 6,
        "sparsity90": 5,
        "type_counts": {
          "poloidal_ring": 2,
          "point": 4
        }
      },
      "n_images": 6,
      "type_counts": {
        "poloidal_ring": 2,
        "point": 4
      },
      "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.40\\discovered_system.json",
      "reg_l1": 0.0004,
      "boundary_weight": 0.9,
      "n_colloc": 4096,
      "ratio_boundary": 0.8
    },
    {
      "z": 0.45,
      "weights": [
        0.0011119142873212695,
        0.006654791999608278,
        0.010961705818772316,
        -0.007596162147819996,
        -0.006559211295098066,
        0.010062525048851967
      ],
      "metrics": {
        "boundary_mae": 45509864.0,
        "offaxis_mae": 568887680.0,
        "offaxis_rel": 1.1313869953155518,
        "offaxis_belt_rel": 0.64667147397995,
        "axis_mae": 15536323380.724016,
        "axis_rel": 0.960847352482139,
        "n_images": 6,
        "sparsity90": 5,
        "type_counts": {
          "poloidal_ring": 2,
          "point": 4
        }
      },
      "n_images": 6,
      "type_counts": {
        "poloidal_ring": 2,
        "point": 4
      },
      "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.45\\discovered_system.json",
      "reg_l1": 0.0004,
      "boundary_weight": 0.9,
      "n_colloc": 4096,
      "ratio_boundary": 0.8
    },
    {
      "z": 0.5,
      "weights": [
        0.000922389910556376,
        0.004915258847177029,
        0.008057046681642532,
        -0.004811642225831747,
        -0.007977703586220741,
        0.011593419127166271
      ],
      "metrics": {
        "boundary_mae": 45724784.0,
        "offaxis_mae": 611222912.0,
        "offaxis_rel": 1.7247411012649536,
        "offaxis_belt_rel": 0.5557665228843689,
        "axis_mae": 17289736231.34681,
        "axis_rel": 0.9608546174635744,
        "n_images": 6,
        "sparsity90": 5,
        "type_counts": {
          "poloidal_ring": 2,
          "point": 4
        }
      },
      "n_images": 6,
      "type_counts": {
        "poloidal_ring": 2,
        "point": 4
      },
      "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.50\\discovered_system.json",
      "reg_l1": 0.0004,
      "boundary_weight": 0.9,
      "n_colloc": 4096,
      "ratio_boundary": 0.8
    },
    {
      "z": 0.55,
      "weights": [
        0.000671813846565783,
        0.0033502080477774143,
        0.007242069113999605,
        -0.0036347282584756613,
        -0.007563007529824972,
        0.011026536114513874
      ],
      "metrics": {
        "boundary_mae": 46303136.0,
        "offaxis_mae": 638771712.0,
        "offaxis_rel": 1.3142085075378418,
        "offaxis_belt_rel": 0.5065845251083374,
        "axis_mae": 23181591632.625084,
        "axis_rel": 0.9589655777489291,
        "n_images": 6,
        "sparsity90": 5,
        "type_counts": {
          "poloidal_ring": 2,
          "point": 4
        }
      },
      "n_images": 6,
      "type_counts": {
        "poloidal_ring": 2,
        "point": 4
      },
      "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.55\\discovered_system.json",
      "reg_l1": 0.0004,
      "boundary_weight": 0.9,
      "n_colloc": 4096,
      "ratio_boundary": 0.8
    },
    {
      "z": 0.6,
      "weights": [
        0.0004059612692799419,
        0.0015079121803864837,
        0.005641034338623285,
        -0.001967949327081442,
        -0.006050618831068277,
        0.009091817773878574
      ],
      "metrics": {
        "boundary_mae": 44697144.0,
        "offaxis_mae": 744034816.0,
        "offaxis_rel": 1.2028447389602661,
        "offaxis_belt_rel": 0.6431548595428467,
        "axis_mae": 368141417659253.1,
        "axis_rel": 0.960342782834265,
        "n_images": 6,
        "sparsity90": 4,
        "type_counts": {
          "poloidal_ring": 2,
          "point": 4
        }
      },
      "n_images": 6,
      "type_counts": {
        "poloidal_ring": 2,
        "point": 4
      },
      "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.60\\discovered_system.json",
      "reg_l1": 0.0004,
      "boundary_weight": 0.9,
      "n_colloc": 4096,
      "ratio_boundary": 0.8
    },
    {
      "z": 0.65,
      "weights": [
        0.00028636990464292467,
        0.00050847337115556,
        0.0036217388696968555,
        -0.00016929712728597224,
        -0.007035532966256142,
        0.010138518176972866
      ],
      "metrics": {
        "boundary_mae": 43631292.0,
        "offaxis_mae": 907807808.0,
        "offaxis_rel": 2.348407506942749,
        "offaxis_belt_rel": 0.34855449199676514,
        "axis_mae": 23397137511.23248,
        "axis_rel": 0.9615213130225002,
        "n_images": 6,
        "sparsity90": 3,
        "type_counts": {
          "poloidal_ring": 2,
          "point": 4
        }
      },
      "n_images": 6,
      "type_counts": {
        "poloidal_ring": 2,
        "point": 4
      },
      "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.65\\discovered_system.json",
      "reg_l1": 0.0004,
      "boundary_weight": 0.9,
      "n_colloc": 4096,
      "ratio_boundary": 0.8
    },
    {
      "z": 0.7,
      "weights": [
        0.000267999799689278,
        0.0011615999974310398,
        0.004377189092338085,
        -0.0020764386281371117,
        -0.005346748046576977,
        0.007603487931191921
      ],
      "metrics": {
        "boundary_mae": 29348624.0,
        "offaxis_mae": 750699072.0,
        "offaxis_rel": 1.1415890455245972,
        "offaxis_belt_rel": 0.485932320356369,
        "axis_mae": 17720404538.916862,
        "axis_rel": 0.9727443422182797,
        "n_images": 6,
        "sparsity90": 4,
        "type_counts": {
          "poloidal_ring": 2,
          "point": 4
        }
      },
      "n_images": 6,
      "type_counts": {
        "poloidal_ring": 2,
        "point": 4
      },
      "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.70\\discovered_system.json",
      "reg_l1": 0.0004,
      "boundary_weight": 0.9,
      "n_colloc": 4096,
      "ratio_boundary": 0.8
    },
    {
      "z": 0.75,
      "weights": [
        2.8866619686596096e-05,
        -0.0006606316310353577,
        0.0029390896670520306,
        -0.00039642848423682153,
        -0.004347058013081551,
        0.006388729903846979
      ],
      "metrics": {
        "boundary_mae": 30035374.0,
        "offaxis_mae": 936936384.0,
        "offaxis_rel": 1.132386326789856,
        "offaxis_belt_rel": 0.7875714898109436,
        "axis_mae": 16173650227.961239,
        "axis_rel": 0.9722249747515903,
        "n_images": 6,
        "sparsity90": 3,
        "type_counts": {
          "poloidal_ring": 2,
          "point": 4
        }
      },
      "n_images": 6,
      "type_counts": {
        "poloidal_ring": 2,
        "point": 4
      },
      "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.75\\discovered_system.json",
      "reg_l1": 0.0004,
      "boundary_weight": 0.9,
      "n_colloc": 4096,
      "ratio_boundary": 0.8
    },
    {
      "z": 0.8,
      "weights": [
        -0.00020965366275049746,
        -0.0022326004691421986,
        0.002137273084372282,
        0.0014499076642096043,
        -0.007378298789262772,
        0.010186675004661083
      ],
      "metrics": {
        "boundary_mae": 40936052.0,
        "offaxis_mae": 944651904.0,
        "offaxis_rel": 1.0493475198745728,
        "offaxis_belt_rel": 0.9328900575637817,
        "axis_mae": 15854389457.277124,
        "axis_rel": 0.9621278201236245,
        "n_images": 6,
        "sparsity90": 4,
        "type_counts": {
          "poloidal_ring": 2,
          "point": 4
        }
      },
      "n_images": 6,
      "type_counts": {
        "poloidal_ring": 2,
        "point": 4
      },
      "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.80\\discovered_system.json",
      "reg_l1": 0.0004,
      "boundary_weight": 0.9,
      "n_colloc": 4096,
      "ratio_boundary": 0.8
    },
    {
      "z": 0.85,
      "weights": [
        -8.817981870379299e-05,
        -0.0015597918536514044,
        0.0019021735060960054,
        0.0004614948993548751,
        -0.004742044489830732,
        0.006917193997651339
      ],
      "metrics": {
        "boundary_mae": 27924488.0,
        "offaxis_mae": 950370048.0,
        "offaxis_rel": 1.062003254890442,
        "offaxis_belt_rel": 0.8133978843688965,
        "axis_mae": 16375009760.236095,
        "axis_rel": 0.9725114056802994,
        "n_images": 6,
        "sparsity90": 4,
        "type_counts": {
          "poloidal_ring": 2,
          "point": 4
        }
      },
      "n_images": 6,
      "type_counts": {
        "poloidal_ring": 2,
        "point": 4
      },
      "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.85\\discovered_system.json",
      "reg_l1": 0.0004,
      "boundary_weight": 0.9,
      "n_colloc": 4096,
      "ratio_boundary": 0.8
    },
    {
      "z": 0.9,
      "weights": [
        -0.0004557660431601107,
        -0.0040223621763288975,
        -0.0007280927966348827,
        0.004624643363058567,
        -0.0073957983404397964,
        0.010106083005666733
      ],
      "metrics": {
        "boundary_mae": 39691956.0,
        "offaxis_mae": 1048957568.0,
        "offaxis_rel": 1.0659478902816772,
        "offaxis_belt_rel": 1.1604185104370117,
        "axis_mae": 18117061761.911644,
        "axis_rel": 0.9608346886548795,
        "n_images": 6,
        "sparsity90": 4,
        "type_counts": {
          "poloidal_ring": 2,
          "point": 4
        }
      },
      "n_images": 6,
      "type_counts": {
        "poloidal_ring": 2,
        "point": 4
      },
      "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.90\\discovered_system.json",
      "reg_l1": 0.0004,
      "boundary_weight": 0.9,
      "n_colloc": 4096,
      "ratio_boundary": 0.8
    }
  ]
}
================================================================================
===== END FILE: metrics\mid_axis_weights.json =====
================================================================================

================================================================================
===== BEGIN FILE: metrics\mid_best_candidate_summary.json =====
================================================================================

{
  "best_candidate": "mid_bem_highres_trial02",
  "discovered_system": "runs/torus/discovered/mid_bem_highres_trial02/discovered_system.json",
  "bem_metrics": {
    "max_rel": 22487.10945862872,
    "mean_rel": 5.393999562212118,
    "inner_mean_abs": 38889107.28195952,
    "inner_mean_rel": 7.353864916892917
  },
  "n_images": 6,
  "composition": {
    "poloidal_ring": 2,
    "point": 4
  },
  "compare": {
    "baseline": {
      "max_rel": 353117.054973703,
      "mean_rel": 54.46957169308013,
      "inner_mean_abs": 168407590.2089507,
      "inner_mean_rel": 36.61120880936621
    },
    "seed": {
      "max_rel": 242678.1921256839,
      "mean_rel": 31.40953141867919,
      "inner_mean_abs": 124118898.438664,
      "inner_mean_rel": 26.93287732702711
    },
    "trial003": {
      "max_rel": 155023.0265974587,
      "mean_rel": 19.32201130614231,
      "inner_mean_abs": 68415834.13873671,
      "inner_mean_rel": 18.180891604735304
    },
    "bem_highres_trial02": {
      "max_rel": 22487.10945862872,
      "mean_rel": 5.393999562212118,
      "inner_mean_abs": 38889107.28195952,
      "inner_mean_rel": 7.353864916892917
    }
  },
  "notes": "FMM oracle unavailable; ranking BEM-only. High-res BEM cfg: fp64, max_refine_passes=5, near_quad=True."
}
================================================================================
===== END FILE: metrics\mid_best_candidate_summary.json =====
================================================================================

================================================================================
===== BEGIN FILE: metrics\mid_candidate_metrics_combined.json =====
================================================================================

{
  "baseline": {
    "max_rel": 353117.054973703,
    "mean_rel": 54.46957169308013,
    "inner_mean_abs": 168407590.2089507,
    "inner_mean_rel": 36.61120880936621
  },
  "seed": {
    "max_rel": 242678.1921256839,
    "mean_rel": 31.40953141867919,
    "inner_mean_abs": 124118898.438664,
    "inner_mean_rel": 26.93287732702711
  },
  "trial003": {
    "max_rel": 155023.0265974587,
    "mean_rel": 19.32201130614231,
    "inner_mean_abs": 68415834.13873671,
    "inner_mean_rel": 18.180891604735304
  },
  "bem_highres_trial02": {
    "max_rel": 22487.10945862872,
    "mean_rel": 5.393999562212118,
    "inner_mean_abs": 38889107.28195952,
    "inner_mean_rel": 7.353864916892917
  }
}
================================================================================
===== END FILE: metrics\mid_candidate_metrics_combined.json =====
================================================================================

================================================================================
===== BEGIN FILE: metrics\mid_fmm_stats.json =====
================================================================================

{
  "baseline": {
    "error": "FMM oracle unavailable",
    "ok": false
  },
  "seed": {
    "error": "FMM oracle unavailable",
    "ok": false
  },
  "trial003": {
    "error": "FMM oracle unavailable",
    "ok": false
  },
  "best_bem": {
    "error": "FMM oracle unavailable",
    "ok": false
  }
}
================================================================================
===== END FILE: metrics\mid_fmm_stats.json =====
================================================================================

================================================================================
===== BEGIN FILE: metrics\stage4_metrics_inner_rim.json =====
================================================================================

[
  {
    "spec": "torus_thin",
    "run": "torus_thin_point_toroidal_eigen_mode_boundary_n12_reg0.001_bw0.8_tsFalse_inner",
    "basis_types": [
      "point",
      "toroidal_eigen_mode_boundary"
    ],
    "n_max": 12,
    "reg_l1": 0.001,
    "boundary_weight": 0.8,
    "restarts": 1,
    "two_stage": false,
    "per_type_reg": {
      "point": 0.002,
      "toroidal_eigen_mode_boundary": 0.0008
    },
    "metrics": {
      "boundary_mae": 151594624.0,
      "offaxis_mae": 1395220352.0,
      "offaxis_rel": 7.202818393707275,
      "offaxis_belt_rel": 2.6507351398468018,
      "axis_mae": 368142453003836.0,
      "axis_rel": 0.9413563038066508,
      "n_images": 12,
      "sparsity90": 3,
      "type_counts": {
        "toroidal_eigen_mode": 4,
        "point": 8
      }
    },
    "type_counts": {
      "toroidal_eigen_mode": 4,
      "point": 8
    },
    "elapsed_s": 34.00102663040161
  },
  {
    "spec": "torus_thin",
    "run": "torus_thin_point_poloidal_ring_toroidal_eigen_mode_boundary_ring_ladder_inner_n16_reg0.001_bw0.8_tsTrue_inner",
    "basis_types": [
      "point",
      "poloidal_ring",
      "toroidal_eigen_mode_boundary",
      "ring_ladder_inner"
    ],
    "n_max": 16,
    "reg_l1": 0.001,
    "boundary_weight": 0.8,
    "restarts": 1,
    "two_stage": true,
    "per_type_reg": {
      "point": 0.003,
      "poloidal_ring": 0.001,
      "ring_ladder_inner": 0.001,
      "toroidal_eigen_mode_boundary": 0.0008
    },
    "metrics": {
      "boundary_mae": 164223344.0,
      "offaxis_mae": 2582687744.0,
      "offaxis_rel": 0.9727555513381958,
      "offaxis_belt_rel": 4.224452972412109,
      "axis_mae": 368142446435147.75,
      "axis_rel": 0.9389553409891817,
      "n_images": 16,
      "sparsity90": 4,
      "type_counts": {
        "poloidal_ring": 3,
        "ring_ladder_inner": 1,
        "point": 12
      }
    },
    "type_counts": {
      "poloidal_ring": 3,
      "ring_ladder_inner": 1,
      "point": 12
    },
    "elapsed_s": 16.93670415878296
  },
  {
    "spec": "torus_thin",
    "run": "torus_thin_point_toroidal_eigen_mode_boundary_inner_rim_arc_n12_reg0.0008_bw0.8_tsFalse_inner",
    "basis_types": [
      "point",
      "toroidal_eigen_mode_boundary",
      "inner_rim_arc"
    ],
    "n_max": 12,
    "reg_l1": 0.0008,
    "boundary_weight": 0.8,
    "restarts": 1,
    "two_stage": false,
    "per_type_reg": {
      "point": 0.002,
      "toroidal_eigen_mode_boundary": 0.0008,
      "inner_rim_arc": 0.0008
    },
    "metrics": {
      "boundary_mae": 178441136.0,
      "offaxis_mae": 1636917760.0,
      "offaxis_rel": 0.9519936442375183,
      "offaxis_belt_rel": 6.673402309417725,
      "axis_mae": 368142448298897.9,
      "axis_rel": 0.9390723766200763,
      "n_images": 12,
      "sparsity90": 4,
      "type_counts": {
        "toroidal_eigen_mode": 4,
        "inner_rim_arc": 2,
        "point": 6
      }
    },
    "type_counts": {
      "toroidal_eigen_mode": 4,
      "inner_rim_arc": 2,
      "point": 6
    },
    "elapsed_s": 18.817384481430054
  },
  {
    "spec": "torus_thin",
    "run": "torus_thin_point_toroidal_eigen_mode_boundary_inner_rim_ribbon_n12_reg0.0008_bw0.8_tsFalse_inner",
    "basis_types": [
      "point",
      "toroidal_eigen_mode_boundary",
      "inner_rim_ribbon"
    ],
    "n_max": 12,
    "reg_l1": 0.0008,
    "boundary_weight": 0.8,
    "restarts": 1,
    "two_stage": false,
    "per_type_reg": {
      "point": 0.002,
      "toroidal_eigen_mode_boundary": 0.0008,
      "inner_rim_ribbon": 0.0008
    },
    "metrics": {
      "boundary_mae": 153284976.0,
      "offaxis_mae": 1600720128.0,
      "offaxis_rel": 0.905097484588623,
      "offaxis_belt_rel": 2.2375526428222656,
      "axis_mae": 368142453040200.25,
      "axis_rel": 0.9413111284411365,
      "n_images": 12,
      "sparsity90": 3,
      "type_counts": {
        "toroidal_eigen_mode": 4,
        "inner_rim_ribbon": 1,
        "point": 7
      }
    },
    "type_counts": {
      "toroidal_eigen_mode": 4,
      "inner_rim_ribbon": 1,
      "point": 7
    },
    "elapsed_s": 17.836642742156982
  },
  {
    "spec": "torus_thin",
    "run": "torus_thin_point_toroidal_eigen_mode_boundary_inner_rim_arc_inner_rim_ribbon_inner_patch_ring_n16_reg0.0008_bw0.8_tsTrue_inner",
    "basis_types": [
      "point",
      "toroidal_eigen_mode_boundary",
      "inner_rim_arc",
      "inner_rim_ribbon",
      "inner_patch_ring"
    ],
    "n_max": 16,
    "reg_l1": 0.0008,
    "boundary_weight": 0.8,
    "restarts": 1,
    "two_stage": true,
    "per_type_reg": {
      "point": 0.003,
      "toroidal_eigen_mode_boundary": 0.0008,
      "inner_rim_arc": 0.0008,
      "inner_rim_ribbon": 0.0008,
      "inner_patch_ring": 0.001
    },
    "metrics": {
      "boundary_mae": 164226400.0,
      "offaxis_mae": 1429657344.0,
      "offaxis_rel": 0.9043564796447754,
      "offaxis_belt_rel": 10.524933815002441,
      "axis_mae": 368142443705228.5,
      "axis_rel": 0.9381082127940754,
      "n_images": 16,
      "sparsity90": 3,
      "type_counts": {
        "toroidal_eigen_mode": 4,
        "inner_rim_arc": 2,
        "inner_rim_ribbon": 1,
        "inner_patch_ring": 1,
        "point": 8
      }
    },
    "type_counts": {
      "toroidal_eigen_mode": 4,
      "inner_rim_arc": 2,
      "inner_rim_ribbon": 1,
      "inner_patch_ring": 1,
      "point": 8
    },
    "elapsed_s": 19.008294582366943
  },
  {
    "spec": "torus_thin",
    "run": "torus_thin_point_inner_rim_arc_inner_rim_ribbon_inner_patch_ring_n12_reg0.001_bw0.7_tsFalse_inner",
    "basis_types": [
      "point",
      "inner_rim_arc",
      "inner_rim_ribbon",
      "inner_patch_ring"
    ],
    "n_max": 12,
    "reg_l1": 0.001,
    "boundary_weight": 0.7,
    "restarts": 1,
    "two_stage": false,
    "per_type_reg": {
      "point": 0.004,
      "inner_rim_arc": 0.001,
      "inner_rim_ribbon": 0.001,
      "inner_patch_ring": 0.001
    },
    "metrics": {
      "boundary_mae": 267195696.0,
      "offaxis_mae": 1356889216.0,
      "offaxis_rel": 0.9694992303848267,
      "offaxis_belt_rel": 6.02504825592041,
      "axis_mae": 368142396585646.7,
      "axis_rel": 0.9182417372315417,
      "n_images": 12,
      "sparsity90": 6,
      "type_counts": {
        "inner_rim_arc": 2,
        "inner_rim_ribbon": 1,
        "inner_patch_ring": 1,
        "point": 8
      }
    },
    "type_counts": {
      "inner_rim_arc": 2,
      "inner_rim_ribbon": 1,
      "inner_patch_ring": 1,
      "point": 8
    },
    "elapsed_s": 18.577560424804688
  },
  {
    "spec": "torus_mid",
    "run": "torus_mid_point_toroidal_eigen_mode_boundary_n12_reg0.001_bw0.8_tsFalse_inner",
    "basis_types": [
      "point",
      "toroidal_eigen_mode_boundary"
    ],
    "n_max": 12,
    "reg_l1": 0.001,
    "boundary_weight": 0.8,
    "restarts": 1,
    "two_stage": false,
    "per_type_reg": {
      "point": 0.002,
      "toroidal_eigen_mode_boundary": 0.0008
    },
    "metrics": {
      "boundary_mae": 87937272.0,
      "offaxis_mae": 833725376.0,
      "offaxis_rel": 1.4708269834518433,
      "offaxis_belt_rel": 0.7030966877937317,
      "axis_mae": 17672505893.04577,
      "axis_rel": 0.9172025771543042,
      "n_images": 12,
      "sparsity90": 2,
      "type_counts": {
        "toroidal_eigen_mode": 4,
        "point": 8
      }
    },
    "type_counts": {
      "toroidal_eigen_mode": 4,
      "point": 8
    },
    "elapsed_s": 63.14900517463684
  },
  {
    "spec": "torus_mid",
    "run": "torus_mid_point_poloidal_ring_toroidal_eigen_mode_boundary_ring_ladder_inner_n16_reg0.001_bw0.8_tsTrue_inner",
    "basis_types": [
      "point",
      "poloidal_ring",
      "toroidal_eigen_mode_boundary",
      "ring_ladder_inner"
    ],
    "n_max": 16,
    "reg_l1": 0.001,
    "boundary_weight": 0.8,
    "restarts": 1,
    "two_stage": true,
    "per_type_reg": {
      "point": 0.003,
      "poloidal_ring": 0.001,
      "ring_ladder_inner": 0.001,
      "toroidal_eigen_mode_boundary": 0.0008
    },
    "metrics": {
      "boundary_mae": 86925624.0,
      "offaxis_mae": 814463104.0,
      "offaxis_rel": 3.232579469680786,
      "offaxis_belt_rel": 1.0319949388504028,
      "axis_mae": 17674302332.95202,
      "axis_rel": 0.9203910280260589,
      "n_images": 16,
      "sparsity90": 7,
      "type_counts": {
        "poloidal_ring": 3,
        "point": 12,
        "ring_ladder_inner": 1
      }
    },
    "type_counts": {
      "poloidal_ring": 3,
      "point": 12,
      "ring_ladder_inner": 1
    },
    "elapsed_s": 29.32212543487549
  },
  {
    "spec": "torus_mid",
    "run": "torus_mid_point_toroidal_eigen_mode_boundary_inner_rim_arc_n12_reg0.0008_bw0.8_tsFalse_inner",
    "basis_types": [
      "point",
      "toroidal_eigen_mode_boundary",
      "inner_rim_arc"
    ],
    "n_max": 12,
    "reg_l1": 0.0008,
    "boundary_weight": 0.8,
    "restarts": 1,
    "two_stage": false,
    "per_type_reg": {
      "point": 0.002,
      "toroidal_eigen_mode_boundary": 0.0008,
      "inner_rim_arc": 0.0008
    },
    "metrics": {
      "boundary_mae": 86081080.0,
      "offaxis_mae": 755091264.0,
      "offaxis_rel": 1.1784679889678955,
      "offaxis_belt_rel": 1.2245665788650513,
      "axis_mae": 17674244935.936394,
      "axis_rel": 0.9166972141728355,
      "n_images": 12,
      "sparsity90": 2,
      "type_counts": {
        "toroidal_eigen_mode": 4,
        "inner_rim_arc": 2,
        "point": 6
      }
    },
    "type_counts": {
      "toroidal_eigen_mode": 4,
      "inner_rim_arc": 2,
      "point": 6
    },
    "elapsed_s": 30.37660241127014
  },
  {
    "spec": "torus_mid",
    "run": "torus_mid_point_toroidal_eigen_mode_boundary_inner_rim_ribbon_n12_reg0.0008_bw0.8_tsFalse_inner",
    "basis_types": [
      "point",
      "toroidal_eigen_mode_boundary",
      "inner_rim_ribbon"
    ],
    "n_max": 12,
    "reg_l1": 0.0008,
    "boundary_weight": 0.8,
    "restarts": 1,
    "two_stage": false,
    "per_type_reg": {
      "point": 0.002,
      "toroidal_eigen_mode_boundary": 0.0008,
      "inner_rim_ribbon": 0.0008
    },
    "metrics": {
      "boundary_mae": 85787504.0,
      "offaxis_mae": 781618368.0,
      "offaxis_rel": 1.260993480682373,
      "offaxis_belt_rel": 1.2855111360549927,
      "axis_mae": 17673499311.20202,
      "axis_rel": 0.9178154850860029,
      "n_images": 12,
      "sparsity90": 2,
      "type_counts": {
        "toroidal_eigen_mode": 4,
        "inner_rim_ribbon": 1,
        "point": 7
      }
    },
    "type_counts": {
      "toroidal_eigen_mode": 4,
      "inner_rim_ribbon": 1,
      "point": 7
    },
    "elapsed_s": 32.5958468914032
  },
  {
    "spec": "torus_mid",
    "run": "torus_mid_point_toroidal_eigen_mode_boundary_inner_rim_arc_inner_rim_ribbon_inner_patch_ring_n16_reg0.0008_bw0.8_tsTrue_inner",
    "basis_types": [
      "point",
      "toroidal_eigen_mode_boundary",
      "inner_rim_arc",
      "inner_rim_ribbon",
      "inner_patch_ring"
    ],
    "n_max": 16,
    "reg_l1": 0.0008,
    "boundary_weight": 0.8,
    "restarts": 1,
    "two_stage": true,
    "per_type_reg": {
      "point": 0.003,
      "toroidal_eigen_mode_boundary": 0.0008,
      "inner_rim_arc": 0.0008,
      "inner_rim_ribbon": 0.0008,
      "inner_patch_ring": 0.001
    },
    "metrics": {
      "boundary_mae": 93705352.0,
      "offaxis_mae": 806120704.0,
      "offaxis_rel": 2.9145491123199463,
      "offaxis_belt_rel": 2.4493801593780518,
      "axis_mae": 17669500444.373894,
      "axis_rel": 0.914968948208573,
      "n_images": 16,
      "sparsity90": 3,
      "type_counts": {
        "toroidal_eigen_mode": 4,
        "inner_rim_arc": 2,
        "inner_rim_ribbon": 1,
        "inner_patch_ring": 1,
        "point": 8
      }
    },
    "type_counts": {
      "toroidal_eigen_mode": 4,
      "inner_rim_arc": 2,
      "inner_rim_ribbon": 1,
      "inner_patch_ring": 1,
      "point": 8
    },
    "elapsed_s": 32.25554943084717
  },
  {
    "spec": "torus_mid",
    "run": "torus_mid_point_inner_rim_arc_inner_rim_ribbon_inner_patch_ring_n12_reg0.001_bw0.7_tsFalse_inner",
    "basis_types": [
      "point",
      "inner_rim_arc",
      "inner_rim_ribbon",
      "inner_patch_ring"
    ],
    "n_max": 12,
    "reg_l1": 0.001,
    "boundary_weight": 0.7,
    "restarts": 1,
    "two_stage": false,
    "per_type_reg": {
      "point": 0.004,
      "inner_rim_arc": 0.001,
      "inner_rim_ribbon": 0.001,
      "inner_patch_ring": 0.001
    },
    "metrics": {
      "boundary_mae": 138756416.0,
      "offaxis_mae": 770403648.0,
      "offaxis_rel": 1.9128799438476562,
      "offaxis_belt_rel": 3.179722309112549,
      "axis_mae": 17640569169.76452,
      "axis_rel": 0.8797897333863145,
      "n_images": 12,
      "sparsity90": 8,
      "type_counts": {
        "inner_rim_arc": 2,
        "inner_rim_ribbon": 1,
        "inner_patch_ring": 1,
        "point": 8
      }
    },
    "type_counts": {
      "inner_rim_arc": 2,
      "inner_rim_ribbon": 1,
      "inner_patch_ring": 1,
      "point": 8
    },
    "elapsed_s": 28.94383478164673
  }
]
================================================================================
===== END FILE: metrics\stage4_metrics_inner_rim.json =====
================================================================================

================================================================================
===== BEGIN FILE: metrics\stage4_metrics_inner_rim_refined.json =====
================================================================================

[
  {
    "spec": "torus_thin",
    "run": "torus_thin_point_toroidal_eigen_mode_boundary_inner_rim_arc_rich_inner_rim_n12_reg0.0008_bw0.8_tsFalse_rich_inner",
    "basis_types": [
      "point",
      "toroidal_eigen_mode_boundary",
      "inner_rim_arc",
      "rich_inner_rim"
    ],
    "n_max": 12,
    "reg_l1": 0.0008,
    "boundary_weight": 0.8,
    "restarts": 1,
    "two_stage": false,
    "per_type_reg": {
      "point": 0.002,
      "toroidal_eigen_mode_boundary": 0.0008,
      "inner_rim_arc": 0.0008
    },
    "metrics": {
      "boundary_mae": 157839504.0,
      "offaxis_mae": 1411896704.0,
      "offaxis_rel": 1.1156885623931885,
      "offaxis_belt_rel": 0.7133009433746338,
      "axis_mae": 368142451309709.5,
      "axis_rel": 0.9409190138273275,
      "n_images": 12,
      "sparsity90": 6,
      "type_counts": {
        "toroidal_eigen_mode": 4,
        "inner_rim_arc": 4,
        "point": 4
      }
    },
    "type_counts": {
      "toroidal_eigen_mode": 4,
      "inner_rim_arc": 4,
      "point": 4
    },
    "elapsed_s": 27.878510236740112
  }
]
================================================================================
===== END FILE: metrics\stage4_metrics_inner_rim_refined.json =====
================================================================================

================================================================================
===== BEGIN FILE: metrics\stage4_metrics_mid_axis_sweep_bem.json =====
================================================================================

[
  {
    "z": 0.4,
    "metrics": {
      "max_rel": 28249.24206204296,
      "mean_rel": 7.491638863862438,
      "inner_mean_abs": 63732395.16532022,
      "inner_mean_rel": 11.411429799100985
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    },
    "reg_l1": 0.0004,
    "boundary_weight": 0.9,
    "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.40\\discovered_system.json",
    "npz_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\diagnostics\\mid_axis_sweep_z0.40.npz"
  },
  {
    "z": 0.5,
    "metrics": {
      "max_rel": 31794.042040998072,
      "mean_rel": 7.290473752406813,
      "inner_mean_abs": 56780548.29635543,
      "inner_mean_rel": 17.78441733007571
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    },
    "reg_l1": 0.0004,
    "boundary_weight": 0.9,
    "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.50\\discovered_system.json",
    "npz_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\diagnostics\\mid_axis_sweep_z0.50.npz"
  },
  {
    "z": 0.6,
    "metrics": {
      "max_rel": 20767.196535060622,
      "mean_rel": 7.467518809717343,
      "inner_mean_abs": 53129698.064931124,
      "inner_mean_rel": 14.531227935492593
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    },
    "reg_l1": 0.0004,
    "boundary_weight": 0.9,
    "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.60\\discovered_system.json",
    "npz_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\diagnostics\\mid_axis_sweep_z0.60.npz"
  },
  {
    "z": 0.7,
    "metrics": {
      "max_rel": 23110.78409225047,
      "mean_rel": 5.51391442837005,
      "inner_mean_abs": 38987893.49877696,
      "inner_mean_rel": 7.370997596993729
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    },
    "reg_l1": 0.0004,
    "boundary_weight": 0.9,
    "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.70\\discovered_system.json",
    "npz_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\diagnostics\\mid_axis_sweep_z0.70.npz"
  },
  {
    "z": 0.8,
    "metrics": {
      "max_rel": 75968.63277835023,
      "mean_rel": 10.30366910142194,
      "inner_mean_abs": 48583147.616335124,
      "inner_mean_rel": 13.212549988429718
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    },
    "reg_l1": 0.0004,
    "boundary_weight": 0.9,
    "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.80\\discovered_system.json",
    "npz_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\diagnostics\\mid_axis_sweep_z0.80.npz"
  },
  {
    "z": 0.9,
    "metrics": {
      "max_rel": 24221.96916383447,
      "mean_rel": 7.140908922754886,
      "inner_mean_abs": 43024067.90870394,
      "inner_mean_rel": 14.612400140539366
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    },
    "reg_l1": 0.0004,
    "boundary_weight": 0.9,
    "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.90\\discovered_system.json",
    "npz_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\diagnostics\\mid_axis_sweep_z0.90.npz"
  }
]
================================================================================
===== END FILE: metrics\stage4_metrics_mid_axis_sweep_bem.json =====
================================================================================

================================================================================
===== BEGIN FILE: metrics\stage4_metrics_mid_axis_sweep_stage4.json =====
================================================================================

[
  {
    "z": 0.4,
    "metrics": {
      "boundary_mae": 46248460.0,
      "offaxis_mae": 520454496.0,
      "offaxis_rel": 0.9668756723403931,
      "offaxis_belt_rel": 0.5621426701545715,
      "axis_mae": 15023621169.598335,
      "axis_rel": 0.9631552708685117,
      "n_images": 6,
      "sparsity90": 5,
      "type_counts": {
        "poloidal_ring": 2,
        "point": 4
      }
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    },
    "reg_l1": 0.0004,
    "boundary_weight": 0.9,
    "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.40\\discovered_system.json"
  },
  {
    "z": 0.5,
    "metrics": {
      "boundary_mae": 45699064.0,
      "offaxis_mae": 681151360.0,
      "offaxis_rel": 1.072285532951355,
      "offaxis_belt_rel": 0.4242769777774811,
      "axis_mae": 17292409096.29212,
      "axis_rel": 0.9628960803479111,
      "n_images": 6,
      "sparsity90": 5,
      "type_counts": {
        "poloidal_ring": 2,
        "point": 4
      }
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    },
    "reg_l1": 0.0004,
    "boundary_weight": 0.9,
    "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.50\\discovered_system.json"
  },
  {
    "z": 0.6,
    "metrics": {
      "boundary_mae": 43987696.0,
      "offaxis_mae": 694981056.0,
      "offaxis_rel": 1.0586588382720947,
      "offaxis_belt_rel": 0.31276512145996094,
      "axis_mae": 368141418656769.2,
      "axis_rel": 0.9617275212758221,
      "n_images": 6,
      "sparsity90": 4,
      "type_counts": {
        "poloidal_ring": 2,
        "point": 4
      }
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    },
    "reg_l1": 0.0004,
    "boundary_weight": 0.9,
    "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.60\\discovered_system.json"
  },
  {
    "z": 0.7,
    "metrics": {
      "boundary_mae": 28956944.0,
      "offaxis_mae": 851339584.0,
      "offaxis_rel": 2.591733455657959,
      "offaxis_belt_rel": 0.9626517295837402,
      "axis_mae": 17721337920.225456,
      "axis_rel": 0.9733501499122945,
      "n_images": 6,
      "sparsity90": 4,
      "type_counts": {
        "poloidal_ring": 2,
        "point": 4
      }
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    },
    "reg_l1": 0.0004,
    "boundary_weight": 0.9,
    "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.70\\discovered_system.json"
  },
  {
    "z": 0.8,
    "metrics": {
      "boundary_mae": 42951640.0,
      "offaxis_mae": 877003648.0,
      "offaxis_rel": 1.1839147806167603,
      "offaxis_belt_rel": 0.970605194568634,
      "axis_mae": 15851525917.800562,
      "axis_rel": 0.9591962927524884,
      "n_images": 6,
      "sparsity90": 4,
      "type_counts": {
        "poloidal_ring": 2,
        "point": 4
      }
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    },
    "reg_l1": 0.0004,
    "boundary_weight": 0.9,
    "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.80\\discovered_system.json"
  },
  {
    "z": 0.9,
    "metrics": {
      "boundary_mae": 40879984.0,
      "offaxis_mae": 1130675584.0,
      "offaxis_rel": 1.5069364309310913,
      "offaxis_belt_rel": 0.757006049156189,
      "axis_mae": 18117973337.81008,
      "axis_rel": 0.9613354057551344,
      "n_images": 6,
      "sparsity90": 5,
      "type_counts": {
        "poloidal_ring": 2,
        "point": 4
      }
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    },
    "reg_l1": 0.0004,
    "boundary_weight": 0.9,
    "system_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\discovered\\mid_axis_sweep_z0.90\\discovered_system.json"
  }
]
================================================================================
===== END FILE: metrics\stage4_metrics_mid_axis_sweep_stage4.json =====
================================================================================

================================================================================
===== BEGIN FILE: metrics\stage4_metrics_mid_axis_weight_svd_bem.json =====
================================================================================

[
  {
    "z": 0.4,
    "rank": "full",
    "metrics": {
      "max_rel": 76956.18521534964,
      "mean_rel": 8.77345264846998,
      "inner_mean_abs": 63448811.58526389,
      "inner_mean_rel": 10.60329098387958
    },
    "npz_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\diagnostics\\mid_axis_weight_rankfull_z0.40.npz"
  },
  {
    "z": 0.4,
    "rank": 2,
    "metrics": {
      "max_rel": 68176.60417071986,
      "mean_rel": 7.858968608276959,
      "inner_mean_abs": 58697997.30202437,
      "inner_mean_rel": 9.464469643760905
    },
    "npz_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\diagnostics\\mid_axis_weight_rank2_z0.40.npz"
  },
  {
    "z": 0.4,
    "rank": 3,
    "metrics": {
      "max_rel": 70039.32176695587,
      "mean_rel": 8.078010359870031,
      "inner_mean_abs": 60272739.151184164,
      "inner_mean_rel": 9.85855445492967
    },
    "npz_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\diagnostics\\mid_axis_weight_rank3_z0.40.npz"
  },
  {
    "z": 0.6,
    "rank": "full",
    "metrics": {
      "max_rel": 5114.650965918822,
      "mean_rel": 5.778945341498697,
      "inner_mean_abs": 53961745.415399365,
      "inner_mean_rel": 9.612415662162695
    },
    "npz_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\diagnostics\\mid_axis_weight_rankfull_z0.60.npz"
  },
  {
    "z": 0.6,
    "rank": 2,
    "metrics": {
      "max_rel": 4543.388978879032,
      "mean_rel": 5.2290549252997724,
      "inner_mean_abs": 49993056.19244841,
      "inner_mean_rel": 8.710123684514148
    },
    "npz_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\diagnostics\\mid_axis_weight_rank2_z0.60.npz"
  },
  {
    "z": 0.6,
    "rank": 3,
    "metrics": {
      "max_rel": 4502.005706656673,
      "mean_rel": 5.1850665172807675,
      "inner_mean_abs": 49479629.13682924,
      "inner_mean_rel": 8.58747614831436
    },
    "npz_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\diagnostics\\mid_axis_weight_rank3_z0.60.npz"
  },
  {
    "z": 0.7,
    "rank": "full",
    "metrics": {
      "max_rel": 15047.293566321423,
      "mean_rel": 5.68337719730036,
      "inner_mean_abs": 39485993.70648648,
      "inner_mean_rel": 9.371970782349575
    },
    "npz_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\diagnostics\\mid_axis_weight_rankfull_z0.70.npz"
  },
  {
    "z": 0.7,
    "rank": 2,
    "metrics": {
      "max_rel": 16710.01652359818,
      "mean_rel": 6.223709505463275,
      "inner_mean_abs": 42478314.62688145,
      "inner_mean_rel": 10.366915991839827
    },
    "npz_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\diagnostics\\mid_axis_weight_rank2_z0.70.npz"
  },
  {
    "z": 0.7,
    "rank": 3,
    "metrics": {
      "max_rel": 16512.150376022524,
      "mean_rel": 6.154090054039686,
      "inner_mean_abs": 41909452.46053599,
      "inner_mean_rel": 10.172745917311087
    },
    "npz_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\diagnostics\\mid_axis_weight_rank3_z0.70.npz"
  },
  {
    "z": 0.9,
    "rank": "full",
    "metrics": {
      "max_rel": 410815.58321340324,
      "mean_rel": 19.252252083244098,
      "inner_mean_abs": 44368105.12080964,
      "inner_mean_rel": 10.264149491186673
    },
    "npz_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\diagnostics\\mid_axis_weight_rankfull_z0.90.npz"
  },
  {
    "z": 0.9,
    "rank": 2,
    "metrics": {
      "max_rel": 392184.01420102443,
      "mean_rel": 18.456297631725445,
      "inner_mean_abs": 42389964.03237977,
      "inner_mean_rel": 9.727398922406987
    },
    "npz_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\diagnostics\\mid_axis_weight_rank2_z0.90.npz"
  },
  {
    "z": 0.9,
    "rank": 3,
    "metrics": {
      "max_rel": 400985.10907762445,
      "mean_rel": 18.812998329053027,
      "inner_mean_abs": 43450300.50639586,
      "inner_mean_rel": 10.020310268366465
    },
    "npz_path": "C:\\Users\\dimen\\Desktop\\R.J._Tech_Admin\\emag\\electrodrive_repo\\runs\\torus\\diagnostics\\mid_axis_weight_rank3_z0.90.npz"
  }
]
================================================================================
===== END FILE: metrics\stage4_metrics_mid_axis_weight_svd_bem.json =====
================================================================================

================================================================================
===== BEGIN FILE: metrics\stage4_metrics_mid_bem_highres_local.json =====
================================================================================

[
  {
    "run": "mid_bem_highres_trial00",
    "rings": [
      {
        "radius": 1.064771796436354,
        "delta_r": 0.096409645721064,
        "order": 0
      },
      {
        "radius": 0.9439773819206975,
        "delta_r": 0.20074685410041335,
        "order": 2
      }
    ],
    "points": [
      {
        "rho": 0.8450876661748787,
        "phi": 1.432637202748396,
        "z": 0.029687613226783472
      },
      {
        "rho": 0.9022052673477143,
        "phi": 1.5206687041079503,
        "z": 0.03228198717289325
      },
      {
        "rho": 0.8459356069124241,
        "phi": 2.8414130387222167,
        "z": -0.046711064258179905
      },
      {
        "rho": 0.8645544379426462,
        "phi": 2.913529665927185,
        "z": 0.07035987556568037
      }
    ],
    "reg_l1": 0.0003,
    "boundary_weight": 0.9,
    "metrics": {
      "max_rel": 48462.96782762683,
      "mean_rel": 10.378409227495037,
      "inner_mean_abs": 60786967.496775396,
      "inner_mean_rel": 12.607643634329197
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    }
  },
  {
    "run": "mid_bem_highres_trial01",
    "rings": [
      {
        "radius": 1.055906766373682,
        "delta_r": 0.09766227735110501,
        "order": 0
      },
      {
        "radius": 0.9396129624286257,
        "delta_r": 0.1994850587950858,
        "order": 2
      }
    ],
    "points": [
      {
        "rho": 0.8253239405344368,
        "phi": 1.7695727861539825,
        "z": -0.0019135971371017982
      },
      {
        "rho": 0.8942299819509157,
        "phi": 1.5427281312971894,
        "z": 0.016682996528824864
      },
      {
        "rho": 0.8416390822239534,
        "phi": 2.936218619641686,
        "z": -0.0629332651772693
      },
      {
        "rho": 0.8802486385785503,
        "phi": 3.039599294908421,
        "z": 0.07035923701531605
      },
      {
        "rho": 0.8479766001010105,
        "phi": 3.108778564210469,
        "z": 0.10132574332098684
      }
    ],
    "reg_l1": 0.0006,
    "boundary_weight": 0.95,
    "metrics": {
      "max_rel": 45354.22774328765,
      "mean_rel": 9.765883275783741,
      "inner_mean_abs": 57848931.99612166,
      "inner_mean_rel": 11.870201280684235
    },
    "n_images": 7,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 5
    }
  },
  {
    "run": "mid_bem_highres_trial02",
    "rings": [
      {
        "radius": 1.0572520602426125,
        "delta_r": 0.08330611714662312,
        "order": 2
      },
      {
        "radius": 0.9534857715110798,
        "delta_r": 0.18689133279124553,
        "order": 2
      }
    ],
    "points": [
      {
        "rho": 0.8488895546341421,
        "phi": 1.6614855454092532,
        "z": 0.01143324662271416
      },
      {
        "rho": 0.9068986133185759,
        "phi": 1.7102155615143193,
        "z": 0.0073220205714147595
      },
      {
        "rho": 0.844458210883082,
        "phi": 3.058832974389509,
        "z": -0.0417168433213225
      },
      {
        "rho": 0.8496426911423777,
        "phi": 3.130141493966175,
        "z": 0.08968504792237417
      }
    ],
    "reg_l1": 0.0002,
    "boundary_weight": 0.95,
    "metrics": {
      "max_rel": 22487.10945862872,
      "mean_rel": 5.393999562212118,
      "inner_mean_abs": 38889107.28195952,
      "inner_mean_rel": 7.353864916892917
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    }
  },
  {
    "run": "mid_bem_highres_trial03",
    "rings": [
      {
        "radius": 1.076588520170078,
        "delta_r": 0.08126545465309921,
        "order": 0
      },
      {
        "radius": 0.9322729704689742,
        "delta_r": 0.1955481137246259,
        "order": 2
      }
    ],
    "points": [
      {
        "rho": 0.8260547737484379,
        "phi": 1.636428572337462,
        "z": -0.002450568415376008
      },
      {
        "rho": 0.9196638949703929,
        "phi": 1.7972634655628548,
        "z": 0.03303479695499438
      },
      {
        "rho": 0.846248001245079,
        "phi": 2.84747384624864,
        "z": -0.05130539227554344
      },
      {
        "rho": 0.8739417603017331,
        "phi": 3.064326209525003,
        "z": 0.07888698587481488
      }
    ],
    "reg_l1": 0.0003,
    "boundary_weight": 0.9,
    "metrics": {
      "max_rel": 47613.04274180321,
      "mean_rel": 10.133079464230317,
      "inner_mean_abs": 57838660.43532323,
      "inner_mean_rel": 11.764124990657328
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    }
  },
  {
    "run": "mid_bem_highres_trial04",
    "rings": [
      {
        "radius": 1.0659224159966845,
        "delta_r": 0.09396764678329216,
        "order": 0
      },
      {
        "radius": 0.9494669291053012,
        "delta_r": 0.20100227393648779,
        "order": 2
      }
    ],
    "points": [
      {
        "rho": 0.8525273217882026,
        "phi": 1.7098209624709217,
        "z": 0.03211972714576335
      },
      {
        "rho": 0.9036424794604214,
        "phi": 1.7260947899777,
        "z": 0.00038486017757265525
      },
      {
        "rho": 0.8461777416192272,
        "phi": 3.0081252744439544,
        "z": -0.06616457944754815
      },
      {
        "rho": 0.8847670228849156,
        "phi": 3.1543618519553935,
        "z": 0.0678299647327899
      }
    ],
    "reg_l1": 0.0003,
    "boundary_weight": 0.95,
    "metrics": {
      "max_rel": 41727.797108122555,
      "mean_rel": 9.045440717640911,
      "inner_mean_abs": 53986556.5960198,
      "inner_mean_rel": 10.871789068683693
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    }
  },
  {
    "run": "mid_bem_highres_trial05",
    "rings": [
      {
        "radius": 1.073657543019344,
        "delta_r": 0.09181625793367915,
        "order": 0
      },
      {
        "radius": 0.9273580519769278,
        "delta_r": 0.19410375997156631,
        "order": 2
      }
    ],
    "points": [
      {
        "rho": 0.8216278381234635,
        "phi": 1.6104241722726438,
        "z": 0.01011123331981718
      },
      {
        "rho": 0.912922207458526,
        "phi": 1.6277962865815667,
        "z": -0.0035313111360848123
      },
      {
        "rho": 0.8196784511057223,
        "phi": 3.134552108238977,
        "z": -0.06293713534588301
      },
      {
        "rho": 0.8862660054173301,
        "phi": 3.132444977813828,
        "z": 0.07599877896701242
      }
    ],
    "reg_l1": 0.0002,
    "boundary_weight": 0.9,
    "metrics": {
      "max_rel": 51906.627936202116,
      "mean_rel": 11.002460708280381,
      "inner_mean_abs": 62747773.24217552,
      "inner_mean_rel": 13.04049658472366
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    }
  },
  {
    "run": "mid_bem_highres_trial06",
    "rings": [
      {
        "radius": 1.0511833983826133,
        "delta_r": 0.08458514029994361,
        "order": 0
      },
      {
        "radius": 0.9553872613979137,
        "delta_r": 0.19929205753461754,
        "order": 2
      }
    ],
    "points": [
      {
        "rho": 0.8239628390434635,
        "phi": 1.4317060092438059,
        "z": 0.013696890525858759
      },
      {
        "rho": 0.9153803293275281,
        "phi": 1.5032064305476078,
        "z": -0.00031182592544809484
      },
      {
        "rho": 0.8319841796237769,
        "phi": 3.1342260771965424,
        "z": -0.07856317630056274
      },
      {
        "rho": 0.8580038454830542,
        "phi": 3.0359875873126025,
        "z": 0.06182799609884908
      }
    ],
    "reg_l1": 0.0004,
    "boundary_weight": 0.95,
    "metrics": {
      "max_rel": 45980.75318905887,
      "mean_rel": 9.913392027005552,
      "inner_mean_abs": 58554295.81755464,
      "inner_mean_rel": 11.901859455325209
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    }
  },
  {
    "run": "mid_bem_highres_trial07",
    "rings": [
      {
        "radius": 1.0519168414955182,
        "delta_r": 0.08692821728376575,
        "order": 0
      },
      {
        "radius": 0.9297476969320235,
        "delta_r": 0.2042824921432317,
        "order": 2
      }
    ],
    "points": [
      {
        "rho": 0.8271807423204602,
        "phi": 1.7802279036599493,
        "z": 0.018737012817173403
      },
      {
        "rho": 0.9206781858554604,
        "phi": 1.686075769829913,
        "z": 0.02311693298674289
      },
      {
        "rho": 0.8119278514453068,
        "phi": 2.915381011105898,
        "z": -0.06759635981244896
      },
      {
        "rho": 0.8750024564592109,
        "phi": 3.016171334370399,
        "z": 0.06300040053950126
      }
    ],
    "reg_l1": 0.0004,
    "boundary_weight": 0.95,
    "metrics": {
      "max_rel": 39594.4420377804,
      "mean_rel": 8.628376966231963,
      "inner_mean_abs": 52063913.41614443,
      "inner_mean_rel": 10.437600214250327
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    }
  },
  {
    "run": "mid_bem_highres_trial08",
    "rings": [
      {
        "radius": 1.0474473461300133,
        "delta_r": 0.09042042462570564,
        "order": 0
      },
      {
        "radius": 0.9291108853502796,
        "delta_r": 0.20479605071366377,
        "order": 0
      }
    ],
    "points": [
      {
        "rho": 0.8492372345536834,
        "phi": 1.6397225100982373,
        "z": 0.009087760352637057
      },
      {
        "rho": 0.9077616209991324,
        "phi": 1.474449407242665,
        "z": 0.03228824395095131
      },
      {
        "rho": 0.825839892406465,
        "phi": 2.859428162669381,
        "z": -0.07885810542230116
      },
      {
        "rho": 0.8725225647136634,
        "phi": 3.2575998018212324,
        "z": 0.08366396161732852
      }
    ],
    "reg_l1": 0.0004,
    "boundary_weight": 0.9,
    "metrics": {
      "max_rel": 45901.123997647665,
      "mean_rel": 10.580358476021088,
      "inner_mean_abs": 74519539.6491652,
      "inner_mean_rel": 15.277824681609264
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    }
  },
  {
    "run": "mid_bem_highres_trial09",
    "rings": [
      {
        "radius": 1.0544045705225482,
        "delta_r": 0.0880590568647503,
        "order": 0
      },
      {
        "radius": 0.9501064230475927,
        "delta_r": 0.19474894850614755,
        "order": 2
      }
    ],
    "points": [
      {
        "rho": 0.8201559568317986,
        "phi": 1.6387441151287272,
        "z": 0.007122834406561052
      },
      {
        "rho": 0.9040711778644288,
        "phi": 1.5982724483328086,
        "z": -0.0036769962176418647
      },
      {
        "rho": 0.8085430406641513,
        "phi": 2.887967400087085,
        "z": -0.055008199529007665
      },
      {
        "rho": 0.8689131013188397,
        "phi": 3.149132244434558,
        "z": 0.08102039596115844
      }
    ],
    "reg_l1": 0.0004,
    "boundary_weight": 0.95,
    "metrics": {
      "max_rel": 42254.677193444426,
      "mean_rel": 9.176580139085544,
      "inner_mean_abs": 54644729.42866443,
      "inner_mean_rel": 11.010483355159097
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    }
  },
  {
    "run": "mid_bem_highres_trial10",
    "rings": [
      {
        "radius": 1.0636958717296374,
        "delta_r": 0.08670845032116235,
        "order": 0
      },
      {
        "radius": 0.9307221902044754,
        "delta_r": 0.19549905418516586,
        "order": 2
      }
    ],
    "points": [
      {
        "rho": 0.8453555606886385,
        "phi": 1.508650670080685,
        "z": -0.0017787051665635045
      },
      {
        "rho": 0.8986215102890418,
        "phi": 1.7543260542242036,
        "z": 0.008633575250802866
      },
      {
        "rho": 0.832040278993947,
        "phi": 3.063033079675856,
        "z": -0.04122119561057179
      },
      {
        "rho": 0.8570811198889964,
        "phi": 3.0343958118765455,
        "z": 0.08797542016959903
      }
    ],
    "reg_l1": 0.0004,
    "boundary_weight": 0.95,
    "metrics": {
      "max_rel": 41138.31205896382,
      "mean_rel": 8.91435525191646,
      "inner_mean_abs": 53438389.99308947,
      "inner_mean_rel": 10.831996979993209
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    }
  },
  {
    "run": "mid_bem_highres_trial11",
    "rings": [
      {
        "radius": 1.0476070903400108,
        "delta_r": 0.09129282091475882,
        "order": 0
      },
      {
        "radius": 0.9462429762830217,
        "delta_r": 0.1938178632941214,
        "order": 2
      }
    ],
    "points": [
      {
        "rho": 0.8520076271638596,
        "phi": 1.5786877789140743,
        "z": -0.00035051903092656045
      },
      {
        "rho": 0.9001179389406164,
        "phi": 1.58796489302225,
        "z": 0.009059564727875204
      },
      {
        "rho": 0.8287279982193031,
        "phi": 2.9025262140403063,
        "z": -0.07466992638061604
      },
      {
        "rho": 0.8721656576268073,
        "phi": 2.947359447488022,
        "z": 0.0828605309141959
      }
    ],
    "reg_l1": 0.0003,
    "boundary_weight": 0.95,
    "metrics": {
      "max_rel": 39499.87733264694,
      "mean_rel": 8.630752783217819,
      "inner_mean_abs": 52472113.08850752,
      "inner_mean_rel": 10.486407872263486
    },
    "n_images": 6,
    "type_counts": {
      "poloidal_ring": 2,
      "point": 4
    }
  }
]
================================================================================
===== END FILE: metrics\stage4_metrics_mid_bem_highres_local.json =====
================================================================================

================================================================================
===== BEGIN FILE: metrics\stage4_metrics_modes_families.json =====
================================================================================

[
  {
    "spec": "torus_thin",
    "run": "torus_thin_point_toroidal_eigen_mode_boundary_n12_reg0.001_bw0.8_tsFalse",
    "basis_types": [
      "point",
      "toroidal_eigen_mode_boundary"
    ],
    "n_max": 12,
    "reg_l1": 0.001,
    "boundary_weight": 0.8,
    "restarts": 1,
    "two_stage": false,
    "per_type_reg": {
      "point": 0.002,
      "toroidal_eigen_mode_boundary": 0.0008
    },
    "metrics": {
      "boundary_mae": 154295600.0,
      "offaxis_mae": 1461747584.0,
      "offaxis_rel": 0.9282485246658325,
      "offaxis_belt_rel": NaN,
      "axis_mae": 368142452167304.25,
      "axis_rel": 0.941048297842255,
      "n_images": 12,
      "sparsity90": 3,
      "type_counts": {
        "toroidal_eigen_mode": 4,
        "point": 8
      }
    },
    "type_counts": {
      "toroidal_eigen_mode": 4,
      "point": 8
    },
    "elapsed_s": 29.008260488510132
  },
  {
    "spec": "torus_thin",
    "run": "torus_thin_point_poloidal_ring_toroidal_eigen_mode_boundary_ring_ladder_inner_n16_reg0.001_bw0.8_tsTrue",
    "basis_types": [
      "point",
      "poloidal_ring",
      "toroidal_eigen_mode_boundary",
      "ring_ladder_inner"
    ],
    "n_max": 16,
    "reg_l1": 0.001,
    "boundary_weight": 0.8,
    "restarts": 1,
    "two_stage": true,
    "per_type_reg": {
      "point": 0.003,
      "poloidal_ring": 0.001,
      "ring_ladder_inner": 0.001,
      "toroidal_eigen_mode_boundary": 0.0008
    },
    "metrics": {
      "boundary_mae": 166438848.0,
      "offaxis_mae": 1597092864.0,
      "offaxis_rel": 0.9122951626777649,
      "offaxis_belt_rel": 6.5958099365234375,
      "axis_mae": 368142446854045.75,
      "axis_rel": 0.9389755124330924,
      "n_images": 16,
      "sparsity90": 4,
      "type_counts": {
        "poloidal_ring": 3,
        "ring_ladder_inner": 1,
        "point": 12
      }
    },
    "type_counts": {
      "poloidal_ring": 3,
      "ring_ladder_inner": 1,
      "point": 12
    },
    "elapsed_s": 13.424432516098022
  },
  {
    "spec": "torus_mid",
    "run": "torus_mid_point_toroidal_eigen_mode_boundary_n12_reg0.001_bw0.8_tsFalse",
    "basis_types": [
      "point",
      "toroidal_eigen_mode_boundary"
    ],
    "n_max": 12,
    "reg_l1": 0.001,
    "boundary_weight": 0.8,
    "restarts": 1,
    "two_stage": false,
    "per_type_reg": {
      "point": 0.002,
      "toroidal_eigen_mode_boundary": 0.0008
    },
    "metrics": {
      "boundary_mae": 87109984.0,
      "offaxis_mae": 749104000.0,
      "offaxis_rel": 1.9288212060928345,
      "offaxis_belt_rel": NaN,
      "axis_mae": 17673432398.04577,
      "axis_rel": 0.9185212641319356,
      "n_images": 12,
      "sparsity90": 2,
      "type_counts": {
        "toroidal_eigen_mode": 4,
        "point": 8
      }
    },
    "type_counts": {
      "toroidal_eigen_mode": 4,
      "point": 8
    },
    "elapsed_s": 55.20566177368164
  },
  {
    "spec": "torus_mid",
    "run": "torus_mid_point_poloidal_ring_toroidal_eigen_mode_boundary_ring_ladder_inner_n16_reg0.001_bw0.8_tsTrue",
    "basis_types": [
      "point",
      "poloidal_ring",
      "toroidal_eigen_mode_boundary",
      "ring_ladder_inner"
    ],
    "n_max": 16,
    "reg_l1": 0.001,
    "boundary_weight": 0.8,
    "restarts": 1,
    "two_stage": true,
    "per_type_reg": {
      "point": 0.003,
      "poloidal_ring": 0.001,
      "ring_ladder_inner": 0.001,
      "toroidal_eigen_mode_boundary": 0.0008
    },
    "metrics": {
      "boundary_mae": 92927176.0,
      "offaxis_mae": 775888640.0,
      "offaxis_rel": 1.5260564088821411,
      "offaxis_belt_rel": NaN,
      "axis_mae": 17670217752.01452,
      "axis_rel": 0.9166558192036174,
      "n_images": 16,
      "sparsity90": 4,
      "type_counts": {
        "poloidal_ring": 3,
        "point": 12,
        "ring_ladder_inner": 1
      }
    },
    "type_counts": {
      "poloidal_ring": 3,
      "point": 12,
      "ring_ladder_inner": 1
    },
    "elapsed_s": 29.028461694717407
  }
]
================================================================================
===== END FILE: metrics\stage4_metrics_modes_families.json =====
================================================================================

================================================================================
===== BEGIN FILE: README.txt =====
================================================================================

Staging contents for mid-torus 2-ring + 4-point study

- docs/: research PDFs (toroid, inner-rim asymptotics, functional analysis).
- specs/: torus specs (mid, thin if present).
- systems/: discovered systems (baseline, seed, trial003, trial02, axis sweep, rank-2/3 SVD systems).
- metrics/: JSON metrics (discovery, axis sweep, weights/SVD).
- diagnostics/: NPZ error fields (baseline, trial02, axis sweep, rank truncations).
- code/: core scripts and plotting utilities used to generate figures/tables.
- vault_summaries/: lab-style summaries for key experiments.
- figures/raw/: original diagnostic PNGs.
- figures/paper/: paper-ready figures (fig1–fig10, rank plots, histograms, error maps).
- tables/: CSV tables for candidate metrics and axis sweep.

================================================================================
===== END FILE: README.txt =====
================================================================================

================================================================================
===== BEGIN FILE: specs\torus_axis_point_mid.json =====
================================================================================

{
  "charges": [
    { "type": "point", "q": 1.0, "pos": [0.0, 0.0, 0.7] }
  ],
  "conductors": [
    {
      "type": "torus",
      "center": [0.0, 0.0, 0.0],
      "major_radius": 1.0,
      "minor_radius": 0.35,
      "potential": 0.0
    }
  ],
  "domain": { "bbox": [[-3, -3, -3], [3, 3, 3]] }
}

================================================================================
===== END FILE: specs\torus_axis_point_mid.json =====
================================================================================

================================================================================
===== BEGIN FILE: specs\torus_axis_point_thin.json =====
================================================================================

{
  "charges": [
    { "type": "point", "q": 1.0, "pos": [0.0, 0.0, 0.6] }
  ],
  "conductors": [
    {
      "type": "torus",
      "center": [0.0, 0.0, 0.0],
      "major_radius": 1.0,
      "minor_radius": 0.15,
      "potential": 0.0
    }
  ],
  "domain": { "bbox": [[-3, -3, -3], [3, 3, 3]] }
}

================================================================================
===== END FILE: specs\torus_axis_point_thin.json =====
================================================================================

================================================================================
===== BEGIN FILE: systems\mid_axis_sweep_z0.40.json =====
================================================================================

{
  "metadata": {
    "z": 0.4,
    "reg_l1": 0.0004,
    "boundary_weight": 0.9
  },
  "images": [
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 1.057252049446106,
        "delta_r": 0.08330611884593964,
        "order": 2,
        "n_quad": 128
      },
      "weight": 0.001306801801547408
    },
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 0.9534857869148254,
        "delta_r": 0.1868913322687149,
        "order": 2,
        "n_quad": 128
      },
      "weight": 0.008410651236772537
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.07687963545322418,
          0.8454010486602783,
          0.011433246545493603
        ]
      },
      "weight": 0.009251425974071026
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.12602989375591278,
          0.898098886013031,
          0.00732202036306262
        ]
      },
      "weight": -0.006085553672164679
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.841567873954773,
          0.06980734318494797,
          -0.04171684384346008
        ]
      },
      "weight": -0.005418639630079269
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.8495869040489197,
          0.009729181416332722,
          0.08968504518270493
        ]
      },
      "weight": 0.009170474484562874
    }
  ]
}
================================================================================
===== END FILE: systems\mid_axis_sweep_z0.40.json =====
================================================================================

================================================================================
===== BEGIN FILE: systems\mid_axis_sweep_z0.50.json =====
================================================================================

{
  "metadata": {
    "z": 0.5,
    "reg_l1": 0.0004,
    "boundary_weight": 0.9
  },
  "images": [
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 1.057252049446106,
        "delta_r": 0.08330611884593964,
        "order": 2,
        "n_quad": 128
      },
      "weight": 0.000922389910556376
    },
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 0.9534857869148254,
        "delta_r": 0.1868913322687149,
        "order": 2,
        "n_quad": 128
      },
      "weight": 0.004915258847177029
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.07687963545322418,
          0.8454010486602783,
          0.011433246545493603
        ]
      },
      "weight": 0.008057046681642532
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.12602989375591278,
          0.898098886013031,
          0.00732202036306262
        ]
      },
      "weight": -0.004811642225831747
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.841567873954773,
          0.06980734318494797,
          -0.04171684384346008
        ]
      },
      "weight": -0.007977703586220741
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.8495869040489197,
          0.009729181416332722,
          0.08968504518270493
        ]
      },
      "weight": 0.011593419127166271
    }
  ]
}
================================================================================
===== END FILE: systems\mid_axis_sweep_z0.50.json =====
================================================================================

================================================================================
===== BEGIN FILE: systems\mid_axis_sweep_z0.60.json =====
================================================================================

{
  "metadata": {
    "z": 0.6,
    "reg_l1": 0.0004,
    "boundary_weight": 0.9
  },
  "images": [
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 1.057252049446106,
        "delta_r": 0.08330611884593964,
        "order": 2,
        "n_quad": 128
      },
      "weight": 0.0004059612692799419
    },
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 0.9534857869148254,
        "delta_r": 0.1868913322687149,
        "order": 2,
        "n_quad": 128
      },
      "weight": 0.0015079121803864837
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.07687963545322418,
          0.8454010486602783,
          0.011433246545493603
        ]
      },
      "weight": 0.005641034338623285
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.12602989375591278,
          0.898098886013031,
          0.00732202036306262
        ]
      },
      "weight": -0.001967949327081442
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.841567873954773,
          0.06980734318494797,
          -0.04171684384346008
        ]
      },
      "weight": -0.006050618831068277
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.8495869040489197,
          0.009729181416332722,
          0.08968504518270493
        ]
      },
      "weight": 0.009091817773878574
    }
  ]
}
================================================================================
===== END FILE: systems\mid_axis_sweep_z0.60.json =====
================================================================================

================================================================================
===== BEGIN FILE: systems\mid_axis_sweep_z0.70.json =====
================================================================================

{
  "metadata": {
    "z": 0.7,
    "reg_l1": 0.0004,
    "boundary_weight": 0.9
  },
  "images": [
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 1.057252049446106,
        "delta_r": 0.08330611884593964,
        "order": 2,
        "n_quad": 128
      },
      "weight": 0.000267999799689278
    },
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 0.9534857869148254,
        "delta_r": 0.1868913322687149,
        "order": 2,
        "n_quad": 128
      },
      "weight": 0.0011615999974310398
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.07687963545322418,
          0.8454010486602783,
          0.011433246545493603
        ]
      },
      "weight": 0.004377189092338085
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.12602989375591278,
          0.898098886013031,
          0.00732202036306262
        ]
      },
      "weight": -0.0020764386281371117
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.841567873954773,
          0.06980734318494797,
          -0.04171684384346008
        ]
      },
      "weight": -0.005346748046576977
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.8495869040489197,
          0.009729181416332722,
          0.08968504518270493
        ]
      },
      "weight": 0.007603487931191921
    }
  ]
}
================================================================================
===== END FILE: systems\mid_axis_sweep_z0.70.json =====
================================================================================

================================================================================
===== BEGIN FILE: systems\mid_axis_sweep_z0.80.json =====
================================================================================

{
  "metadata": {
    "z": 0.8,
    "reg_l1": 0.0004,
    "boundary_weight": 0.9
  },
  "images": [
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 1.057252049446106,
        "delta_r": 0.08330611884593964,
        "order": 2,
        "n_quad": 128
      },
      "weight": -0.00020965366275049746
    },
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 0.9534857869148254,
        "delta_r": 0.1868913322687149,
        "order": 2,
        "n_quad": 128
      },
      "weight": -0.0022326004691421986
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.07687963545322418,
          0.8454010486602783,
          0.011433246545493603
        ]
      },
      "weight": 0.002137273084372282
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.12602989375591278,
          0.898098886013031,
          0.00732202036306262
        ]
      },
      "weight": 0.0014499076642096043
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.841567873954773,
          0.06980734318494797,
          -0.04171684384346008
        ]
      },
      "weight": -0.007378298789262772
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.8495869040489197,
          0.009729181416332722,
          0.08968504518270493
        ]
      },
      "weight": 0.010186675004661083
    }
  ]
}
================================================================================
===== END FILE: systems\mid_axis_sweep_z0.80.json =====
================================================================================

================================================================================
===== BEGIN FILE: systems\mid_axis_sweep_z0.90.json =====
================================================================================

{
  "metadata": {
    "z": 0.9,
    "reg_l1": 0.0004,
    "boundary_weight": 0.9
  },
  "images": [
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 1.057252049446106,
        "delta_r": 0.08330611884593964,
        "order": 2,
        "n_quad": 128
      },
      "weight": -0.0004557660431601107
    },
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 0.9534857869148254,
        "delta_r": 0.1868913322687149,
        "order": 2,
        "n_quad": 128
      },
      "weight": -0.0040223621763288975
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.07687963545322418,
          0.8454010486602783,
          0.011433246545493603
        ]
      },
      "weight": -0.0007280927966348827
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.12602989375591278,
          0.898098886013031,
          0.00732202036306262
        ]
      },
      "weight": 0.004624643363058567
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.841567873954773,
          0.06980734318494797,
          -0.04171684384346008
        ]
      },
      "weight": -0.0073957983404397964
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.8495869040489197,
          0.009729181416332722,
          0.08968504518270493
        ]
      },
      "weight": 0.010106083005666733
    }
  ]
}
================================================================================
===== END FILE: systems\mid_axis_sweep_z0.90.json =====
================================================================================

================================================================================
===== BEGIN FILE: systems\mid_axis_weight_rank2_z0.60.json =====
================================================================================

{
  "metadata": {
    "z": 0.6,
    "rank": "rank2"
  },
  "images": [
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 1.057252049446106,
        "delta_r": 0.08330611884593964,
        "order": 2,
        "n_quad": 128
      },
      "weight": 0.00042084878077730536
    },
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 0.9534857869148254,
        "delta_r": 0.1868913322687149,
        "order": 2,
        "n_quad": 128
      },
      "weight": 0.001898699440062046
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.07687963545322418,
          0.8454010486602783,
          0.011433246545493603
        ]
      },
      "weight": 0.005149542354047298
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.12602989375591278,
          0.898098886013031,
          0.00732202036306262
        ]
      },
      "weight": -0.002030625706538558
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.841567873954773,
          0.06980734318494797,
          -0.04171684384346008
        ]
      },
      "weight": -0.006237671244889498
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.8495869040489197,
          0.009729181416332722,
          0.08968504518270493
        ]
      },
      "weight": 0.009145250543951988
    }
  ]
}
================================================================================
===== END FILE: systems\mid_axis_weight_rank2_z0.60.json =====
================================================================================

================================================================================
===== BEGIN FILE: systems\mid_axis_weight_rank2_z0.90.json =====
================================================================================

{
  "metadata": {
    "z": 0.9,
    "rank": "rank2"
  },
  "images": [
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 1.057252049446106,
        "delta_r": 0.08330611884593964,
        "order": 2,
        "n_quad": 128
      },
      "weight": -0.000525167677551508
    },
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 0.9534857869148254,
        "delta_r": 0.1868913322687149,
        "order": 2,
        "n_quad": 128
      },
      "weight": -0.004749143961817026
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.07687963545322418,
          0.8454010486602783,
          0.011433246545493603
        ]
      },
      "weight": -0.0004247041651979089
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.12602989375591278,
          0.898098886013031,
          0.00732202036306262
        ]
      },
      "weight": 0.004123192746192217
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.841567873954773,
          0.06980734318494797,
          -0.04171684384346008
        ]
      },
      "weight": -0.007374897599220276
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.8495869040489197,
          0.009729181416332722,
          0.08968504518270493
        ]
      },
      "weight": 0.009992247447371483
    }
  ]
}
================================================================================
===== END FILE: systems\mid_axis_weight_rank2_z0.90.json =====
================================================================================

================================================================================
===== BEGIN FILE: systems\mid_axis_weight_rank3_z0.60.json =====
================================================================================

{
  "metadata": {
    "z": 0.6,
    "rank": "rank3"
  },
  "images": [
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 1.057252049446106,
        "delta_r": 0.08330611884593964,
        "order": 2,
        "n_quad": 128
      },
      "weight": 0.0003730954194907099
    },
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 0.9534857869148254,
        "delta_r": 0.1868913322687149,
        "order": 2,
        "n_quad": 128
      },
      "weight": 0.0015215007588267326
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.07687963545322418,
          0.8454010486602783,
          0.011433246545493603
        ]
      },
      "weight": 0.0053522298112511635
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.12602989375591278,
          0.898098886013031,
          0.00732202036306262
        ]
      },
      "weight": -0.0022497824393212795
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.841567873954773,
          0.06980734318494797,
          -0.04171684384346008
        ]
      },
      "weight": -0.006229516118764877
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.8495869040489197,
          0.009729181416332722,
          0.08968504518270493
        ]
      },
      "weight": 0.009068531915545464
    }
  ]
}
================================================================================
===== END FILE: systems\mid_axis_weight_rank3_z0.60.json =====
================================================================================

================================================================================
===== BEGIN FILE: systems\mid_axis_weight_rank3_z0.90.json =====
================================================================================

{
  "metadata": {
    "z": 0.9,
    "rank": "rank3"
  },
  "images": [
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 1.057252049446106,
        "delta_r": 0.08330611884593964,
        "order": 2,
        "n_quad": 128
      },
      "weight": -0.0004339452716521919
    },
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 0.9534857869148254,
        "delta_r": 0.1868913322687149,
        "order": 2,
        "n_quad": 128
      },
      "weight": -0.004028587602078915
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.07687963545322418,
          0.8454010486602783,
          0.011433246545493603
        ]
      },
      "weight": -0.0008118939585983753
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.12602989375591278,
          0.898098886013031,
          0.00732202036306262
        ]
      },
      "weight": 0.004541843663901091
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.841567873954773,
          0.06980734318494797,
          -0.04171684384346008
        ]
      },
      "weight": -0.007390476297587156
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.8495869040489197,
          0.009729181416332722,
          0.08968504518270493
        ]
      },
      "weight": 0.010138803161680698
    }
  ]
}
================================================================================
===== END FILE: systems\mid_axis_weight_rank3_z0.90.json =====
================================================================================

================================================================================
===== BEGIN FILE: systems\mid_baseline_eigen.json =====
================================================================================

{
  "metadata": {
    "name": "mid_baseline_eigen",
    "basis_types": [
      "point",
      "toroidal_eigen_mode_boundary"
    ],
    "n_max": 12,
    "reg_l1": 0.001,
    "boundary_weight": 0.8,
    "per_type_reg": {
      "point": 0.002,
      "toroidal_eigen_mode_boundary": 0.0008
    }
  },
  "images": [
    {
      "type": "toroidal_eigen_mode",
      "params": {
        "components": [
          {
            "coeff": 2.276411533355713,
            "elem": {
              "type": "poloidal_ring",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "radius": 1.0,
                "delta_r": 0.17499999701976776,
                "order": 1,
                "n_quad": 128
              }
            }
          },
          {
            "coeff": 1.7075176239013672,
            "elem": {
              "type": "toroidal_mode_cluster",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "major_radius": 1.0,
                "minor_radius": 0.3499999940395355,
                "mode_m": 0,
                "n_phi": 16,
                "radial_offset": 0.17499999701976776
              }
            }
          },
          {
            "coeff": -0.7464241981506348,
            "elem": {
              "type": "poloidal_ring",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "radius": 1.0,
                "delta_r": 0.17499999701976776,
                "order": 2,
                "n_quad": 128
              }
            }
          },
          {
            "coeff": -0.729513943195343,
            "elem": {
              "type": "poloidal_ring",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "radius": 1.0,
                "delta_r": 0.17499999701976776,
                "order": 0,
                "n_quad": 128
              }
            }
          },
          {
            "coeff": -0.4833073616027832,
            "elem": {
              "type": "ring_ladder_inner",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "radius": 1.0,
                "minor_radius": 0.3499999940395355,
                "variant": 0,
                "n_quad": 96
              }
            }
          },
          {
            "coeff": -0.48302316665649414,
            "elem": {
              "type": "ring_ladder_inner",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "radius": 1.0,
                "minor_radius": 0.3499999940395355,
                "variant": 0,
                "n_quad": 96
              }
            }
          },
          {
            "coeff": 0.07898146659135818,
            "elem": {
              "type": "toroidal_mode_cluster",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "major_radius": 1.0,
                "minor_radius": 0.3499999940395355,
                "mode_m": 2,
                "n_phi": 16,
                "radial_offset": 0.17499999701976776
              }
            }
          },
          {
            "coeff": 0.046148285269737244,
            "elem": {
              "type": "toroidal_mode_cluster",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "major_radius": 1.0,
                "minor_radius": 0.3499999940395355,
                "mode_m": 1,
                "n_phi": 16,
                "radial_offset": 0.17499999701976776
              }
            }
          }
        ]
      },
      "weight": -0.010027432814240456
    },
    {
      "type": "toroidal_eigen_mode",
      "params": {
        "components": [
          {
            "coeff": 1.4710540771484375,
            "elem": {
              "type": "poloidal_ring",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "radius": 1.0,
                "delta_r": 0.17499999701976776,
                "order": 1,
                "n_quad": 128
              }
            }
          },
          {
            "coeff": 1.0234813690185547,
            "elem": {
              "type": "toroidal_mode_cluster",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "major_radius": 1.0,
                "minor_radius": 0.3499999940395355,
                "mode_m": 0,
                "n_phi": 16,
                "radial_offset": 0.17499999701976776
              }
            }
          },
          {
            "coeff": -0.5953559875488281,
            "elem": {
              "type": "poloidal_ring",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "radius": 1.0,
                "delta_r": 0.17499999701976776,
                "order": 2,
                "n_quad": 128
              }
            }
          },
          {
            "coeff": -0.34895801544189453,
            "elem": {
              "type": "ring_ladder_inner",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "radius": 1.0,
                "minor_radius": 0.3499999940395355,
                "variant": 0,
                "n_quad": 96
              }
            }
          },
          {
            "coeff": -0.3487577438354492,
            "elem": {
              "type": "ring_ladder_inner",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "radius": 1.0,
                "minor_radius": 0.3499999940395355,
                "variant": 0,
                "n_quad": 96
              }
            }
          },
          {
            "coeff": -0.3085756301879883,
            "elem": {
              "type": "poloidal_ring",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "radius": 1.0,
                "delta_r": 0.17499999701976776,
                "order": 0,
                "n_quad": 128
              }
            }
          },
          {
            "coeff": 0.070309117436409,
            "elem": {
              "type": "toroidal_mode_cluster",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "major_radius": 1.0,
                "minor_radius": 0.3499999940395355,
                "mode_m": 2,
                "n_phi": 16,
                "radial_offset": 0.17499999701976776
              }
            }
          },
          {
            "coeff": 0.03172580152750015,
            "elem": {
              "type": "toroidal_mode_cluster",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "major_radius": 1.0,
                "minor_radius": 0.3499999940395355,
                "mode_m": 1,
                "n_phi": 16,
                "radial_offset": 0.17499999701976776
              }
            }
          }
        ]
      },
      "weight": 0.17203514277935028
    },
    {
      "type": "toroidal_eigen_mode",
      "params": {
        "components": [
          {
            "coeff": 0.13045954704284668,
            "elem": {
              "type": "poloidal_ring",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "radius": 1.0,
                "delta_r": 0.17499999701976776,
                "order": 1,
                "n_quad": 128
              }
            }
          },
          {
            "coeff": 0.0994940996170044,
            "elem": {
              "type": "toroidal_mode_cluster",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "major_radius": 1.0,
                "minor_radius": 0.3499999940395355,
                "mode_m": 0,
                "n_phi": 16,
                "radial_offset": 0.17499999701976776
              }
            }
          },
          {
            "coeff": -0.04667103290557861,
            "elem": {
              "type": "poloidal_ring",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "radius": 1.0,
                "delta_r": 0.17499999701976776,
                "order": 2,
                "n_quad": 128
              }
            }
          },
          {
            "coeff": -0.03725294768810272,
            "elem": {
              "type": "poloidal_ring",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "radius": 1.0,
                "delta_r": 0.17499999701976776,
                "order": 0,
                "n_quad": 128
              }
            }
          },
          {
            "coeff": -0.03023076057434082,
            "elem": {
              "type": "ring_ladder_inner",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "radius": 1.0,
                "minor_radius": 0.3499999940395355,
                "variant": 0,
                "n_quad": 96
              }
            }
          },
          {
            "coeff": -0.03021395206451416,
            "elem": {
              "type": "ring_ladder_inner",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "radius": 1.0,
                "minor_radius": 0.3499999940395355,
                "variant": 0,
                "n_quad": 96
              }
            }
          },
          {
            "coeff": -0.012712468393146992,
            "elem": {
              "type": "toroidal_mode_cluster",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "major_radius": 1.0,
                "minor_radius": 0.3499999940395355,
                "mode_m": 2,
                "n_phi": 16,
                "radial_offset": 0.17499999701976776
              }
            }
          },
          {
            "coeff": -0.0029108256567269564,
            "elem": {
              "type": "toroidal_mode_cluster",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "major_radius": 1.0,
                "minor_radius": 0.3499999940395355,
                "mode_m": 1,
                "n_phi": 16,
                "radial_offset": 0.17499999701976776
              }
            }
          }
        ]
      },
      "weight": 1.9810433387756348
    },
    {
      "type": "toroidal_eigen_mode",
      "params": {
        "components": [
          {
            "coeff": -0.0397181510925293,
            "elem": {
              "type": "poloidal_ring",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "radius": 1.0,
                "delta_r": 0.17499999701976776,
                "order": 1,
                "n_quad": 128
              }
            }
          },
          {
            "coeff": -0.03785276412963867,
            "elem": {
              "type": "toroidal_mode_cluster",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "major_radius": 1.0,
                "minor_radius": 0.3499999940395355,
                "mode_m": 0,
                "n_phi": 16,
                "radial_offset": 0.17499999701976776
              }
            }
          },
          {
            "coeff": 0.025123000144958496,
            "elem": {
              "type": "poloidal_ring",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "radius": 1.0,
                "delta_r": 0.17499999701976776,
                "order": 0,
                "n_quad": 128
              }
            }
          },
          {
            "coeff": 0.006688714027404785,
            "elem": {
              "type": "ring_ladder_inner",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "radius": 1.0,
                "minor_radius": 0.3499999940395355,
                "variant": 0,
                "n_quad": 96
              }
            }
          },
          {
            "coeff": 0.006684780120849609,
            "elem": {
              "type": "ring_ladder_inner",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "radius": 1.0,
                "minor_radius": 0.3499999940395355,
                "variant": 0,
                "n_quad": 96
              }
            }
          },
          {
            "coeff": 0.004944801330566406,
            "elem": {
              "type": "poloidal_ring",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "radius": 1.0,
                "delta_r": 0.17499999701976776,
                "order": 2,
                "n_quad": 128
              }
            }
          },
          {
            "coeff": 0.00260065752081573,
            "elem": {
              "type": "toroidal_mode_cluster",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "major_radius": 1.0,
                "minor_radius": 0.3499999940395355,
                "mode_m": 2,
                "n_phi": 16,
                "radial_offset": 0.17499999701976776
              }
            }
          },
          {
            "coeff": -0.0008775616297498345,
            "elem": {
              "type": "toroidal_mode_cluster",
              "params": {
                "center": [
                  0.0,
                  0.0,
                  0.0
                ],
                "major_radius": 1.0,
                "minor_radius": 0.3499999940395355,
                "mode_m": 1,
                "n_phi": 16,
                "radial_offset": 0.17499999701976776
              }
            }
          }
        ]
      },
      "weight": 4.297216892242432
    },
    {
      "type": "point",
      "params": {
        "position": [
          0.9157331585884094,
          -0.015477371402084827,
          0.05008603632450104
        ]
      },
      "weight": 0.0048985471948981285
    },
    {
      "type": "point",
      "params": {
        "position": [
          0.8696231842041016,
          0.28122854232788086,
          -0.03297017142176628
        ]
      },
      "weight": 0.00020883804245386273
    },
    {
      "type": "point",
      "params": {
        "position": [
          0.8632487654685974,
          0.4439578950405121,
          -0.08992702513933182
        ]
      },
      "weight": -0.005901680327951908
    },
    {
      "type": "point",
      "params": {
        "position": [
          0.6013989448547363,
          0.6230278611183167,
          0.07484465092420578
        ]
      },
      "weight": 0.007545508909970522
    },
    {
      "type": "point",
      "params": {
        "position": [
          0.3078763782978058,
          0.7778884768486023,
          -0.014399133622646332
        ]
      },
      "weight": -0.011716403067111969
    },
    {
      "type": "point",
      "params": {
        "position": [
          0.19954237341880798,
          0.8650360703468323,
          0.02115783281624317
        ]
      },
      "weight": 0.01346657332032919
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.12576308846473694,
          0.9599190354347229,
          -0.021691277623176575
        ]
      },
      "weight": -0.00904802605509758
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.3850373327732086,
          0.8213119506835938,
          0.021506555378437042
        ]
      },
      "weight": 0.006155145354568958
    }
  ]
}
================================================================================
===== END FILE: systems\mid_baseline_eigen.json =====
================================================================================

================================================================================
===== BEGIN FILE: systems\mid_bem_highres_trial02.json =====
================================================================================

{
  "metadata": {
    "reg_l1": 0.0002,
    "boundary_weight": 0.95
  },
  "images": [
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 1.057252049446106,
        "delta_r": 0.08330611884593964,
        "order": 2,
        "n_quad": 128
      },
      "weight": 0.00044968281872570515
    },
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 0.9534857869148254,
        "delta_r": 0.1868913322687149,
        "order": 2,
        "n_quad": 128
      },
      "weight": 0.001816187403164804
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.07687964290380478,
          0.8454011082649231,
          0.011433246545493603
        ]
      },
      "weight": 0.003923818934708834
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.12602989375591278,
          0.898098886013031,
          0.00732202036306262
        ]
      },
      "weight": -0.001726781134493649
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.8415679335594177,
          0.06980734318494797,
          -0.04171684384346008
        ]
      },
      "weight": -0.005254000425338745
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.8495869636535645,
          0.009729181416332722,
          0.08968504518270493
        ]
      },
      "weight": 0.007336752023547888
    }
  ]
}
================================================================================
===== END FILE: systems\mid_bem_highres_trial02.json =====
================================================================================

================================================================================
===== BEGIN FILE: systems\mid_local_seed5500358_trial003.json =====
================================================================================

{
  "metadata": {
    "run": "mid_local_seed5500358_trial003",
    "reg_l1": 0.0004,
    "boundary_weight": 0.95,
    "per_type_reg": {
      "poloidal_ring": 0.0003351702049417128,
      "point": 0.0014021538542835063
    }
  },
  "images": [
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 1.0616551637649536,
        "delta_r": 0.09116708487272263,
        "order": 0,
        "n_quad": 128
      },
      "weight": 0.005894324742257595
    },
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 0.9363718628883362,
        "delta_r": 0.19660720229148865,
        "order": 2,
        "n_quad": 128
      },
      "weight": -0.0006413449300453067
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.05687188729643822,
          0.9002212285995483,
          0.013354171067476273
        ]
      },
      "weight": -0.00029021184309385717
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.029752392321825027,
          0.8394414782524109,
          0.017241142690181732
        ]
      },
      "weight": 0.0005344147211872041
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.8681967854499817,
          0.04832879826426506,
          0.07809602469205856
        ]
      },
      "weight": 0.004235350526869297
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.8162236213684082,
          0.13355880975723267,
          -0.06057657673954964
        ]
      },
      "weight": -0.0033142841421067715
    }
  ]
}
================================================================================
===== END FILE: systems\mid_local_seed5500358_trial003.json =====
================================================================================

================================================================================
===== BEGIN FILE: systems\mid_random_seed5500358.json =====
================================================================================

{
  "metadata": {
    "run": "torus_mid_seed5500358",
    "basis_types": [
      "point",
      "toroidal_eigen_mode_boundary",
      "poloidal_ring",
      "inner_rim_arc",
      "inner_rim_ribbon"
    ],
    "n_max": 6,
    "reg_l1": 0.0003,
    "per_type_reg": {
      "point": 0.001338494391855387,
      "toroidal_eigen_mode_boundary": 0.0003103191571636365,
      "poloidal_ring": 0.00027535615045679675,
      "inner_rim_arc": 0.00041093856806633514,
      "inner_rim_ribbon": 0.00030746372147824114
    },
    "boundary_weight": 0.9,
    "restarts": 1,
    "two_stage": true
  },
  "images": [
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 1.0,
        "delta_r": 0.17499999701976776,
        "order": 0,
        "n_quad": 128
      },
      "weight": 0.007287273649126291
    },
    {
      "type": "poloidal_ring",
      "params": {
        "center": [
          0.0,
          0.0,
          0.0
        ],
        "radius": 1.0,
        "delta_r": 0.17499999701976776,
        "order": 2,
        "n_quad": 128
      },
      "weight": -0.0001330888771917671
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.005980550777167082,
          0.8942309617996216,
          0.031122533604502678
        ]
      },
      "weight": 0.004863223992288113
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.9103789329528809,
          0.028032781556248665,
          0.030982226133346558
        ]
      },
      "weight": 0.006016171537339687
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.06747370958328247,
          0.8027620911598206,
          -0.010085975751280785
        ]
      },
      "weight": -0.004357452038675547
    },
    {
      "type": "point",
      "params": {
        "position": [
          -0.7996633052825928,
          0.00685100257396698,
          -0.04097582772374153
        ]
      },
      "weight": -0.004245209973305464
    }
  ]
}
================================================================================
===== END FILE: systems\mid_random_seed5500358.json =====
================================================================================

================================================================================
===== BEGIN FILE: vault_summaries\summary.md =====
================================================================================

Mid-torus axis weight SVD study (2 rings + 4 points, fixed geometry)

Theory inputs (docs/research):
- Functional_Analysis_of_the_Torous.pdf: single-layer boundary operator on the torus is compact, positive, Fredholm with discrete spectrum → Green’s kernel is Hilbert–Schmidt with infinite rank; exact finite-basis representation is ruled out except for trivial geometries. Finite N can only approximate; low effective rank along a restricted parameter set (axis) is plausible.
- toroid.pdf: toroidal harmonics give infinite (m,n) family even for m=0; no truncation expected.
- Inner-Rim Asymptotics and Boundary Layers.pdf: inner-rim boundary layer requires high poloidal content; localized primitives near the inner rim help capture steep gradients.

Experiment design:
- Fixed geometry = mid_bem_highres_trial02 (2 poloidal_ring order=2, radii 1.0573/0.9535, delta_r 0.0833/0.1869; 4 near-surface points).
- Axis grid z = 0.40…0.90 step 0.05 (11 samples). Solve weights only via ISTA (n_colloc=4096, ratio_boundary=0.8, reg_l1=4e-4, point_reg_mult=4, boundary_weight=0.9).
- Dataset: runs/torus/mid_axis_weights.json (weights + Stage metrics).
- SVD of weight matrix W ∈ R^{6×11}: σ/σ1 ≈ [1.0, 0.408, 0.059, 0.0196, 0.0059, 0.0025]; rank thresholds: >1e-1 → 2, >1e-2 → 4.
- Reduced-rank reconstructions (r=2,3) evaluated with high-res BEM (nr=nz=200) at z∈{0.40,0.60,0.70,0.90}.

Key BEM metrics (mean_rel / inner_mean_rel / max_rel):
- Full (r=6): z=0.40 → 8.77 / 10.60 / 7.70e4; z=0.60 → 5.78 / 9.61 / 5.1e3; z=0.70 → 5.68 / 9.37 / 1.50e4; z=0.90 → 19.25 / 10.26 / 4.11e5.
- Rank-2: z=0.40 → 7.86 / 9.46 / 6.82e4; z=0.60 → 5.23 / 8.71 / 4.54e3; z=0.70 → 6.22 / 10.37 / 1.67e4; z=0.90 → 18.46 / 9.73 / 3.92e5.
- Rank-3: z=0.40 → 8.08 / 9.86 / 7.00e4; z=0.60 → 5.19 / 8.59 / 4.50e3; z=0.70 → 6.15 / 10.17 / 1.65e4; z=0.90 → 18.81 / 10.02 / 4.01e5.
Baselines for context: mid_bem_highres_trial02 (z=0.70) mean_rel≈5.39, inner_mean_rel≈7.35, max_rel≈2.25e4.

Interpretation:
- The operator viewpoint and toroidal harmonic theory forbid an exact finite-basis Green’s function; the axis family is at best low-rank. The weight map shows strong decay after two modes (σ2/σ1≈0.41, σ3/σ1≈0.059), consistent with a low Kolmogorov n-width for this 1D manifold.
- Rank-2/3 truncations barely degrade BEM accuracy for z=0.40–0.70 and even reduce inner_mean_rel in some cases (z=0.60). High max_rel persists, especially near z=0.90, indicating unresolved boundary-layer / far-field structure; geometry likely needs an extra localized element for the inner rim or outer belt to tame spikes.
- Conclusion: Evidence supports a very low-rank approximate Green’s function along the axis (effective rank ≈2–3 within 5–10% mean_rel), but theory and high max_rel spikes confirm no exact finite-basis solution; boundary-layer physics keeps the operator infinite-rank.

Artifacts:
- Dataset: mid_axis_weights.json, SVD: mid_axis_weight_svd.json, BEM metrics: metrics_bem.json.
- Systems: full z-sweep, rank-2/3 systems at z=0.60, 0.90; baselines (mid_bem_highres_trial02, mid_baseline_eigen).
- Diagnostics: mid_axis_weight_rank{full,2,3}_z{0.40,0.60,0.70,0.90}.npz.
- Visuals: mid_axis_weight_full_z0.60.png, mid_axis_weight_rank2_z0.60.png, mid_axis_weight_rank2_z0.90.png.

================================================================================
===== END FILE: vault_summaries\summary.md =====
================================================================================

